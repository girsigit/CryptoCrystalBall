{"cells":[{"cell_type":"markdown","metadata":{"id":"7hIg3ij469IA"},"source":["# Version 1\n","2022-10-13"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sK6Uuoy5qsua"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9w8HifRHR1_a"},"outputs":[],"source":["project_id = 'tweetprediction'\n","bucket_name = 'ticks_with_indicators_with_volume'\n","bucket_name_tick_data = 'bittrex_tick_data'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MTJ7bYMtHmvS"},"outputs":[],"source":["from google.colab import auth\n","auth.authenticate_user()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"f-DcetcgNDks"},"outputs":[],"source":["import tensorflow as tf\n","from tensorflow.keras.layers import Input, Dense, ReLU, Add, Flatten, Concatenate, LayerNormalization, UpSampling2D, Activation, LSTM, Multiply, Dropout, Reshape, Permute, BatchNormalization, MaxPooling1D, AveragePooling1D, MaxPooling3D, AveragePooling2D, LayerNormalization, MaxPooling2D\n","from tensorflow.keras.layers import Conv1D, Conv2D\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.optimizers import Adam"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LZnQ-1ltqt8o"},"outputs":[],"source":["try:\n","  import talib\n","except:\n","  #!cp /content/drive/MyDrive/Privat/Crypto/ta-lib-0.4.0-src.tar.gz ta-lib-0.4.0-src.tar.gz\n","  # !wget http://prdownloads.sourceforge.net/ta-lib/ta-lib-0.4.0-src.tar.gz\n","  #!tar -xzvf ta-lib-0.4.0-src.tar.gz\n","  !unzip /content/drive/MyDrive/Privat/Crypto/talibmaked.zip -d /\n","  %cd ta-lib\n","  #!./configure --prefix=/usr\n","  #!make\n","  !make install\n","  !pip install Ta-Lib\n","  \n","  import talib\n","  from talib import MA_Type"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"82wh7z6fx10V"},"outputs":[],"source":["!pip install transformers"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"J5lm4kZqsHl6"},"outputs":[],"source":["import logging\n","logger = logging.getLogger()\n","logger.setLevel(logging.INFO)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1KWxAFhKqvPY"},"outputs":[],"source":["import sys\n","sys.path.insert(0, \"/content/drive/MyDrive/Privat/Crypto/CryptoCrystalBall/DataStreamCreator\")\n","sys.path.insert(0, \"/content/drive/MyDrive/Privat/Crypto/CryptoCrystalBall/IndicatorCalculator\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"a-9z-QVIqwcZ"},"outputs":[],"source":["from IndicatorCalculator import IndicatorCalculator, IndicatorCalculationError\n","import DataStreamCreator"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EcBnUrFKqyCK"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import json\n","import copy\n","import pickle\n","import matplotlib.pyplot as plt\n","import os\n","from tqdm import tqdm"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4Q2C2e64L8V4"},"outputs":[],"source":["from sklearn.cluster import Birch"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rfq5Vbzq_sxh"},"outputs":[],"source":["RANDOM_SEED = 10"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EtDdNX7JsJ7X"},"outputs":[],"source":["BASE_PATH = \"/content/drive/MyDrive/Privat/Crypto/bittrex\"\n","checkpoint_path = \"gs://ticks_with_indicators_with_volume/chk/\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XYz0PnPnH_dV"},"outputs":[],"source":["# Get file names\n","from os import listdir\n","from os.path import isfile, join\n","VALID_CURRS_DIR = \"/content/drive/MyDrive/Privat/Crypto/bittrex/train/normalCharts\"\n","validcurrs = [f.replace(\".jpg\",\"\") for f in listdir(VALID_CURRS_DIR) if (isfile(join(VALID_CURRS_DIR, f)))]\n","validcurrs = sorted(validcurrs)\n","len(validcurrs)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6fcaN9Sxq0gO"},"outputs":[],"source":["# Get train file names\n","import os\n","from os import listdir\n","from os.path import isfile, join\n","\n","TRAIN_PATH = os.path.join(BASE_PATH, \"train\")\n","\n","trainfiles = [f for f in listdir(TRAIN_PATH) if isfile(join(TRAIN_PATH, f)) and \".csv\" in f ]\n","trainfiles = [f for f in trainfiles if \"-USDT\" in f]\n","trainfiles = [f for f in trainfiles if f.split(\"/\")[-1].replace(\".csv\",\"\") in validcurrs]\n","trainfiles = sorted(trainfiles)\n","len(trainfiles)\n","\n","# trainfiles = trainfiles[:20]\n","# len(trainfiles)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"s46Kst58fyb1"},"outputs":[],"source":["TRAIN_PATH"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1qQkceIMK2Zn"},"outputs":[],"source":["# Get test file names\n","import os\n","from os import listdir\n","from os.path import isfile, join\n","\n","TEST_PATH = os.path.join(BASE_PATH, \"test\")\n","\n","# testfiles = [f for f in listdir(TEST_PATH) if isfile(join(TEST_PATH, f)) and \".csv\" in f ]\n","# testfiles = [f for f in testfiles if \"-USDT\" in f]\n","# testfiles = sorted(testfiles)\n","\n","# indices_to_access = [100,7,43]\n","# accessed_mapping = map(testfiles.__getitem__, indices_to_access)\n","# testfiles = list(accessed_mapping)\n","testfiles = ['ETH-USDT.csv', 'BMP-USDT.csv', 'DOGE-USDT.csv', 'XRP-USDT.csv']\n","testfiles "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WMVeO-Y0yvcs"},"outputs":[],"source":["# SMCNT = 200\n","# SMCNT2 = 200\n","# 0.4\t0.4\t0.0\t2.000000e-01\t2.000000e-01\t"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"97V6EXnKk6DS"},"outputs":[],"source":["BATCH_SIZE = 64\n","FEATURES = 228\n","PATTERN_CNT = 61\n","X_LOOKBACK_CNT = 128 #192 #64\n","Y_LOOKAHEAD_CNT = 0\n","GAIN_LOOKAROUND_CNT = np.nan"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6GLKUY_eGxO0"},"outputs":[],"source":["# Y_TYPE = 3 # 0 for categorical, 1 for float, 2 for gain lookaround, 3 for entry/exit\n","# SMCNT = 48\n","# SMCNT2 = 48\n","# EXPECTED_GAIN_LOOKFORWARD = 2*24\n","# ENTR_THR = 0.6\n","# ENTR_THR2 = 0.6\n","# ENTR_THR3 = 0.0\n","# EXIT_THR = -0.1\n","# EXIT_THR2 = 0.1"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9gVMc87DJoaj"},"outputs":[],"source":["# PARAM_SET = 2\n","\n","# Y_TYPE = 3 # 0 for categorical, 1 for float, 2 for gain lookaround, 3 for entry/exit\n","# SMCNT = 48\n","# SMCNT2 = 48\n","# EXPECTED_GAIN_LOOKFORWARD = 2*24\n","# ENTR_THR = 0.9\n","# ENTR_THR2 = 0.8\n","# ENTR_THR3 = 0.0\n","# EXIT_THR = -0.5\n","# EXIT_THR2 = 0.1"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gfueNXTq0gl6"},"outputs":[],"source":["# Parameterset 3\n","PARAM_SET = 3\n","\n","Y_TYPE = 3 # 0 for categorical, 1 for float, 2 for gain lookaround, 3 for entry/exit\n","SMCNT = 48\n","SMCNT2 = 48\n","EXPECTED_GAIN_LOOKFORWARD = 7*24\n","ENTR_THR = 0.9\n","ENTR_THR2 = 0.8\n","ENTR_THR3 = 0.1\n","EXIT_THR = -0.75\n","EXIT_THR2 = -0.7\n","\n","CLASS_WEIGHT = {0:3.17505149, 1: 1.62627684, 2: 1.0}\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8ecky-ERC0bI"},"outputs":[],"source":["# # # Parameterset 4\n","\n","# Y_TYPE = 1 # 0 for categorical, 1 for float, 2 for gain lookaround, 3 for entry/exit\n","# SMCNT = 120\n","# SMCNT2 = 48\n","# EXPECTED_GAIN_LOOKFORWARD = 7*24\n","# ENTR_THR = 0.9\n","# ENTR_THR2 = 0.8\n","# ENTR_THR3 = 0.1\n","# EXIT_THR = -0.75\n","# EXIT_THR2 = -0.7"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1JVT1Z2U0lW8"},"outputs":[],"source":["SHORTSPAN = 6\n","MIDSPAN = 48\n","LONGSPAN = 120"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7W5Vc3jzgtCT"},"outputs":[],"source":["# FRQ_SMOOTH_PERIODS = [1,2,16]\n","# TIME_WARP_FACTORS = [1,4,16]\n","\n","FRQ_SMOOTH_PERIODS = [1] #[1,4,8]\n","TIME_WARP_FACTORS = [2]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DBshSD4bqQ4y"},"outputs":[],"source":["# FRQ_SMOOTH_PERIODS = [1,4,8]\n","# TIME_WARP_FACTORS = [1]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6DjXlrEnqdHX"},"outputs":[],"source":["# # New periods\n","# FRQ_SMOOTH_PERIODS = [1,4,16,64]\n","# TIME_WARP_FACTORS = [1,4,8,16]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VvZfMFeIsPA4"},"outputs":[],"source":["import tensorflow as tf\n","from tensorflow.python.lib.io import file_io"]},{"cell_type":"markdown","metadata":{"id":"k-J7-V5YbFzH"},"source":["# Visualization of y"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-0abeO63cDP7"},"outputs":[],"source":["VISUAL_ID = 7 #7"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rNMB8gPwbK9J"},"outputs":[],"source":["y_dir = None\n","y_dir2nd = None\n","\n","ite = DataStreamCreator.FileListToDataStream([trainfiles[VISUAL_ID]], 1, TRAIN_PATH,\n","                                              smooth_cnt=SMCNT, smooth_cnt2=SMCNT2,\n","                                              X_lookback_cnt = X_LOOKBACK_CNT,\n","                                              y_lookahead_cnt = Y_LOOKAHEAD_CNT,\n","                                              gain_lookaround_cnt = GAIN_LOOKAROUND_CNT,\n","                                              shortspan=SHORTSPAN, midspan=MIDSPAN, longspan=LONGSPAN,\n","                                              y_type = Y_TYPE,\n","                                              expected_gain_lookforward=EXPECTED_GAIN_LOOKFORWARD, entr_thr=ENTR_THR, entr_thr2=ENTR_THR2, entr_thr3=ENTR_THR3,\n","                                              exit_thr=EXIT_THR, exit_thr2=EXIT_THR2,\n","                                              parallel_generators = 1, random_seed=RANDOM_SEED,\n","                                              y_exponent = 1.0,\n","                                              shuffle = False,\n","                                              batch_norm = False)\n","while True:\n","  try:    \n","    ne = next(ite)\n","  except StopIteration:\n","    break\n","  if y_dir is None or y_dir2nd is None:\n","    y_dir = ne[1][:,0]\n","    y_dir2nd = ne[1][:,1]\n","  else:\n","    y_dir = np.concatenate([y_dir, ne[1][:,0]])\n","    y_dir2nd = np.concatenate([y_dir2nd, ne[1][:,1]])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uVJ5b3pycLwH"},"outputs":[],"source":["# Load the tick table\n","tickpath = os.path.join(TRAIN_PATH, trainfiles[VISUAL_ID])\n","tickdata = pd.read_csv(tickpath)\n","tickdata.set_index(\"startsAt\", inplace = True)\n","tickdata.sort_index()\n"," \n","# Crop the lookback\n","tickdata = tickdata.iloc[X_LOOKBACK_CNT:]\n","\n","tickdata"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ky3xgVHGOMGr"},"outputs":[],"source":["y_dir.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"E0uPUZfSz2Pr"},"outputs":[],"source":["y_dir"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wce8gu8obf_W"},"outputs":[],"source":["fig, ax1 = plt.subplots(figsize=(30,10))\n","\n","ax1.plot(y_dir2nd, color=\"red\")\n","ax1.plot(y_dir, color=\"green\")\n","\n","# ax1.set_xlim(0,1000)\n","\n","ax2 = ax1.twinx()\n","\n","y_dir_naned = copy.deepcopy(y_dir)\n","y_dir_naned[y_dir_naned == 0] = np.nan\n","\n","exit_naned = copy.deepcopy(y_dir2nd)\n","exit_naned[exit_naned == 0] = np.nan\n","\n","# ax2.plot(tickdata.loc[:,\"close\"].values * y_dir_naned, color = \"green\", linewidth=2, marker=\"X\", markersize=15)\n","# ax2.plot(tickdata.loc[:,\"close\"].values * exit_naned, color = \"red\", linewidth=2, marker=\"X\", markersize=15)\n","\n","ax2.plot(tickdata.loc[:,\"close\"].values, color = \"black\")\n","\n","ax1.set_ylim(0,1.1)"]},{"cell_type":"markdown","metadata":{"id":"vpcxC96KL0b2"},"source":["# Birch training"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QCOifeDEq5pB"},"outputs":[],"source":["stop"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2d0TvmpVz5zV"},"outputs":[],"source":["ite = DataStreamCreator.FileListToDataStream(trainfiles, 32, TRAIN_PATH,\n","                                              smooth_cnt=SMCNT, smooth_cnt2=SMCNT2,\n","                                              X_lookback_cnt = X_LOOKBACK_CNT,\n","                                              y_lookahead_cnt = Y_LOOKAHEAD_CNT,\n","                                              gain_lookaround_cnt = GAIN_LOOKAROUND_CNT,\n","                                              shortspan=SHORTSPAN, midspan=MIDSPAN, longspan=LONGSPAN,\n","                                              y_type = Y_TYPE,\n","                                              expected_gain_lookforward=EXPECTED_GAIN_LOOKFORWARD, entr_thr=ENTR_THR, entr_thr2=ENTR_THR2, entr_thr3=ENTR_THR3,\n","                                              exit_thr=EXIT_THR, exit_thr2=EXIT_THR2,\n","                                              parallel_generators = 32, random_seed=RANDOM_SEED,\n","                                              y_exponent = 1.0,\n","                                              norm_price_related_indicators = False,\n","                                              shuffle = True,\n","                                              batch_norm = False)\n","\n","X_raw = np.zeros((10032,128,228))\n","i = 0\n","\n","while True:\n","  ne = next(ite)\n","\n","  X_raw[i:i+ne[0].shape[0], :, :] = ne[0]\n","  i = i+ne[0].shape[0]\n","\n","  print(i)\n","  if 10000 < i:\n","    break"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xJMcBgND0ZXV"},"outputs":[],"source":["X_raw.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"R1O7WXUXdnF3"},"outputs":[],"source":["# X_raw = X_raw[:210,:,:]\n","# X_raw.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mvcxOdMx1E24"},"outputs":[],"source":["plt.plot(X_raw[204,90,:])\n","plt.plot(X_raw[205,90,:])\n","plt.plot(X_raw[208,90,:])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OirRohgbY7gD"},"outputs":[],"source":["X_raw.shape[0] * X_raw.shape[1] * X_raw.shape[2]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yK29GahBYvi7"},"outputs":[],"source":["np.sum(X_raw >= 100) / (X_raw.shape[0] * X_raw.shape[1] * X_raw.shape[2])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"awO9k8oJY4hN"},"outputs":[],"source":["np.sum(X_raw < 100)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mAfii332B78G"},"outputs":[],"source":["def NormForBirch(XIn):\n","  _THR = 100\n","  normed = copy.deepcopy(XIn)\n","\n","  print(f\"Elements over threshold: {np.sum(normed > _THR) / (normed.shape[0] * normed.shape[1] * normed.shape[2])}\")\n","  print(f\"Elements under threshold: {np.sum(normed < -_THR) / (normed.shape[0] * normed.shape[1] * normed.shape[2])}\")\n","\n","  normed[normed >= _THR] = _THR\n","  normed[normed <= -_THR] = -_THR\n","  # normed = np.tanh(normed)\n","  # normed += _THR + 1\n","  # normed = np.log10(normed)\n","  # normed -= np.log10(_THR + 1)\n","  \n","  return normed"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"snDbCWFyd6Tb"},"outputs":[],"source":["X_normed = NormForBirch(X_raw)\n","X_normed.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7Zr-NdBWl9M7"},"outputs":[],"source":["del X_raw"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aRwyoKOGeBGR"},"outputs":[],"source":["fig, ax1 = plt.subplots(figsize=(30,10))\n","_ = ax1.plot(X_normed[204,90,:])\n","_ = ax1.plot(X_normed[205,90,:])\n","_ = ax1.plot(X_normed[208,90,:])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"I_8ZbWq0eXcc"},"outputs":[],"source":["import random"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"53IFpRDUd1h4"},"outputs":[],"source":["# randomElementsLen = int(X_raw_RS.shape[0] * 0.5)\n","# print((\"randomElementsLen\", randomElementsLen))\n","# randomIndices = np.empty((randomElementsLen), dtype=int)\n","\n","# for i in range(len(randomIndices)):\n","#   rn = int(random.randrange(0,X_raw_RS.shape[0]-1,1))\n","\n","#   while rn in randomIndices:\n","#     rn = int(random.randrange(0,X_raw_RS.shape[0]-1,1))\n","  \n","#   randomIndices[i] = rn"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qfZJGJaCeeBK"},"outputs":[],"source":["# randomElements = X_raw_RS[randomIndices,:]\n","# randomElements.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ctUCyd_leTkc"},"outputs":[],"source":["np.min(X_normed)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qjh5lcZEwcGP"},"outputs":[],"source":["np.max(X_normed)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xYTZKzdIf-JT"},"outputs":[],"source":["X_normed_flat = np.reshape(X_normed, (X_normed.shape[0] * X_normed.shape[1], X_normed.shape[2]))\n","X_normed_flat.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"e-xLfdEBdGkY"},"outputs":[],"source":["del X_normed"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"66mQocPaYmbS"},"outputs":[],"source":["brc = Birch(n_clusters=256-4) # Minus 4 because BOS,EOS,PAD and MASK Tokens are required for NLP model\n","brc.fit(X_normed_flat)\n","brc"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"49fnRqOLdeA_"},"outputs":[],"source":["p = brc.predict(X_normed_flat)\n","p.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NP7tfkzrgIXD"},"outputs":[],"source":["p[:25]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JOA7UoiJaqPQ"},"outputs":[],"source":["plt.plot(p)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Kge0LLHldnHx"},"outputs":[],"source":["plt.hist(p)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9Ajooxh4gxNG"},"outputs":[],"source":["np.max(p)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3CVbDSHsgK6i"},"outputs":[],"source":["categoryDict = {}\n","\n","# Create empty lists\n","for i in range(np.max(p)+1):\n","  categoryDict[i] = []\n","\n","for i, xClass in enumerate(p):\n","  categoryDict[xClass].append(X_normed_flat[i,:])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kBm634Q_jVHC"},"outputs":[],"source":["len(categoryDict)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1ADMijh6hpVC"},"outputs":[],"source":["# Create and average feature map for each xClass\n","meanFeatureArray = np.zeros( (len(categoryDict), X_normed_flat.shape[-1]))\n","\n","for xClass in categoryDict:\n","  print((xClass, len(categoryDict[xClass])))\n","\n","  cdList = categoryDict[xClass]\n","  cdArray = np.array(cdList)\n","\n","  meanFeature = np.mean(cdArray, axis=0)\n","\n","  meanFeatureArray[xClass, :] = meanFeature"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nZsY1Eikj06W"},"outputs":[],"source":["meanFeatureArray.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kAXV7eCLieRp"},"outputs":[],"source":["# plt.plot(cdArray)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"R7_7jMF-infg"},"outputs":[],"source":["fig, ax1 = plt.subplots(figsize=(30,10))\n","ax1.set_ylim(-1,1)\n","_ = ax1.plot(meanFeatureArray.transpose())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6h9cvZFHjaWD"},"outputs":[],"source":["meanFeatureArray.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3faZ21QxkH0u"},"outputs":[],"source":["# Show a distance matrix to check if the clusters are different \n","distances = np.zeros((meanFeatureArray.shape[0], meanFeatureArray.shape[0]))\n","for i in range(meanFeatureArray.shape[0]):\n","  for k in range(meanFeatureArray.shape[0]):\n","    distances[i,k,] = np.linalg.norm( meanFeatureArray[i,:]-meanFeatureArray[k,:] )\n","\n","print(np.min(distances))\n","print(np.max(distances))\n","\n","fig, ax1 = plt.subplots(figsize=(15,15))\n","_ = ax1.imshow(distances, cmap=\"gray\")"]},{"cell_type":"markdown","metadata":{"id":"b7pOlcQulLqZ"},"source":["### Save the clusterer"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"owPynZbP8C3h"},"outputs":[],"source":["sys.setrecursionlimit(10000) \n","with file_io.FileIO(\"/content/brc.pkl\", mode='wb+') as handle:\n","  pickle.dump(brc, handle, protocol=pickle.HIGHEST_PROTOCOL)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RThDcPvR7hLZ"},"outputs":[],"source":["with open(\"/content/brc.pkl\", 'rb') as pickle_file:\n","  brc2 = pickle.load(pickle_file)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4lh7jCLv8sfq"},"outputs":[],"source":["X_normed_flat.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3ZmLHSOn8qkM"},"outputs":[],"source":["p2 = brc.predict(X_normed_flat[:1000,:])\n","p2.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"c4fXrC0H8wPX"},"outputs":[],"source":["# Check if the re-loaded prediction is the same as the original one\n","diff = p2 - p[:1000]\n","np.sum(np.abs(diff))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"D68ShnBw9FHa"},"outputs":[],"source":["# Store to drive\n","stop\n","!cp /content/brc.pkl /content/drive/MyDrive/Privat/Crypto/birchNew.pkl"]},{"cell_type":"markdown","metadata":{"id":"moBea0tTbFbX"},"source":["# Train a neural network to predict the categories - NOT WORKING"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LgYIewcQcN02"},"outputs":[],"source":["stop"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YNedwP_oAQNP"},"outputs":[],"source":["# Load the BIRCH categorizer\n","with open(\"/content/drive/MyDrive/Privat/Crypto/birchNew.pkl\", 'rb') as pickle_file:\n","  brc = pickle.load(pickle_file)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QSz1VCtNAcbA"},"outputs":[],"source":["ite = DataStreamCreator.FileListToDataStream(trainfiles, 32, TRAIN_PATH,\n","                                              smooth_cnt=SMCNT, smooth_cnt2=SMCNT2,\n","                                              X_lookback_cnt = X_LOOKBACK_CNT,\n","                                              y_lookahead_cnt = Y_LOOKAHEAD_CNT,\n","                                              gain_lookaround_cnt = GAIN_LOOKAROUND_CNT,\n","                                              shortspan=SHORTSPAN, midspan=MIDSPAN, longspan=LONGSPAN,\n","                                              y_type = Y_TYPE,\n","                                              expected_gain_lookforward=EXPECTED_GAIN_LOOKFORWARD, entr_thr=ENTR_THR, entr_thr2=ENTR_THR2, entr_thr3=ENTR_THR3,\n","                                              exit_thr=EXIT_THR, exit_thr2=EXIT_THR2,\n","                                              parallel_generators = 1, random_seed=RANDOM_SEED,\n","                                              y_exponent = 1.0,\n","                                              norm_price_related_indicators = False,\n","                                              shuffle = True)\n","\n","while True:\n","  ne = next(ite)\n","\n","  print(ne[0].shape)\n","\n","  break"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"O5qjpjSLs4zB"},"outputs":[],"source":["def trainGeneratorMethod():\n","  it = DataStreamCreator.FileListToDataStream(trainfiles, BATCH_SIZE, TRAIN_PATH,\n","                                              smooth_cnt=SMCNT, smooth_cnt2=SMCNT2,\n","                                              X_lookback_cnt = X_LOOKBACK_CNT,\n","                                              y_lookahead_cnt = Y_LOOKAHEAD_CNT,\n","                                              gain_lookaround_cnt = GAIN_LOOKAROUND_CNT,\n","                                              shortspan=SHORTSPAN, midspan=MIDSPAN, longspan=LONGSPAN,\n","                                              y_type = Y_TYPE,\n","                                              parallel_generators = 8, random_seed=RANDOM_SEED,\n","                                              y_exponent = 1.0,\n","                                              norm_price_related_indicators = False,\n","                                              shuffle=True)\n","  while True:\n","    try:\n","      ne = next(it)\n","      _X = ne[0]\n","\n","      # Merge batch and time dimension, as birch take 2D data\n","      bIn = _X.reshape((_X.shape[0] * _X.shape[1], _X.shape[2]))\n","      bIn = NormForBirch(bIn)\n","      \n","      bOut = brc.predict(bIn)\n","\n","      # Each feature-frame shall be converted into a number\n","      _y = bOut.reshape(_X.shape[0], _X.shape[1])\n","\n","      # Limit the range to [0,1]\n","      # _y = _y / 1024.0\n","\n","      # Create sparse matrices (one for the category, the other a binary repesantion)\n","      categoryIndices= np.round(_y).astype(int)\n","      ySparse = np.zeros((categoryIndices.shape[0], categoryIndices.shape[1], 1024), dtype=int)\n","      yBinSparse = np.zeros((categoryIndices.shape[0], categoryIndices.shape[1], 10), dtype=int)\n","\n","      for i in range(categoryIndices.shape[0]):\n","        for j in range(categoryIndices.shape[1]):\n","\n","          ySparse[i,j,categoryIndices[i,j]] = 1\n","\n","          # Convert the index into a binary representation\n","          # categoryIndexBinString = bin(categoryIndices[i,j])[2:]\n","          # cropped = np.array([*categoryIndexBinString]).astype(int)\n","          # categoryIndexBin = np.zeros((10))\n","          # categoryIndexBin[-cropped.shape[0]:] = cropped\n","          # yBinSparse[i,j,:] = categoryIndexBin\n","      \n","      # yield (_X, ySparse, yBinSparse)\n","      yield (_X, ySparse)\n","    except StopIteration as si:\n","      logging.warning(\"StopIteration in FileListToDataStream\")\n","      logging.warning(si)\n","      return\n","\n","tfgenTrain = tf.data.Dataset.from_generator(trainGeneratorMethod,\n","                                            output_types = (tf.float32, tf.int64),\n","                                            output_shapes=(\n","                                                (BATCH_SIZE,X_LOOKBACK_CNT,228), \n","                                                (BATCH_SIZE,X_LOOKBACK_CNT,1024)#,\n","                                                # (BATCH_SIZE,X_LOOKBACK_CNT,10)\n","                                                )\n","                                            )\n","\n","tfgenTrain = tfgenTrain.prefetch(tf.data.AUTOTUNE)\n","tfgenTrain\n","\n","n = next(tfgenTrain.as_numpy_iterator())\n","print(n[0].shape) # Normal X data\n","print(n[1].shape) # The one-hot encoded desired filter for each feature frame\n","# print(n[2].shape) # category id in binary"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VAdhYlkhDkww"},"outputs":[],"source":["from sklearn.utils import shuffle\n","import numpy as np"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RRsY0Zbo5hiO"},"outputs":[],"source":["from os import listdir\n","from os.path import isfile, join\n","from tqdm import tqdm\n","from datetime import datetime"]},{"cell_type":"markdown","metadata":{"id":"5zygBVEJDuef"},"source":["# Create Model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RtZlMls8I-Iw"},"outputs":[],"source":["#@title CreateModelFeatureEmbeddingNew\n","# def CreateModelFeatureEmbeddingNew():\n","\n","#   # Build your model input\n","#   inputTimeline = Input(shape=(X_LOOKBACK_CNT, FEATURES), name='input', dtype='float32')\n","  \n","#   # Convert feeatures into \"word embeddings\"\n","#   categoryFilters = Conv1D(filters=1024,\n","#                            kernel_size=1,\n","#                            padding=\"same\",\n","#                            activation=\"softmax\",\n","#                            data_format=\"channels_last\",\n","#                            trainable=False,\n","#                            name=\"CategoryFilters\")(inputTimeline)\n","\n","#   # Convert the features into disrete integers, e.g. a \"sentence\"\n","#   floatFeatures = Dense(1, name=\"OneHotToFloat\", trainable=False)(categoryFilters)\n","\n","#   outputs = [floatFeatures]\n","\n","#   # And combine it all in a model object\n","#   model = Model(inputs=inputTimeline, outputs=outputs, name='ModelFeatureEmbeddingNew')\n","\n","#   # Set the weights for one hot to float conversion manually\n","#   manualWeights = np.array(range(1024))\n","#   manualWeights = np.expand_dims(manualWeights, axis=1)\n","#   manualBias = np.array([0])\n","#   model.get_layer(\"OneHotToFloat\").set_weights([manualWeights, manualBias])\n","\n","#   return model\n","\n","# modelFeatureEmbeddingNew = CreateModelFeatureEmbeddingNew()\n","\n","# Load the prepared model from drive\n","with tf.device('/CPU:0'):\n","  modelFeatureEmbeddingNew = tf.keras.models.load_model('/content/drive/MyDrive/Privat/Crypto/ModelFeatureEmbeddingNew.h5')\n","  modelFeatureEmbeddingNew.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FWwn3B67ntid"},"outputs":[],"source":["##@title CreateModelMergeFeatureToOneFloat\n","# Inspired by https://towardsdatascience.com/how-to-use-convolutional-neural-networks-for-time-series-classification-56b1b0a07a57\n","def CreateModelMergeFeatureToOneFloat():\n","\n","  # Build your model input\n","  inputTimeline = Input(shape=(X_LOOKBACK_CNT, FEATURES), name='input', dtype='float32')\n","  \n","  # Convert feeatures into \"word embeddings\"\n","  categoryFilters = Conv1D(filters=1024,\n","                           kernel_size=1,\n","                           padding=\"same\",\n","                           activation=\"softmax\",\n","                           data_format=\"channels_last\",\n","                           name=\"CategoryFilters\")(inputTimeline)\n","\n","  binaryCategoryId = Dense(10, name=\"BinaryCategoryIdDense1\")(categoryFilters)\n","  binaryCategoryId = Dense(10, name=\"BinaryCategoryIdDense2\", activation=\"sigmoid\")(binaryCategoryId)\n","\n","  outputs = [categoryFilters]\n","\n","  mnamesuffix = \"_1\"\n","\n","  # And combine it all in a model object\n","  model = Model(inputs=inputTimeline, outputs=outputs, name='MergeFeatureToOneFloat'+mnamesuffix)\n","\n","  return model\n","\n","# modelFeatureToNormedInt = CreateModelMergeFeatureToOneFloat()\n","# modelFeatureToNormedInt.summary(line_length=170)"]},{"cell_type":"markdown","metadata":{"id":"kXE8AjjoEWE4"},"source":["# Train the model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lirhCyjsH4WE"},"outputs":[],"source":["model = CreateModelMergeFeatureToOneFloat()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_jkOrQ01hZnE"},"outputs":[],"source":["CHKPNT_NAME = \"{}_T{}_{}LB_LF{}_EN{}_{}_{}_EX{}_{}_SM{}_{}\".format(model.name, Y_TYPE, X_LOOKBACK_CNT, EXPECTED_GAIN_LOOKFORWARD, ENTR_THR, ENTR_THR2, ENTR_THR3, EXIT_THR, EXIT_THR2, SMCNT, SMCNT2)\n","CHKPNT_NAME"]},{"cell_type":"markdown","metadata":{"id":"WDAS1BhBXJ67"},"source":["# Train"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"g0VmovApkwAB"},"outputs":[],"source":["# Set an optimizer\n","optimizer = Adam(\n","    learning_rate=1e-05,\n","    epsilon=1e-05,\n","    decay=0.01)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AOLSygN7Ut7_"},"outputs":[],"source":["# Compile the model\n","model.compile(\n","    optimizer = optimizer,\n","    loss = ['categorical_crossentropy'], \n","    metrics=['mse', 'mae'])\n","\n","# model.compile(\n","#     optimizer = optimizer,\n","#     loss = ['mse'], \n","#     metrics=['mae'])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LuuH0xBKGE1g"},"outputs":[],"source":["# Load the TensorBoard notebook extension\n","%load_ext tensorboard"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eC5mKfMt5z2J"},"outputs":[],"source":["# # !gcloud config set project {project_id} -y\n","# !gsutil cp -R gs://ticks_with_indicators_with_volume/logs/ModelNLP_1_T3_128LB_LF168_EN0.9_0.8_0.1_EX-0.75_-0.7_SM48_4820220915-162219 /content/logs"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AOJpZbR84tTr"},"outputs":[],"source":["# %tensorboard --logdir /content/logs"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ysPZj5WZ4qSs"},"outputs":[],"source":["# from tensorboard import notebook\n","# notebook.list() # View open TensorBoard instances"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0y4tg7WfJTEk"},"outputs":[],"source":["2**14 -1"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TFa0iWcaqli5"},"outputs":[],"source":["model.summary(line_length=220)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iGC1RvizroRS"},"outputs":[],"source":["class CustomCallback(tf.keras.callbacks.Callback):\n","  def __init__(self, save_freq, val_freq, checkpoint_path, model_name, epoch_add=0):\n","    self.save_freq = save_freq\n","    self.val_freq = val_freq\n","    self.checkpoint_path = checkpoint_path\n","    self.model_name = model_name\n","    self.current_epoch = 0\n","    self.epoch_add = epoch_add\n","\n","  def on_epoch_begin(self, epoch, logs=None):\n","    self.current_epoch = epoch + self.epoch_add\n","    # keys = list(logs.keys())\n","    # print(\"Start epoch {} of training; got log keys: {}\".format(epoch, keys))\n","\n","  def on_epoch_end(self, logs=None):\n","    self.saveTheModel(\"end\", logs)\n","\n","  def on_train_batch_end(self, batch, logs=None):\n","    self.saveTheModel(batch, logs)\n","\n","  def saveTheModel(self, batch, logs=None):\n","    if (0 < batch and 0 == batch % self.save_freq) or (\"end\" == batch):\n","      if \"end\" == batch:\n","        _save_folder = os.path.join(self.checkpoint_path,\n","                                    self.model_name,\n","                                    \"cp_daily_valid_{:01d}_end\".format(self.current_epoch)\n","                                    )\n","      else:\n","        _save_folder = os.path.join(self.checkpoint_path,\n","                                    self.model_name,\n","                                    \"cp_daily_valid_{:01d}_{:05d}\".format(self.current_epoch, batch)\n","                                    )\n","\n","      _model_path_local = os.path.join(\"/content/\", \"model.h5\")\n","      _model_path_bucket = os.path.join(_save_folder, \"model.h5\")\n","\n","      model.save(_model_path_local)\n","     \n","      # Copy model.h5 over to Google Cloud Storage\n","      with file_io.FileIO(_model_path_local, mode='rb') as input_f:\n","          with file_io.FileIO(_model_path_bucket, mode='wb+') as output_f:\n","              output_f.write(input_f.read())\n","              print(\"\\nSaved model to: '\" + _model_path_bucket + \"'\")\n","\n","      # Save optimizer config\n","      c = copy.deepcopy(self.model.optimizer.get_config())\n","\n","      fp = os.path.join(_save_folder, \"c.pickle\")\n","      with file_io.FileIO(fp, mode='wb+') as handle:\n","        pickle.dump(c, handle, protocol=pickle.HIGHEST_PROTOCOL)\n","        print(\"Saved optimizer config to: '\" + fp + \"'\")\n","\n","      # Save optimizer weights\n","      w = copy.deepcopy(self.model.optimizer.get_weights())\n","\n","      fp = os.path.join(_save_folder, \"w.pickle\")\n","      with file_io.FileIO(fp, mode='wb+') as handle:\n","        pickle.dump(w, handle, protocol=pickle.HIGHEST_PROTOCOL)\n","        print(\"Saved optimizer weights to: '\" + fp + \"'\")\n","\n","    # if 0 < batch and 0 == batch % self.val_freq:\n","    #   print(\"-------------------------EVAL-------------------------\")\n","    #   model.evaluate(tfgenTest)\n","    #   print(\"\\n-------------------------EVAL-------------------------\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JyggHiDGNTEX"},"outputs":[],"source":["epoch_add = 0"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-pJ08IBN7cgB"},"outputs":[],"source":["CALLBACK_EVERY_N_BATCHES = 2000"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CuGT0rFvzH1n"},"outputs":[],"source":["cc = CustomCallback(checkpoint_path = checkpoint_path,\n","                    model_name = CHKPNT_NAME,\n","                    save_freq = CALLBACK_EVERY_N_BATCHES,\n","                    val_freq = CALLBACK_EVERY_N_BATCHES,\n","                    epoch_add = epoch_add)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AGTsaO_KGH58"},"outputs":[],"source":["import datetime\n","log_dir = \"gs://ticks_with_indicators_with_volume/logs/\" + CHKPNT_NAME + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n","tensorboard_callback = tf.keras.callbacks.TensorBoard(\n","    log_dir=log_dir,\n","     histogram_freq=0,\n","     update_freq=CALLBACK_EVERY_N_BATCHES \n","     )"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RtTR6r4VFCt4"},"outputs":[],"source":["model.fit(tfgenTrain, epochs=200, verbose = 1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wQcuvAPxgQMK"},"outputs":[],"source":["# 4602/Unknown - 8547s 2s/step - loss: 74.7547 - mse: 0.0018 - mae: 0.0019\n","# model.save(\"/content/drive/MyDrive/Privat/Crypto/FeatureEmbedding.h5\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"04uFO99WW9ny"},"outputs":[],"source":["n = next(tfgenTrain.as_numpy_iterator())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sH8H0iONXG-T"},"outputs":[],"source":["n[0].shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"S1BYfaRGXWP9"},"outputs":[],"source":["n[1].shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iEdD4Wtq-ONy"},"outputs":[],"source":["plt.plot(model.layers[1].get_weights()[0][0,:,1000])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sIJoUv7SXI1t"},"outputs":[],"source":["p = model.predict(n[0])\n","p.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QMqHZ2fCh7AR"},"outputs":[],"source":["np.array(range(1024))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"45T1aqYMkqq4"},"outputs":[],"source":["tf.convert_to_tensor(np.array(range(1024)))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fBEF4h1liHj4"},"outputs":[],"source":["cats = []\n","for i in range(p.shape[1]):\n","  cats.append(int(np.sum(p[0,i,:] * np.array(range(1024)))))\n","  print(cats[-1])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"m4XXLJoOiXYt"},"outputs":[],"source":["plt.hist(cats)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aHfh8p-XiFGF"},"outputs":[],"source":["np.sum(p[0,4,:] * np.array(range(1024)))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dqB28Qkbh4RN"},"outputs":[],"source":["np.sum(p[0,5,:] * np.array(range(1024)))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yhOpNNN1hnzR"},"outputs":[],"source":["plt.plot(p[0,5,:])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"byyiNoeAXMgk"},"outputs":[],"source":["plt.plot(p[0,:])\n","plt.plot(n[1][0,:])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Pj6oSUmPlsBX"},"outputs":[],"source":["p.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zzEHLLLslzsR"},"outputs":[],"source":["X_LOOKBACK_CNT"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qy_h5gldl1NU"},"outputs":[],"source":["FEATURES"]},{"cell_type":"markdown","metadata":{"id":"coZL2ZCIlOyj"},"source":["# Create a dense layer to convert one hot to int"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OCwxXwNElUvy"},"outputs":[],"source":["##@title CreateModelOneHotToInt\n","def CreateModelOneHotToInt():\n","\n","  # Build your model input\n","  inputTimeline = Input(shape=(X_LOOKBACK_CNT, 1024), name='input', dtype='float32')\n","\n","  floatFeature = Dense(1, name=\"OneHotToFloat\")(inputTimeline)\n","\n","  outputs = [floatFeature]\n","  \n","  # And combine it all in a model object\n","  model = Model(inputs=inputTimeline, outputs=outputs, name='ModelOneHotToInt')\n","\n","  return model\n","\n","modelOneHotToInt = CreateModelOneHotToInt()\n","modelOneHotToInt.summary(line_length=170)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4UbVFuPvmhh7"},"outputs":[],"source":["X_data = np.empty((1024,128,1024))\n","y_data = np.empty((1024,128,1))\n","\n","for i in range(1024):\n","  X_data[i,:,i] = 1\n","  y_data[i,:,0] = i"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jg2NbkSpnKxs"},"outputs":[],"source":["y_data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-OD7niz7m2vq"},"outputs":[],"source":["X_data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2pMfhGaJncBX"},"outputs":[],"source":["# Set an optimizer\n","optimizer = Adam(\n","    learning_rate=1e-05,\n","    epsilon=1e-05,\n","    decay=0.01)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"p-AGoaxhnVQ2"},"outputs":[],"source":["# Compile the model\n","modelOneHotToInt.compile(\n","    optimizer = optimizer,\n","    loss = ['mse'], \n","    metrics=['mae'])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ij6uJLuCndXd"},"outputs":[],"source":["modelOneHotToInt.fit(X_data, y_data, epochs=100)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Tx7u0RjVnv6B"},"outputs":[],"source":["X_test = np.zeros((1,128,1024))\n","X_test[:,0,2] = 1\n","X_test"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aX3id9HNoK4U"},"outputs":[],"source":["manualWeights = np.array(range(1024))\n","manualWeights = np.expand_dims(manualWeights, axis=1)\n","manualBias = np.array([0])\n","manualWeights.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"X8Bes7ssrzRS"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DAw2F2pWr5EJ"},"outputs":[],"source":["modelOneHotToInt.get_layer(\"OneHotToFloat\").set_weights([manualWeights, manualBias])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KBWqfsnHoAQ5"},"outputs":[],"source":["modelOneHotToInt.get_layer(\"OneHotToFloat\").get_weights()[1].shape"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyNd6HHFLo7W32ovPyOlNYiT","collapsed_sections":[],"machine_shape":"hm","provenance":[{"file_id":"1UUw6C5Z23QlibFe0elnZt4pUFzjN3t8o","timestamp":1663591256912},{"file_id":"1jILOLRiHpk26BEbfAnq3PDeXUK2lniiJ","timestamp":1635017831673},{"file_id":"1zqNi1eWTbsXaETc5v3Oz6ZWeUV9dOkNv","timestamp":1634375019112},{"file_id":"1o3ZRZFmtB4A0DAyjf6z84hgRT2LDpj91","timestamp":1634300557985},{"file_id":"1jNsdjdOOGBCcKgGWKtVICp9vj2R7unGm","timestamp":1632570519117},{"file_id":"1uf6CqNsiocD_TOU3wJwlzt9Sa0fdO86S","timestamp":1632559358988},{"file_id":"1Mg5CJdXb5GRmIT7fJtRCxq_U2AWjvd4g","timestamp":1632395092269},{"file_id":"1IvG6p2CEyfKoAGtYCzj4US2CHSthjh6n","timestamp":1632328373336}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
