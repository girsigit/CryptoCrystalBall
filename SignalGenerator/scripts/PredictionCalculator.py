# -*- coding: utf-8 -*-
"""
A class to calculate the predictions on a tick DF using a trained ML model

# Todo: Clean up this file, all teh variables and the dokumentation is messed up

LiveSignalGenerator.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1QGTgcto2YEGAmJa5WXe4PtwKls549dFY

# Live predictor

## Todo: Add link to training and finder notebook
## Todo: Create model download
"""

# Activate logging
import tempfile
import copy
import sys
import numpy as np
import pandas as pd
import os
import tensorflow as tf
import logging
logger = logging.getLogger()

if __name__ == "__main__":
    logger.setLevel(logging.INFO)

# Check if the tf version is 2.10.0

if '2.10.0' != tf.__version__:
    raise NotImplementedError(
        f"Tensorflow has to be version 2.10.0, yours is {tf.__version__}")


"""---
# Todo: Improve
# Add custom import path for DataStreamCreator and IndicatorCalculator

These libs are not in the standard python directory, so their paths have to be added to the import paths
"""


class PredictionCalculator:
    '''
    Todo add description: A class to predict future gain and its derivation from live data
    '''

    def __init__(self, modelPath):
        # Create the import directories for the DataStreamCreator and the IndicatorCalculator
        dsc_dir = '/content/CryptoCrystalBall/DataStreamCreator'
        print(f"dsc_dir: {dsc_dir}")

        ind_dir = '/content/CryptoCrystalBall/IndicatorCalculator'
        print(f"ind_dir: {ind_dir}")

        # Add them to the import paths
        sys.path.insert(0, dsc_dir)
        sys.path.insert(0, ind_dir)

        # Import the actual class
        import DataStreamCreator
        self.DataStreamCreator = DataStreamCreator

        """---
    # Define all the parameters and variables
    """

        # Todo: pass as argument
        # MODEL_PATH = "/content/CryptoCrystalBall/Data/strategies/etf_good_on_test_and_eval/FPNWithAttentionBiggerTimebased_2_FutureOnly_60days_GPU_128LB/cp_daily_valid_05_end/model.h5"

        # Define how many y data vectors shall be predicted. This is required to calc the past min/max values of the inidicators
        self.INDICATOR_MINMAX_PERIOD = 28

        # X_BLOCK_LENGHT defines how far into the past a 'slice of a chart' shall be
        # See: https://github.com/girsigit/CryptoCrystalBall/tree/main/DataStreamCreator#xblockgenerator

        # For this ML architecture, the X_BLOCK_LENGHT has to be a member of 2**n, otherwise the feature pyramid cannot be built correctly
        self.X_BLOCK_LENGHT = 128

        # How many examples shall be processed at the same time, limited by GPU memory
        self.BATCH_SIZE = self.INDICATOR_MINMAX_PERIOD

        # A fixed number of features is used
        self.FEATURES = 149

        # Finanical indicator timespans
        # See: https://github.com/girsigit/CryptoCrystalBall/tree/main/IndicatorCalculator
        self.SHORTSPAN = 7
        self.MIDSPAN = 38
        self.LONGSPAN = 50

        # The TaLib indicators need some time to settle to stable, reproducible values (Todo imporant: Check which need this, why, and how long (determinisitcally) this period is)
        self.RING_IN_PERIOD = 3 * self.LONGSPAN

        # Additional settings for the data stream
        # For this notebook, the calculation of pattern indicators is turned off
        self.DATA_STREAM_PARAMETERS = {
            "calcPatternIndicators": False,  # No patterns are used
            # No volume indicators, these are wide spread and may disturb the classifer
            "calcVolumeInidators": False,
            # For the prediction, na values shall not be dropped, as this would crop the data as not y-values can be calculated (they would be in the future)
            "dropna": False
        }

        """---
    # Create the neural network

    **Actually, the network architecture is loaded from the model.h5 file and not created explicitly. The code is just left here for information.**


    This approach uses a FPN (Feature-Pyramid-Network, https://jonathan-hui.medium.com/understanding-feature-pyramid-networks-for-object-detection-fpn-45b227b9106c) architecture, followed by LSTM and Dense regressor heads to extract the future gain information.
    The pyramid elements are built in a Res-Net style to provide a good information flow.


    Additionally, it is equipped with Attention layers to focus on relevant information. Futhermore, it uses antialiasing to smooth out disturbance.


    ```
    Todo: Create Image of network structure
    ```
    """

        # @title Create the CreateModelFPNWithAttention model
        # def CreateModelFPNWithAttention():
        #   # Define model parameters
        #   mp = {
        #       "NAME": "FPNWithAttentionBiggerTimebased",
        #       "VERSION": "2_FutureOnly_60days",
        #       "CNN_INITIAL_FILTERS": 64,
        #       "CNN_EXTRACTOR_LAYERS": 6,
        #       "CNN_INITIAL_KERNEL_SIZE": 2,
        #       "CNN_MAX_KERNEL_SIZE": 8,
        #       "FEATURE_PYRAMID_START_INDEX": 2,
        #       "HEAD_LSTM_SIZE": 64,
        #       "HEAD_DENSE_SIZE": 32
        #       }

        #   # Create the model input
        #   inputTicksAndIndicators = Input(shape=(X_BLOCK_LENGHT, FEATURES), name='inputTicksAndIndicators', dtype='float32')

        #   # Apply dropout on the input to make the model robust
        #   inputTicksAndIndicators = Dropout(0.1, name='inputDropout')(inputTicksAndIndicators)

        #   # Normalize the input data, as it has a wide value spread (range of 1e8)
        #   normalized = UnitNormalization(name="UnitNormalizationInput", axis=-2)(inputTicksAndIndicators)

        #   # ----------------------------------------------------------------------------

        #   # A 1D-CNN pyramid is used to extract higher-level features out of the time dimension
        #   conv_layers = []
        #   aligned_layers = []
        #   feature_map_layers = []
        #   anti_aliased_layers = []
        #   anti_aliased_pyramid_indices = []
        #   regressor_layers = []

        #   finalFilters = mp["CNN_INITIAL_FILTERS"] * 2**(mp["FEATURE_PYRAMID_START_INDEX"])
        #   print(finalFilters)

        #   for i in range(mp["CNN_EXTRACTOR_LAYERS"]):
        #     if 0 == i:
        #       source_layer = normalized
        #     else:
        #       source_layer = feature_conv

        #     filters = int(mp["CNN_INITIAL_FILTERS"]*(2**i))
        #     kernel_size = mp["CNN_INITIAL_KERNEL_SIZE"]*(2**i)
        #     kernel_size = int(np.min([mp["CNN_MAX_KERNEL_SIZE"], kernel_size]))
        #     strides = int(np.min([2,kernel_size]))

        #     print(f"Step {i}, using {filters} filters with a kernel size of {kernel_size} at strides of {strides}")

        #     # Create the feature extraction convolution
        #     res_net_element = Conv1D(filters=source_layer.shape[-1],
        #                           kernel_size=kernel_size,
        #                           strides=1,
        #                           padding="same",
        #                           name=f"ResNet_{i}_Conv1D_1")(source_layer)

        #     res_net_element = Activation("relu",
        #                               name=f"ResNet_{i}_ReLU")(res_net_element)

        #     res_net_element = Conv1D(filters=source_layer.shape[-1],
        #                           kernel_size=kernel_size,
        #                           strides=1,
        #                           padding="same",
        #                           name=f"ResNet_{i}_Conv1D_2")(res_net_element)

        #     res_net_element = Add(name=f"ResNet_{i}_Add")([res_net_element, source_layer])

        #     feature_conv = Conv1D(filters=filters,
        #                           kernel_size=kernel_size,
        #                           strides=strides,
        #                           padding="same",
        #                           name=f"ResNet_{i}_Feature_Conv1D_FilterDimReduction")(res_net_element)

        #     attention_map = Attention(name=f"Attention_Layer_{i}")([feature_conv,feature_conv])
        #     print(f"attention_map.shape: {attention_map.shape}")

        #     feature_conv_attentioned = Multiply(name=f"Multiply_Apply_Attention_{i}")([feature_conv, attention_map])
        #     print(f"feature_conv_attentioned.shape: {feature_conv_attentioned.shape}")

        #     conv_layers.append(feature_conv_attentioned)

        #     # Apply the feature extraction pyramid
        #     if mp["FEATURE_PYRAMID_START_INDEX"] <= i:
        #       # Apply a 1x1 convolution to align the channel depth
        #       if feature_conv_attentioned.shape[-1] != finalFilters:
        #         aligned_layer = Conv1D(filters=finalFilters,
        #                               kernel_size=1,
        #                               strides=1,
        #                               padding="same",
        #                               name=f"Channel_Depth_Alignment_{i}")(feature_conv_attentioned)
        #       else:
        #         aligned_layer = feature_conv_attentioned

        #       aligned_layers.append(aligned_layer)

        #   # Go top-down through the aligned_layers to create the feature_map_layers
        #   for i in range(mp["CNN_EXTRACTOR_LAYERS"]-1, mp["FEATURE_PYRAMID_START_INDEX"]-1, -1):
        #     aligned_layers_index = i - mp["FEATURE_PYRAMID_START_INDEX"]
        #     aligned_layer = aligned_layers[aligned_layers_index]

        #     print(f"Building feature_map_layers, step {i}. Shape of aligned_layer: {aligned_layer.shape}")

        #     # The highest-filtered layer is taken as feature map directly
        #     if i == mp["CNN_EXTRACTOR_LAYERS"]-1:
        #       feature_map_layers.append(aligned_layer)
        #       anti_aliased_layers.append(feature_map_layers[-1])
        #     else:
        #       # Take the last feature_map_layer and scale it by two
        #       upsampled = UpSampling1D(size=2,
        #                                name=f"Pyramid_Upsampling_{i}")(feature_map_layers[-1])

        #       # Add the aligned_layer
        #       added = Add(name=f"Pyramid_Add_{i}")([upsampled, aligned_layer])

        #       # Append as new feature_map_layer
        #       feature_map_layers.append(added)

        #       # Apply a convolution with a kernel size of 3 to "reduce the aliasing effect"
        #       anti_aliased_layer = Conv1D(filters=feature_map_layers[-1].shape[-1],
        #                                   kernel_size=3,
        #                                   strides=1,
        #                                   padding="same",
        #                                   name=f"Anti_Alias_{i}")(feature_map_layers[-1])

        #       anti_aliased_layers.append(anti_aliased_layer)

        #     # Helper storage to keep pyramid index consistent, also in predictor/regressor
        #     anti_aliased_pyramid_indices.append(i)

        #   # Apply the predictor head to each feature dimension layer
        #   for n in range(len(anti_aliased_layers)):
        #     predictor_input = anti_aliased_layers[n]

        #     # Get the pyramid index
        #     pyramid_index = anti_aliased_pyramid_indices[n]

        #     # Permute the Conv output back
        #     predictor_input = Permute((2, 1), name=f"PermutePredictorInput_{pyramid_index}")(predictor_input)

        #     predictor = LSTM(units=mp["HEAD_LSTM_SIZE"],
        #                      name=f"Predictor_Head_{pyramid_index}_LSTM")(predictor_input)

        #     # Direction and derivation regressor
        #     regressor = Dense(units=mp["HEAD_DENSE_SIZE"],
        #                       name=f"Predictor_Head_{pyramid_index}_Dense_Regressor",
        #                       activation='relu')(predictor)

        #     regressor_layers.append(regressor)

        #   # Add all regressors together
        #   regressor_conced = Concatenate(name="Concatenate_regressors")(regressor_layers)
        #   #regressor_conced = Dense(regressor_conced.shape[1], name="Combined_Regressor_1")(regressor_conced)
        #   #regressor_conced = Dense(regressor_conced.shape[1], name="Combined_Regressor_2")(regressor_conced)

        #   # The output are two values (direction and derivation) in the range [-1.0, 1.0]
        #   output = Dense(2, activation="tanh", name="Output")(regressor_conced)
        #   outputs = [output]

        #   # Combine it all into a model object
        #   model = Model(inputs=inputTicksAndIndicators, outputs=outputs, name=mp["NAME"] + "_" + str(mp["VERSION"]))

        #   return model, mp

        # model, model_config = CreateModelFPNWithAttention()
        # print(model_config)
        # model.summary(line_length=220)

        # Load the model structure and the weights
        with tf.device("CPU:0"):
            self.model = tf.keras.models.load_model(modelPath)
            self.model.summary(line_length=200)

    """# Use the model to predict the future"""

    def predict(self, tickDF: pd.DataFrame):
        """
        Todo: Improve doku, no training here
        ---
        # Prepare data source



        For training a neural network, first the data source has to be prepared. For this purpose, the method `FileListToDataStream` from the `DataStreamCreator` class is used. This method creates a stream of `X-Block` and `y-data` arrays out of a list of .csv file names, pointing to tick tables (called `EXAMPLE_FILE_PATHS` in this example). For details about `X-Blocks` and `y-data`, please refer to the documentation of the `XBlockGenerator` and the `YDataGenerator` under https://github.com/girsigit/CryptoCrystalBall/tree/main/DataStreamCreator.

        <br>

        As y values for training the ML network the possible future gain and it derivation will be used. The y data type `PARAM_DICT_TEMPLATE_Y_DATA_TYPE_PAST_FUTURE_GAIN` will provide both past and future gain, but the model will only be trained on the future gain, as the past gain can be easily calculated directly, also in a live application.
        """

        Y_TYPE_DICT = copy.deepcopy(
            self.DataStreamCreator.YDataGenerator.PARAM_DICT_TEMPLATE_Y_DATA_TYPE_PAST_FUTURE_GAIN)
        Y_TYPE_DICT["gain_timespan"] = 60

        # Sort the tickDF
        tickDFlocal = copy.deepcopy(tickDF)
        tickDFlocal.sort_index(inplace=True)

        # Save the tickDF as temporary file
        # This is requried, as it has to be loaded as a file by the `FileListToDataStream` method
        tickDFtempfile = tempfile.NamedTemporaryFile(mode="w")

        # Acutally write the data
        tickDFlocal.to_csv(tickDFtempfile)

        # Set the buffer pointer back to position 0
        tickDFtempfile.seek(0)

        # Get the X blocks using a python generator
        # The batch size if the whole table (minus X_BLOCK_LENGHT), the blocks are cropped afterwards to the necessary amount
        # This is done to ensure stability of the indicators
        dataStream = self.DataStreamCreator.FileListToDataStream(fileList=[tickDFtempfile.name],
                                                                 batch_size=tickDFlocal.shape[0] -
                                                                 self.X_BLOCK_LENGHT,
                                                                 X_Block_lenght=self.X_BLOCK_LENGHT,
                                                                 y_type_dict=Y_TYPE_DICT,
                                                                 shuffle=False,
                                                                 parallel_generators=1,
                                                                 random_seed=42,
                                                                 **self.DATA_STREAM_PARAMETERS
                                                                 )

        # Get one batch (the dataset contains only one batch)
        ne = next(dataStream)
        X_blocks = ne['X']

        # Crop the X-Blocks, as only the number of "INDICATOR_MINMAX_PERIOD" X-Blocks is required
        X_blocks = X_blocks[-self.INDICATOR_MINMAX_PERIOD:, :, :]

        print(f"X_blocks.shape after crop: {X_blocks.shape}")

        # Predict the future
        p = self.model.predict(X_blocks, verbose=0)

        # Store the prediction results in nicely named variables
        p_future = p[:, 0]
        p_future_derivation = p[:, 1]

        return {
            "p_future": p_future,
            "p_future_derivation": p_future_derivation
        }


if __name__ == "__main__":
    print("Running as main, doing a test load and prediction..")

    """# Load the dataset
  # Todo: Shall not be a file, but a DataFrame as input
  """

    FILE_TO_PREDICT = '/content/dataset/ETF/tickdata/ticks/DE0002635265.csv'

    tickDF = pd.read_csv(FILE_TO_PREDICT)

    pc = PredictionCalculator()

    for i in range(10):
        p = pc.predict(tickDF)

    print(p)
