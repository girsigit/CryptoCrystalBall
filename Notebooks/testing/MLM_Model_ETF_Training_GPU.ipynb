{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RIbOPenP-I_d"
   },
   "source": [
    "# Mount drive and bucket\n",
    "Todo: Remove in public version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "GHybPwDjX1gZ",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Check if the notebook is run in Google Colab\n",
    "import sys\n",
    "\n",
    "COLAB = 'google.colab' in sys.modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_io.TextIOWrapper name='/content/bigdata/nb_20230227_0945.log' mode='a+' encoding='UTF-8'>\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(60000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 60 seconds\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import datetime\n",
    "import logging\n",
    "\n",
    "nblog = open(f\"/content/bigdata/nb_{datetime.datetime.utcnow().strftime('%Y%m%d_%H%M')}.log\", \"a+\")\n",
    "print(nblog)\n",
    "sys.stdout.echo = nblog\n",
    "sys.stderr.echo = nblog\n",
    "\n",
    "#get_ipython().log.handlers[0].stream = nblog\n",
    "#get_ipython().log.setLevel(logging.INFO)\n",
    "\n",
    "%autosave 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sK6Uuoy5qsua",
    "outputId": "d29d48f5-a2e5-40f9-927d-002d32fd48f9"
   },
   "outputs": [],
   "source": [
    "# if COLAB:\n",
    "#   from google.colab import drive\n",
    "#   drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "MTJ7bYMtHmvS"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run the command!\n"
     ]
    }
   ],
   "source": [
    "if COLAB:\n",
    "  from google.colab import auth\n",
    "  auth.authenticate_user()\n",
    "else:\n",
    "    print(\"Run the command!\")\n",
    "  #Todo #bring the command inside the notebook\n",
    "  #run this terminal inside docker: gcloud auth login b.girsule@gmail.com --no-launch-browser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "DOScyXpJws23"
   },
   "outputs": [],
   "source": [
    "# Todo: Check if possible in local docker\n",
    "# from google.cloud import storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "t9dbL-PU-okV",
    "outputId": "14e73bf6-881d-4bc0-96f4-8a1b79cae570"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-27 09:45:47.879870: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-27 09:45:48.005076: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-02-27 09:45:48.640168: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-27 09:45:48.640225: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-27 09:45:48.640234: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF Version is 2.10.0, ok!\n"
     ]
    }
   ],
   "source": [
    "# Check if the tf version is 2.10.0, this is required to use the 'ignore_class' in the  SparseCategoricalCrossentropy\n",
    "import tensorflow as tf\n",
    "\n",
    "if '2.10.0' != tf.__version__:\n",
    "  !pip uninstall tensorflow -y\n",
    "  !pip install tensorflow-gpu==2.10.0\n",
    "  please_restart_the_runtime\n",
    "else:\n",
    "  print(\"TF Version is 2.10.0, ok!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "FYePtDVpqtkN"
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "# import tensorflow_gcs_config\n",
    "from tensorflow.python.lib.io import file_io\n",
    "\n",
    "from keras.layers import Input, Dense, Flatten #, ReLU, Add, Flatten, Concatenate, LayerNormalization, UpSampling2D, Activation, LSTM, Multiply, Dropout, Reshape, Permute, BatchNormalization, MaxPooling1D, AveragePooling1D, MaxPooling3D, AveragePooling2D, LayerNormalization, MaxPooling2D\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "pxa3Ug_JplIq"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "EcBnUrFKqyCK"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "R_3vswfeRqmj"
   },
   "outputs": [],
   "source": [
    "# Set the google cloud bucket data\n",
    "project_id = 'tweetprediction'\n",
    "bucket_name = 'crypto_nlp_training'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "X3s3eDubSFaJ",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set the checkpoint path for saving train progress\n",
    "if COLAB:\n",
    "    CHECKPOINT_PATH = f\"gs://{bucket_name}/chk/\"\n",
    "else:\n",
    "    CHECKPOINT_PATH = f\"/content/bigdata/chk/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8rvlsLwbpmWJ",
    "outputId": "12f0ff94-d55c-449f-f101-c4581499db7d"
   },
   "outputs": [],
   "source": [
    "# Check if the notebook is run in google colab, if so, clone the repo\n",
    "if COLAB:\n",
    "    print(\"Running in Colab\")\n",
    "\n",
    "    # Clone the whole repo to get all data and code if not already done\n",
    "    if not os.path.exists(\"/content/CryptoCrystalBall\"):\n",
    "      !git clone https://github.com/girsigit/CryptoCrystalBall\n",
    "\n",
    "      # cd into the notebooks directory --> Necessary to match all paths for importing\n",
    "    #%cd /content/CryptoCrystalBall/JupyterDocker/notebooks\n",
    "    %cd /content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "q9OmJ6vFthwG"
   },
   "outputs": [],
   "source": [
    "# Try importing the Ta-Lib library, if this fails, try to install it and\n",
    "# import it again afterwards\n",
    "try:\n",
    "    import talib\n",
    "except:\n",
    "    !wget http://prdownloads.sourceforge.net/ta-lib/ta-lib-0.4.0-src.tar.gz\n",
    "    !tar -xzvf ta-lib-0.4.0-src.tar.gz\n",
    "    %cd ta-lib\n",
    "    !./configure --prefix=/usr\n",
    "    !make\n",
    "    !make install\n",
    "    !pip install Ta-Lib\n",
    "    %cd ..\n",
    "\n",
    "    import talib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "2orTUN099zyA",
    "tags": []
   },
   "outputs": [],
   "source": [
    "try:\n",
    "  from transformers import TFRobertaModel, RobertaConfig\n",
    "except:\n",
    "  # Important!: Version 4.23 does not work on TPU\n",
    "  !pip install transformers==4.22\n",
    "\n",
    "  from transformers import TFRobertaModel, RobertaConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip uninstall -y tensorboard-plugin-profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qfAsp4TWHivL",
    "outputId": "a25fdba4-ad57-40a3-f725-7d4ed114d38b",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Required to do profiling\n",
    "# !pip install tensorboard-plugin-profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "axPYAbN9upgY",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nbt7oQxzL2Zy"
   },
   "source": [
    "---\n",
    "# Add custom import path for DataStreamCreator and IndicatorCalculator\n",
    "\n",
    "These libs are not in the standard python directory, so their paths have to be added to the import paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ICDL0OwbL2Zz",
    "outputId": "41c7541e-3a1e-4035-f2f3-182fed452a8e",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['', 'content']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Get the current directory\n",
    "# current_dir = os.getcwd()\n",
    "# current_dir_splitted = current_dir.split(os.sep)\n",
    "\n",
    "# Todo: is inside /content/CB in local docker\n",
    "current_dir_splitted = [\"\", \"content\"]\n",
    "current_dir_splitted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JJ8l6O2gL2Z1",
    "outputId": "de6d884a-f4be-47e2-c808-eeac3448580c",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dsc_dir: /content/CryptoCrystalBall/DataStreamCreator\n",
      "ind_dir: /content/CryptoCrystalBall/IndicatorCalculator\n"
     ]
    }
   ],
   "source": [
    "# Create the import directories for the DataStreamCreator and the IndicatorCalculator\n",
    "dsc_dir = '/content/CryptoCrystalBall/DataStreamCreator'\n",
    "print(f\"dsc_dir: {dsc_dir}\")\n",
    "\n",
    "ind_dir = '/content/CryptoCrystalBall/IndicatorCalculator'\n",
    "print(f\"ind_dir: {ind_dir}\")\n",
    "\n",
    "# Add them to the import paths\n",
    "sys.path.insert(0, dsc_dir)\n",
    "sys.path.insert(0, ind_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "iqyTbcZDttLT",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import the actual classes\n",
    "from IndicatorCalculator import IndicatorCalculator\n",
    "import DataStreamCreator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zPsG4dqRL2Z5"
   },
   "source": [
    "---\n",
    "# Define all the parameters and variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5J8ODl45L2Z6",
    "outputId": "690c2801-687e-47fe-cefc-616e029a62a5",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA_PATH: /content/DemoData\n"
     ]
    }
   ],
   "source": [
    "# Define the tick data path\n",
    "DATA_PATH = os.path.join(os.sep, *current_dir_splitted, 'DemoData')\n",
    "print(f\"DATA_PATH: {DATA_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7TUeLGiOL2Z7",
    "outputId": "00651843-f462-4c20-e6cc-7cb0d7cd6d23",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMG_SAVE_PATH: /content/Documentation/Images\n"
     ]
    }
   ],
   "source": [
    "# Define the chart image save path\n",
    "IMG_SAVE_PATH = os.path.join(os.sep, *current_dir_splitted, 'Documentation', 'Images')\n",
    "print(f\"IMG_SAVE_PATH: {IMG_SAVE_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "o23rkki9ttLZ",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define a global random seed\n",
    "RANDOM_SEED = 42+27\n",
    "\n",
    "# Set the seed in np\n",
    "np.random.seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "g9gBeRtnxKMD",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# X_BLOCK_LENGHT defines how far into the past a 'slice of a chart' shall be\n",
    "# See: https://github.com/girsigit/CryptoCrystalBall/tree/main/DataStreamCreator#xblockgenerator\n",
    "X_BLOCK_LENGHT = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "sh5dsBKr5Ko-",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# How many examples shall be processed at the same time, limited by GPU memory\n",
    "BATCH_SIZE = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "J331jHk-u345",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# A fixed number of features is used\n",
    "FEATURES = 160"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "1JVT1Z2U0lW8",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Finanical indicator timespans\n",
    "# See: https://github.com/girsigit/CryptoCrystalBall/tree/main/IndicatorCalculator\n",
    "SHORTSPAN = 7\n",
    "MIDSPAN = 38\n",
    "LONGSPAN = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "AnNz-Oke3J3p",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Additional settings for the data stream\n",
    "# For this notebook, the calculation of pattern indicators is turned off\n",
    "DATA_STREAM_PARAMETERS = {\n",
    "    \"calcPatternIndicators\": False, # No patterns are used\n",
    "    \"calcVolumeInidators\": False, # No volume indicators, these are wide spread and may disturb the classifer\n",
    "    \"dropna\": True # Drop all tick/indicator table rows containing nan values instead of just replacing them by 0 (which would lead to wrong predictions)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "GKkv21lAxYEP",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# NLP token configuration\n",
    "BOS_TOKEN_ID = 0\n",
    "PAD_TOKEN_ID = 1\n",
    "EOS_TOKEN_ID = 2\n",
    "MASK_TOKEN_ID = 3\n",
    "\n",
    "MLM_MASK_FACTOR = 0.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "V5P8Nbn7F5CS",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Vocab size configuration\n",
    "# The feature vector to integer classifier model has a 5 digit output, therefore the vocab size would be 100000\n",
    "# As this is too much, the categories are rounded --> Todo: Create better classifier model\n",
    "\n",
    "VOCAB_SIZE = 10000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7xXpDFe9ROVQ"
   },
   "source": [
    "# Load the train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "b2EO18ZmppNe",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Check if the dataset already has been copy, if not, copy it\n",
    "if not os.path.exists(\"/content/dataset\") or not os.path.exists(\"/content/dataset/Train\"):\n",
    "  !mkdir /content/dataset\n",
    "  !mkdir /content/dataset/Train\n",
    "  !gsutil -m cp -r gs://cryptocrystalball_public/CryptoDataset/Hourly/significant_currencies.txt /content/dataset/significant_currencies.txt\n",
    "  !gsutil -m cp -r gs://cryptocrystalball_public/CryptoDataset/Hourly/Train/* /content/dataset/Train/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2sRVckzNtbZL",
    "outputId": "5cfd2c06-7823-40b3-eea8-2dbc3f51df57",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 121 significant files names.\n"
     ]
    }
   ],
   "source": [
    "#@markdown ### Use only significant currencies\n",
    "#@markdown Load a manually defined list of significant currencies (`significant_currencies.txt`).\n",
    "#@markdown This list contains no currencies which little or no volume or price movement, to\n",
    "#@markdown avoid training on data sample which would never be used to trade on in a real \n",
    "#@markdown application.\n",
    "\n",
    "#@markdown If enabled, only currency pairs with the base currency USDT are laoded,\n",
    "#@markdown this is important to prevent interference between different cryptocurrencies.\n",
    "#@markdown For example, in `BTC-ETH.csv`, there is influence of both the BTC and the ETH price, but we want to predict trade signals based on a 'real' currency (USDT is kind of the same as USD).\n",
    "\n",
    "significant_only = True #@param {type:\"boolean\"}\n",
    "\n",
    "if significant_only:\n",
    "  with open(\"/content/dataset/significant_currencies.txt\") as f:\n",
    "    SIGNIFICANT_CURRS = f.read().splitlines()\n",
    "\n",
    "  print(f\"Loaded {len(SIGNIFICANT_CURRS)} significant files names.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dlNAUwUTtdBE",
    "outputId": "3c614762-758a-444f-dc86-e86527a6c0ca",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The train dataset contains 121 files.\n",
      "['/content/dataset/Train/1INCH-USDT.csv', '/content/dataset/Train/4ART-USDT.csv', '/content/dataset/Train/AAVE-USDT.csv']\n"
     ]
    }
   ],
   "source": [
    "# Get train file names - Only pick the ones ending with -USDT to prevent\n",
    "# influence between different currencies\n",
    "TRAIN_PATH = \"/content/dataset/Train\"\n",
    "\n",
    "# Get all file names\n",
    "TRAIN_FILES = [os.path.join(TRAIN_PATH,f) for f in listdir(TRAIN_PATH) if isfile(join(TRAIN_PATH, f)) and \".csv\" in f ]\n",
    "\n",
    "# Filter for significant currencies only\n",
    "if significant_only:\n",
    "  TRAIN_FILES = [f for f in TRAIN_FILES if f.split(\"/\")[-1].replace(\".csv\",\"\") in SIGNIFICANT_CURRS]\n",
    "\n",
    "# Filter for USDT-based ones only\n",
    "TRAIN_FILES = [f for f in TRAIN_FILES if \"-USDT\" in f]\n",
    "\n",
    "# Sort them (as a stable basis for randomizing afterwards)\n",
    "TRAIN_FILES = sorted(TRAIN_FILES)\n",
    "\n",
    "print(f\"The train dataset contains {len(TRAIN_FILES)} files.\")\n",
    "print(TRAIN_FILES[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jhiJj_nfsmU0"
   },
   "source": [
    "# Load the classifier model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i8fWOHkSsMpz",
    "outputId": "1f57628e-dd3c-4395-a875-5d33279b4616",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Copy the feature vector to four float classifier model\n",
    "# Also copy the digit limits\n",
    "if not os.path.exists(\"/content/bottleneckToFourFloatModel.h5\"):\n",
    "  !gsutil -m cp -r gs://crypto_nlp_training/four_float_to_int/bottleneckToFourFloatModel.h5 /content/bottleneckToFourFloatModel.h5\n",
    "  !gsutil -m cp -r gs://crypto_nlp_training/four_float_to_int/digitLimits.npy /content/digitLimits.npy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3daDKjTltDTH",
    "outputId": "aee227b2-d87a-4651-bf6f-14d73592e862",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "Model: \"NNClassifierBottleneckToFourFloat\"\n",
      "____________________________________________________________________________________________________________________________________________________________________________________________________________________________\n",
      " Layer (type)                                                                                      Output Shape                                                                            Param #                          \n",
      "============================================================================================================================================================================================================================\n",
      " inputTicksAndIndicators (InputLayer)                                                              [(None, 512, 160)]                                                                      0                                \n",
      "                                                                                                                                                                                                                            \n",
      " tf.expand_dims_1 (TFOpLambda)                                                                     (None, 512, 160, 1)                                                                     0                                \n",
      "                                                                                                                                                                                                                            \n",
      " permute_1 (Permute)                                                                               (None, 512, 1, 160)                                                                     0                                \n",
      "                                                                                                                                                                                                                            \n",
      " DepthwiseConv2DInput (DepthwiseConv2D)                                                            (None, 512, 1, 160)                                                                     160                              \n",
      "                                                                                                                                                                                                                            \n",
      " tf.compat.v1.squeeze_1 (TFOpLambda)                                                               (None, 512, 160)                                                                        0                                \n",
      "                                                                                                                                                                                                                            \n",
      " Tanh_Input (Activation)                                                                           (None, 512, 160)                                                                        0                                \n",
      "                                                                                                                                                                                                                            \n",
      " tf.clip_by_value_1 (TFOpLambda)                                                                   (None, 512, 160)                                                                        0                                \n",
      "                                                                                                                                                                                                                            \n",
      " Bottleneck_1 (Dense)                                                                              (None, 512, 80)                                                                         12880                            \n",
      "                                                                                                                                                                                                                            \n",
      " Bottleneck_2 (Dense)                                                                              (None, 512, 40)                                                                         3240                             \n",
      "                                                                                                                                                                                                                            \n",
      " Bottleneck_3 (Dense)                                                                              (None, 512, 4)                                                                          164                              \n",
      "                                                                                                                                                                                                                            \n",
      "============================================================================================================================================================================================================================\n",
      "Total params: 16,444\n",
      "Trainable params: 16,444\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________________________________________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-27 09:45:50.417961: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-27 09:45:50.452420: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-27 09:45:50.452605: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-27 09:45:50.453087: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-27 09:45:50.454035: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-27 09:45:50.454201: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-27 09:45:50.454342: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-27 09:45:50.896791: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-27 09:45:50.897006: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-27 09:45:50.897163: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-27 09:45:50.897285: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 7386 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1070, pci bus id: 0000:01:00.0, compute capability: 6.1\n"
     ]
    }
   ],
   "source": [
    "# Load the model\n",
    "with tf.device('/CPU:0'):\n",
    "    fourFloatClassifierModel = keras.models.load_model(\"/content/bottleneckToFourFloatModel.h5\")\n",
    "    fourFloatClassifierModel.summary(line_length=220)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "2nLWLP3AB3gG",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load the digit limits\n",
    "digitLimits = np.load(\"/content/digitLimits.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0BeeQ7hvhXJF"
   },
   "source": [
    "# Load the class weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "05AAfFUyhZdg",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # # Copy the class weights\n",
    "# if not os.path.exists(\"/content/class_weights.npy\"):\n",
    "#   !gsutil -m cp -r gs://crypto_nlp_training/four_float_to_int/class_weights.npy /content/class_weights.npy\n",
    "\n",
    "# # Load the class weights\n",
    "# cwnp = np.load(\"/content/class_weights.npy\")\n",
    "\n",
    "# CLASS_WEIGHTS_DICT = {}\n",
    "\n",
    "# for i in range(cwnp.shape[0]):\n",
    "#   CLASS_WEIGHTS_DICT[i] = cwnp[i]\n",
    "\n",
    "# CLASS_WEIGHTS_DICT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J9cA0AKquwZ2"
   },
   "source": [
    "---\n",
    "# Prepare data source\n",
    "\n",
    "For training a neural network, first the data source has to be prepared. For this purpose, the method `FileListToDataStream` from the `DataStreamCreator` class is used. This method creates a stream of `X-Block` and `y-data` arrays out of a list of .csv file names, pointing to tick tables (called `EXAMPLE_FILE_PATHS` in this example). For details about `X-Blocks` and `y-data`, please refer to the documentation of the `XBlockGenerator` and the `YDataGenerator` under https://github.com/girsigit/CryptoCrystalBall/tree/main/DataStreamCreator.\n",
    "\n",
    "<br>\n",
    "\n",
    "Target values (y-data) from the data generator would not be necessary in this notebook, but since it cannot be switched off, the future direction and its derviation of the price have been chosen in `Y_TYPE_DICT` since they are not expensive to compute. A switch flag will be added in a future release."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pqze4dT8uz6V",
    "outputId": "985dae70-a5db-4972-bde2-b52e5b15c6b5",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dataType': 0,\n",
       " 'direction_ma_timespan': 200,\n",
       " 'derivation_ma_timespan': 100,\n",
       " 'direction_derivation_shift_span': 0}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set direction and derivation information as y target\n",
    "# Both y values (direction & derivation) are in the interval [-1.0,1.0]\n",
    "\n",
    "Y_TYPE_DICT = copy.deepcopy(DataStreamCreator.YDataGenerator.PARAM_DICT_TEMPLATE_Y_DATA_TYPE_DIRECTION_FLOAT)\n",
    "Y_TYPE_DICT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mlb37_K21h7j",
    "outputId": "473038a5-e93d-4ba8-e917-4da2ba5ba05f",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Calculate how many word shall be replaced\n",
    "# replace_index_number = int(np.round(X_BLOCK_LENGHT * MLM_MASK_FACTOR))\n",
    "# replace_index_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1gVe75Q51mHH",
    "outputId": "3dba72d9-8963-4293-b88c-f11421c1d0e3",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Create random indices, to replace 'words' with MASK_TOKEN_I\n",
    "# mask_positions = np.round(np.random.rand(BATCH_SIZE, replace_index_number) * X_BLOCK_LENGHT).astype(int)\n",
    "# print(mask_positions.shape)\n",
    "# mask_positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 336
    },
    "id": "vVctAErd2wzo",
    "outputId": "435f0cae-bf0a-4446-9078-bafb66dd4fbf",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# plt.hist(mask_positions.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "a7iuksPdCSrZ",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Method for normalizing the distribution of one digit\n",
    "def NormalizeDigitDistribution(dataIn, categoryLimitValues):\n",
    "  normalizedDistribution = np.empty(dataIn.shape)\n",
    "\n",
    "  for i, lim in enumerate(categoryLimitValues):\n",
    "    normalizedDistribution[(dataIn >= lim[0]) & (dataIn <= lim[1])] = i\n",
    "\n",
    "  return normalizedDistribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "d4kZzefRCRhB",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Method for converting a four-float vector into an integer 'word' in the range of 0-10000\n",
    "def ConvertFourFloatDataToWords(fourFloatIn, digitLimits):\n",
    "  # Normalize each digit\n",
    "  digitsNormalized = []\n",
    "\n",
    "  for digit in range(4):\n",
    "    digitsNormalized.append(\n",
    "        NormalizeDigitDistribution(fourFloatIn[:,:,digit], digitLimits[digit])\n",
    "        )\n",
    "    \n",
    "  # Combine the digits to one integer (creating the 'word')\n",
    "  intData = digitsNormalized[0] * 1000 + digitsNormalized[1] * 100 + digitsNormalized[2] * 10 + digitsNormalized[3]\n",
    "  intData = intData.astype(np.int32)  \n",
    "\n",
    "  del digitsNormalized\n",
    "\n",
    "  return intData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "S2e6q_2su26o",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# A python generator function has to be applied on the dataStream\n",
    "\n",
    "def pythonGeneratorMLMTraining():\n",
    "  # Initialize the FileListToDataStream generator\n",
    "  dataStreamTraining = DataStreamCreator.FileListToDataStream(fileList = TRAIN_FILES,\n",
    "                                                      batch_size = BATCH_SIZE,\n",
    "                                                      X_Block_lenght = X_BLOCK_LENGHT,\n",
    "                                                      y_type_dict=Y_TYPE_DICT,\n",
    "                                                      shuffle=True,\n",
    "                                                      parallel_generators = np.min([BATCH_SIZE, 8]),\n",
    "                                                      random_seed = RANDOM_SEED,\n",
    "                                                      **DATA_STREAM_PARAMETERS\n",
    "                                                      )\n",
    "  \n",
    "  # Calculate how many word shall be replaced\n",
    "  mask_number = int(np.round(X_BLOCK_LENGHT * MLM_MASK_FACTOR))\n",
    "  logging.info(f\"In each batch of X-Blocks, {mask_number*BATCH_SIZE} elements will be randomly masked. This is an average of {mask_number} per X-Block\")\n",
    "\n",
    "  # This while has to integrated into the FileListToDataStream method\n",
    "  while True:  \n",
    "    try:\n",
    "      ne = next(dataStreamTraining)\n",
    "      _X = ne['X']\n",
    "      _y = ne['y']\n",
    "\n",
    "      # Convert the X-Block into a sentence\n",
    "      with tf.device('/CPU:0'):\n",
    "        _X_extended = np.zeros((BATCH_SIZE, 512, FEATURES))\n",
    "        _X_extended[:,:X_BLOCK_LENGHT,:] = _X\n",
    "        \n",
    "        four_float_sentence_extended = fourFloatClassifierModel.predict(_X_extended, batch_size = BATCH_SIZE, verbose = 0)\n",
    "        int_sentence_extended = ConvertFourFloatDataToWords(four_float_sentence_extended, digitLimits)\n",
    "        \n",
    "        int_sentence = int_sentence_extended[:,:X_BLOCK_LENGHT]\n",
    "\n",
    "        # _X_sentence = intClassifierModel.predict(_X, batch_size = BATCH_SIZE, verbose = 0)\n",
    "\n",
    "      # Round to avoid too many categories\n",
    "      # Todo: Better classifier model!\n",
    "      # _X_sentence = np.round(_X_sentence / 10.0).astype(int)\n",
    "\n",
    "      # Create random indices, to replace 'words' with MASK_TOKEN_I\n",
    "#       mask_positions = np.round(np.random.rand(BATCH_SIZE, mask_number) * X_BLOCK_LENGHT * BATCH_SIZE).astype(int)\n",
    "#       mask_positions[mask_positions == X_BLOCK_LENGHT * BATCH_SIZE] -= 1  # Avoid the upper array limit\n",
    "\n",
    "#       # Mask the chosen tokens\n",
    "#       int_sentence_masked = np.array(int_sentence).flatten()\n",
    "#       int_sentence_masked[mask_positions] = MASK_TOKEN_ID\n",
    "#       int_sentence_masked = int_sentence_masked.reshape(int_sentence.shape)\n",
    "\n",
    "      # print(mask_positions[0,0])\n",
    "\n",
    "      # 'Remove' all tokens that shall not be predicted from the training y data (the full sentence), so that the network can focus on the missing tokens\n",
    "      # More precise: Setting them to -1 tells the loss function to ignore them\n",
    "      # int_sentence[int_sentence_masked != MASK_TOKEN_ID] = -1\n",
    "\n",
    "      # Not required here, as the network shall predict back its original input\n",
    "      # _y = ne['y']\n",
    "      \n",
    "      # Return the masked senteces as X data, the full ones are the y-data --> The network shall predict the missing tokens\n",
    "      yield (int_sentence, _y)\n",
    "    except StopIteration as si:\n",
    "      logging.warning(\"StopIteration in pythonGenerator\")\n",
    "      logging.warning(si)\n",
    "      return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FoTRNHyEvnyg",
    "outputId": "d7fb1944-9236-47c2-c749-8a999e6fe3e3",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<FlatMapDataset element_spec=(TensorSpec(shape=(40, 64), dtype=tf.int32, name=None), TensorSpec(shape=(40, 2), dtype=tf.float32, name=None))>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a Tensorflow dataset out of the python generator, which can be fed to the network\n",
    "tfGenTraining = tf.data.Dataset.from_generator(pythonGeneratorMLMTraining, \n",
    "                                               output_types = (tf.int32, tf.float32),\n",
    "                                               output_shapes=(\n",
    "                                                   (BATCH_SIZE, X_BLOCK_LENGHT),\n",
    "                                                   (BATCH_SIZE, 2)\n",
    "                                                   )\n",
    "                                               )\n",
    "tfGenTraining.prefetch(buffer_size=2)\n",
    "tfGenTraining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YST-Iwzsv4GO",
    "outputId": "5bcf6d64-6742-46d2-a6da-860fd98e47b2",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:File 'HXRO-USDT.csv' loaded, 120 left\n",
      "INFO:root:File 'NEO-USDT.csv' loaded, 119 left\n",
      "INFO:root:File 'MONA-USDT.csv' loaded, 118 left\n",
      "INFO:root:File 'VLX-USDT.csv' loaded, 117 left\n",
      "INFO:root:File 'RVN-USDT.csv' loaded, 116 left\n",
      "INFO:root:File 'ICA-USDT.csv' loaded, 115 left\n",
      "INFO:root:File 'CKB-USDT.csv' loaded, 114 left\n",
      "INFO:root:File 'GOLD-USDT.csv' loaded, 113 left\n",
      "INFO:root:In each batch of X-Blocks, 400 elements will be randomly masked. This is an average of 10 per X-Block\n"
     ]
    }
   ],
   "source": [
    "it = tfGenTraining.as_numpy_iterator()\n",
    "\n",
    "ne = next(it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fUxLLmbB3gu2",
    "outputId": "47b8b7f0-9e8e-4ca1-e7de-fe1619e0193a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4443, 4443, 4443, ..., 8257, 5246, 2323],\n",
       "       [4443, 4443, 4443, ..., 6548, 7557, 5446],\n",
       "       [4443, 4443, 4443, ..., 5320, 5320,  310],\n",
       "       ...,\n",
       "       [4443, 4443, 4443, ..., 5246, 2323, 3422],\n",
       "       [4443, 4443, 4643, ..., 7557, 5446, 3435],\n",
       "       [4443, 4443, 4443, ..., 2443, 1245, 2455]], dtype=int32)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ne[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wh8PxiukwI4r",
    "outputId": "08907604-1651-4f5e-9552-228b10bb71fb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ne[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 354
    },
    "id": "n7Ge9vX8C2q3",
    "outputId": "0dfd442e-7bcc-43fc-951c-3be50f20a210"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  49.,   87.,  202.,  139., 1425.,  129.,  117.,  111.,  142.,\n",
       "         159.]),\n",
       " array([  33. ,  995.4, 1957.8, 2920.2, 3882.6, 4845. , 5807.4, 6769.8,\n",
       "        7732.2, 8694.6, 9657. ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(ne[0].flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 372
    },
    "id": "5_UA09HxC48E",
    "outputId": "9e36f4da-0996-4cd8-d316-abee0fcf3e76"
   },
   "outputs": [],
   "source": [
    "# plt.hist(ne[1].flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3Ow2UkYNIB2X",
    "outputId": "c9667f3f-ddfd-423c-ab3e-fafb1db5b396"
   },
   "outputs": [],
   "source": [
    "# wurst = np.array(ne[1])\n",
    "# wurst[ne[0] != MASK_TOKEN_ID] = -1\n",
    "# wurst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LGFj4aix8P9y",
    "outputId": "c5a2d142-40b7-4f8a-c075-8f351858b62a"
   },
   "outputs": [],
   "source": [
    "# np.sum(ne[0][0,:] == 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "moBea0tTbFbX"
   },
   "source": [
    "---\n",
    "# Create the NLP model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7V1gTRpwWvV_",
    "outputId": "0eacc029-3de8-4c13-a15d-0852238cfac7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RobertaConfig {\n",
       "  \"attention_probs_dropout_prob\": 0.1,\n",
       "  \"bos_token_id\": 0,\n",
       "  \"classifier_dropout\": null,\n",
       "  \"eos_token_id\": 2,\n",
       "  \"hidden_act\": \"gelu\",\n",
       "  \"hidden_dropout_prob\": 0.1,\n",
       "  \"hidden_size\": 768,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"intermediate_size\": 3072,\n",
       "  \"layer_norm_eps\": 1e-12,\n",
       "  \"max_position_embeddings\": 65,\n",
       "  \"model_type\": \"roberta\",\n",
       "  \"num_attention_heads\": 12,\n",
       "  \"num_hidden_layers\": 12,\n",
       "  \"pad_token_id\": 1,\n",
       "  \"position_embedding_type\": \"absolute\",\n",
       "  \"transformers_version\": \"4.22.0\",\n",
       "  \"type_vocab_size\": 2,\n",
       "  \"use_cache\": true,\n",
       "  \"vocab_size\": 10000\n",
       "}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg = RobertaConfig()\n",
    "\n",
    "cfg.vocab_size = VOCAB_SIZE\n",
    "cfg.max_position_embeddings = X_BLOCK_LENGHT + 1\n",
    "\n",
    "cfg.bos_token_id = BOS_TOKEN_ID\n",
    "cfg.pad_token_id = PAD_TOKEN_ID\n",
    "cfg.eos_token_id = EOS_TOKEN_ID\n",
    "\n",
    "cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LE3ZxhjDuZmA",
    "outputId": "819b43b3-72b8-4f41-f8f3-286efc50804d"
   },
   "outputs": [],
   "source": [
    "# #@title CreateModelRobertaMLMTraining\n",
    "# def CreateModelRobertaMLMTraining():\n",
    "\n",
    "#   # A sentence as input\n",
    "#   inputSentence = Input(shape=(X_BLOCK_LENGHT), name='input', dtype='int32')\n",
    "  \n",
    "#   # The NLP model\n",
    "#   nlp = TFRobertaModel(cfg)(inputSentence)\n",
    "\n",
    "#   # A dense layer to predict back the full sentence\n",
    "#   predicted_sentence = Dense(VOCAB_SIZE, activation='softmax', name=\"Categories\")(nlp['last_hidden_state'])\n",
    "\n",
    "#   outputs = [predicted_sentence]\n",
    "\n",
    "#   # And combine it all in a model object\n",
    "#   model = Model(inputs=inputSentence, outputs=outputs, name='RobertaMLMTraining_1')\n",
    "\n",
    "#   return model\n",
    "\n",
    "# modelMLM = CreateModelRobertaMLMTraining()\n",
    "# modelMLM.summary(line_length=220)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"RobertaToDirDerv_ETF1\"\n",
      "____________________________________________________________________________________________________________________________________________________________________________________________________________________________\n",
      " Layer (type)                                                                                      Output Shape                                                                            Param #                          \n",
      "============================================================================================================================================================================================================================\n",
      " input (InputLayer)                                                                                [(None, 64)]                                                                            0                                \n",
      "                                                                                                                                                                                                                            \n",
      " CryptoRoberta (TFRobertaModel)                                                                    TFBaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=(None, 64, 768),       93378048                         \n",
      "                                                                                                    pooler_output=(None, 768),                                                                                              \n",
      "                                                                                                    past_key_values=None, hidden_states=None, attentions=None, cross_attentions=None)                                       \n",
      "                                                                                                                                                                                                                            \n",
      " FlattenNLP (Flatten)                                                                              (None, 49152)                                                                           0                                \n",
      "                                                                                                                                                                                                                            \n",
      " DirDerv (Dense)                                                                                   (None, 2)                                                                               98306                            \n",
      "                                                                                                                                                                                                                            \n",
      "============================================================================================================================================================================================================================\n",
      "Total params: 93,476,354\n",
      "Trainable params: 93,476,354\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________________________________________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#@title CreateModelRobertaToDirDerv\n",
    "def CreateModelRobertaToDirDerv():\n",
    "\n",
    "  # A sentence as input\n",
    "  inputSentence = Input(shape=(X_BLOCK_LENGHT), name='input', dtype='int32')\n",
    "  \n",
    "  # The NLP model\n",
    "  nlp = TFRobertaModel(cfg, name=\"CryptoRoberta\")(inputSentence)\n",
    "\n",
    "  # A dense layer to predict back the full sentence\n",
    "  nlpFlat = Flatten(name=\"FlattenNLP\")(nlp['last_hidden_state'])\n",
    "  dirDerv = Dense(2, activation='tanh', name=\"DirDerv\")(nlpFlat)\n",
    "\n",
    "  outputs = [dirDerv]\n",
    "\n",
    "  # And combine it all in a model object\n",
    "  model = Model(inputs=inputSentence, outputs=outputs, name='RobertaToDirDerv_ETF1')\n",
    "\n",
    "  return model\n",
    "\n",
    "model = CreateModelRobertaToDirDerv()\n",
    "model.summary(line_length=220)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# modelMLM.load_weights(\"/content/bigdata/chk/RobertaMLMTraining_1_GPU_512LB_10000VC_MaskedPrediction/cp_daily_valid_03_144000/model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# model.get_layer(\"CryptoRoberta\").set_weights(modelMLM.get_layer(\"tf_roberta_model\").get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# model.get_layer(\"CryptoRoberta\").trainable=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# model.save(\"/content/bigdata/RobertaToDirDerv_1_init.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.load_weights(\"/content/bigdata/RobertaToDirDerv_1_init.h5\")\n",
    "#model.load_weights(\"/content/bigdata/chk/RobertaToDirDerv_1_GPU_512LB_10000VC_MaskedPrediction/cp_daily_valid_00_18000/model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kXE8AjjoEWE4"
   },
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QfwL7EWInGWB"
   },
   "source": [
    "### Train strategy in the paper\n",
    "https://huggingface.co/roberta-base\n",
    "\n",
    "The model was trained on 1024 V100 GPUs for 500K steps with a batch size of 8K and a sequence length of 512. The optimizer used is Adam with a learning rate of 6e-4, 1=0.9\\beta_{1} = 0.91=0.9, 2=0.98\\beta_{2} = 0.982=0.98 and =1e6\\epsilon = 1e-6=1e6, a weight decay of 0.01, learning rate warmup for 24,000 steps and linear decay of the learning rate after."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "_jkOrQ01hZnE",
    "outputId": "afe655bf-d35c-4f71-ced0-d225a2ff6155"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'RobertaToDirDerv_ETF1_GPU_64LB_10000VC'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CHKPNT_NAME = f\"{model.name}_GPU_{X_BLOCK_LENGHT}LB_{VOCAB_SIZE}VC\"\n",
    "CHKPNT_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "id": "g0VmovApkwAB"
   },
   "outputs": [],
   "source": [
    "# Set an optimizer\n",
    "optimizer = Adam(\n",
    "    learning_rate=1e-04,\n",
    "    epsilon=1e-06,\n",
    "    beta_1=0.9,\n",
    "    beta_2=0.98,\n",
    "    decay=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "id": "yMoJi05f0JKp"
   },
   "outputs": [],
   "source": [
    "# # Create a masked loss to predict only the missing tokens\n",
    "# # https://stackoverflow.com/questions/56328140/how-do-i-implement-a-masked-softmax-cross-entropy-loss-function-in-keras\n",
    "\n",
    "# SCCE = tf.keras.losses.SparseCategoricalCrossentropy(reduction=tf.keras.losses.Reduction.NONE, from_logits=False)\n",
    "\n",
    "# def sparse_crossentropy_masked(y_true, y_pred):\n",
    "#   y_true_masked = tf.boolean_mask(y_true, tf.not_equal(y_true, -1))\n",
    "#   y_pred_masked = tf.boolean_mask(y_pred, tf.not_equal(y_true, -1))\n",
    "\n",
    "#   return tf.reduce_sum(SCCE(y_true_masked, y_pred_masked)) * (1. / BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "id": "mhCAE0Ujne49"
   },
   "outputs": [],
   "source": [
    "# # Create a masked loss to predict only the missing tokens\n",
    "# # https://stackoverflow.com/questions/56328140/how-do-i-implement-a-masked-softmax-cross-entropy-loss-function-in-keras\n",
    "\n",
    "# SCCE = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False)\n",
    "\n",
    "# def sparse_crossentropy_masked(y_true, y_pred):\n",
    "#   # y_true_masked = tf.boolean_mask(y_true, tf.not_equal(y_true, -1))\n",
    "#   # y_pred_masked = tf.boolean_mask(y_pred, tf.not_equal(y_true, -1))\n",
    "\n",
    "#   maskTensor = tf.not_equal(y_true, -1)\n",
    "#   a\n",
    "#   y_true_masked = y_true * tf.cast(maskTensor, tf.int32)\n",
    "#   y_pred_masked = y_pred * tf.cast(maskTensor, tf.float32)\n",
    "\n",
    "#   return SCCE(y_true_masked, y_pred_masked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "id": "AOLSygN7Ut7_"
   },
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer = optimizer,\n",
    "    loss = [\"mse\"], \n",
    "    metrics=[\"mae\"])\n",
    "\n",
    "# model.compile(\n",
    "#     optimizer = optimizer,\n",
    "#     loss = tf.keras.losses.SparseCategoricalCrossentropy(ignore_class=-1),\n",
    "#     metrics=None)\n",
    "\n",
    "# model.compile(\n",
    "#     optimizer = optimizer,\n",
    "#     loss = sparse_crossentropy_masked, \n",
    "#     metrics=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TFa0iWcaqli5",
    "outputId": "0ec595c6-7c5c-4723-8a2c-64d0d7a07f08"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"RobertaToDirDerv_ETF1\"\n",
      "____________________________________________________________________________________________________________________________________________________________________________________________________________________________\n",
      " Layer (type)                                                                                      Output Shape                                                                            Param #                          \n",
      "============================================================================================================================================================================================================================\n",
      " input (InputLayer)                                                                                [(None, 64)]                                                                            0                                \n",
      "                                                                                                                                                                                                                            \n",
      " CryptoRoberta (TFRobertaModel)                                                                    TFBaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=(None, 64, 768),       93378048                         \n",
      "                                                                                                    pooler_output=(None, 768),                                                                                              \n",
      "                                                                                                    past_key_values=None, hidden_states=None, attentions=None, cross_attentions=None)                                       \n",
      "                                                                                                                                                                                                                            \n",
      " FlattenNLP (Flatten)                                                                              (None, 49152)                                                                           0                                \n",
      "                                                                                                                                                                                                                            \n",
      " DirDerv (Dense)                                                                                   (None, 2)                                                                               98306                            \n",
      "                                                                                                                                                                                                                            \n",
      "============================================================================================================================================================================================================================\n",
      "Total params: 93,476,354\n",
      "Trainable params: 93,476,354\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________________________________________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary(line_length=220)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title CustomCallback\n",
    "class CustomCallback(tf.keras.callbacks.Callback):\n",
    "  def __init__(self, save_freq, val_freq, checkpoint_path, model_name, epoch_add=0):\n",
    "    self.save_freq = save_freq\n",
    "    self.val_freq = val_freq\n",
    "    self.checkpoint_path = checkpoint_path\n",
    "    self.model_name = model_name\n",
    "    self.current_epoch = 0\n",
    "    self.epoch_add = epoch_add\n",
    "\n",
    "  def on_epoch_begin(self, epoch, logs=None):\n",
    "    self.current_epoch = epoch + self.epoch_add\n",
    "    # keys = list(logs.keys())\n",
    "    # print(\"Start epoch {} of training; got log keys: {}\".format(epoch, keys))\n",
    "\n",
    "  def on_epoch_end(self, epoch, logs=None):\n",
    "    self.saveTheModel(-1, logs)\n",
    "\n",
    "  def on_train_batch_end(self, batch, logs=None):\n",
    "    self.saveTheModel(batch, logs)\n",
    "\n",
    "  def saveTheModel(self, batch, logs=None):\n",
    "    if (0 < batch and 0 == batch % self.save_freq) or (0 > batch):\n",
    "      logging.info(str(datetime.datetime.utcnow()))\n",
    "    \n",
    "      if 0 > batch:\n",
    "        _save_folder = os.path.join(self.checkpoint_path,\n",
    "                                    self.model_name,\n",
    "                                    \"cp_daily_valid_{:02d}_end\".format(self.current_epoch)\n",
    "                                    )\n",
    "      else:\n",
    "        _save_folder = os.path.join(self.checkpoint_path,\n",
    "                                    self.model_name,\n",
    "                                    \"cp_daily_valid_{:02d}_{:05d}\".format(self.current_epoch, batch)\n",
    "                                    )\n",
    "      \n",
    "      fp = os.path.join(_save_folder, \"model.h5\")\n",
    "      model.save(fp)\n",
    "      logging.info(f\"Saved model to '{fp}'\")\n",
    "      \n",
    "      # Save optimizer config\n",
    "      # c = copy.deepcopy(self.model.optimizer.get_config())\n",
    "\n",
    "      fp = os.path.join(_save_folder, \"c.pickle\")\n",
    "      with file_io.FileIO(fp, mode='wb+') as handle:\n",
    "        pickle.dump(self.model.optimizer.get_config(), handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "        \n",
    "      logging.info(f\"Saved optimizer config to '{fp}'\")\n",
    "\n",
    "      # Save optimizer weights\n",
    "      # w = copy.deepcopy(self.model.optimizer.get_weights())\n",
    "\n",
    "      fp = os.path.join(_save_folder, \"w.pickle\")\n",
    "      with open(fp, \"wb\") as handle:\n",
    "        # with file_io.FileIO(fp, mode='wb+') as handle:\n",
    "        pickle.dump(self.model.optimizer.get_weights(), handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "      \n",
    "      logging.info(f\"Saved optimizer weights to '{fp}'\")\n",
    "        \n",
    "      logging.info(f\"Did a gc collect: {gc.collect()}\")\n",
    "\n",
    "    # if 0 < batch and 0 == batch % self.val_freq:\n",
    "    #   print(\"-------------------------EVAL-------------------------\")\n",
    "    #   model.evaluate(tfgenTest)\n",
    "    #   print(\"\\n-------------------------EVAL-------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25203"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "id": "TczoGFYOStmg"
   },
   "outputs": [],
   "source": [
    "# CLASS_WEIGHTS_DICT = None\n",
    "# CLASS_WEIGHTS_DICT = {}\n",
    "\n",
    "# for i, cw in enumerate(CLASS_WEIGHTS[0,0,:]):\n",
    "#   CLASS_WEIGHTS_DICT[i] = cw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "id": "JyggHiDGNTEX"
   },
   "outputs": [],
   "source": [
    "epoch_add = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "id": "-pJ08IBN7cgB"
   },
   "outputs": [],
   "source": [
    "CALLBACK_EVERY_N_BATCHES = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "id": "CuGT0rFvzH1n"
   },
   "outputs": [],
   "source": [
    "cc = CustomCallback(checkpoint_path = CHECKPOINT_PATH,\n",
    "                    model_name = CHKPNT_NAME,\n",
    "                    save_freq = CALLBACK_EVERY_N_BATCHES,\n",
    "                    val_freq = CALLBACK_EVERY_N_BATCHES,\n",
    "                    epoch_add = epoch_add)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "id": "LuuH0xBKGE1g",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "id": "0noHN-UeSCQ-"
   },
   "outputs": [],
   "source": [
    "%reload_ext tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u7xAyqce3qYJ"
   },
   "source": [
    "The TensorBoard UI is displayed in a browser window. In this colab, perform the following steps to prepare to capture profile information.\n",
    "1.  Click on the dropdown menu box on the top right side and scroll down and click PROFILE. A new window appears that shows: **No profile data was found** at the top.\n",
    "1.  Click on the CAPTURE PROFILE button. A new dialog appears. The top input line shows: **Profile Service URL or TPU name**. Copy and paste the Profile Service URL (the service_addr value shown before launching TensorBoard) into the top input line. While still on the dialog box, start the training with the next step.\n",
    "1.  Click on the next colab cell to start training the model.\n",
    "1.  Watch the output from the training until several epochs have completed. This allows time for the profile data to start being collected. Return to the dialog box and click on the CAPTURE button. If the capture succeeds, the page will auto refresh and redirect you to the profiling results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "mpUXurxwSp_3",
    "outputId": "8d57d014-c4bc-49e1-a434-179a5be0529c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/content/bigdata/log/RobertaToDirDerv_ETF1_GPU_64LB_10000VC20230227-094600'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Todo: Create more elegant solution\n",
    "log_dir = \"gs://ticks_with_indicators_with_volume/logs/TPU/\" + CHKPNT_NAME + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "if not COLAB:\n",
    "    log_dir = os.path.join(\"/content/bigdata/log\",log_dir.split(\"/\")[-1])\n",
    "\n",
    "log_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "He5Jna87RsPN",
    "outputId": "efab0e32-2cca-4c12-bc49-8cd1fb7492b9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/content/bigdata/log/RobertaToDirDerv_ETF1_GPU_64LB_10000VC20230227-094600'"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "id": "_X-ab7uc3gTt"
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(\n",
    "    log_dir=log_dir,\n",
    "    histogram_freq=1,\n",
    "    update_freq=CALLBACK_EVERY_N_BATCHES    \n",
    "    )\n",
    "#profile_batch=(5,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# CLASS_WEIGHTS_DICT = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.load_weights(\"/content/bigdata/chk/RobertaMLMTraining_1_GPU_512LB_10000VC_MaskedPrediction/cp_daily_valid_01_end/model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.optimizer.learning_rate = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-7ecbe6520a5be5ca\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-7ecbe6520a5be5ca\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir $log_dir --host 0.0.0.0 --port 6006"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DcUTfAbHb2FW",
    "outputId": "a6b2d3a2-f00f-4733-fd4b-268b42e7f2a6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:File 'HXRO-USDT.csv' loaded, 120 left\n",
      "INFO:root:File 'NEO-USDT.csv' loaded, 119 left\n",
      "INFO:root:File 'MONA-USDT.csv' loaded, 118 left\n",
      "INFO:root:File 'VLX-USDT.csv' loaded, 117 left\n",
      "INFO:root:File 'RVN-USDT.csv' loaded, 116 left\n",
      "INFO:root:File 'ICA-USDT.csv' loaded, 115 left\n",
      "INFO:root:File 'CKB-USDT.csv' loaded, 114 left\n",
      "INFO:root:File 'GOLD-USDT.csv' loaded, 113 left\n",
      "INFO:root:In each batch of X-Blocks, 400 elements will be randomly masked. This is an average of 10 per X-Block\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     98/Unknown - 55s 503ms/step - loss: 1.0874 - mae: 0.9688"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:File 'CNTM-USDT.csv' loaded, 112 left\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    473/Unknown - 245s 505ms/step - loss: 0.9848 - mae: 0.9229"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:File 'BAND-USDT.csv' loaded, 111 left\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    932/Unknown - 477s 506ms/step - loss: 1.1306 - mae: 0.9875"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:File 'IGNIS-USDT.csv' loaded, 110 left\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   1382/Unknown - 706s 507ms/step - loss: 1.1138 - mae: 0.9802"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:File 'STRK-USDT.csv' loaded, 109 left\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   1561/Unknown - 797s 507ms/step - loss: 1.1227 - mae: 0.9832"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:File 'EDG-USDT.csv' loaded, 108 left\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   1867/Unknown - 952s 507ms/step - loss: 1.1151 - mae: 0.9763"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:File 'STEEM-USDT.csv' loaded, 107 left\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   1956/Unknown - 998s 507ms/step - loss: 1.1117 - mae: 0.9743"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:File 'RFOX-USDT.csv' loaded, 106 left\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   1976/Unknown - 1008s 507ms/step - loss: 1.1107 - mae: 0.9737"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:File 'BOA-USDT.csv' loaded, 105 left\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   2175/Unknown - 1109s 507ms/step - loss: 1.0948 - mae: 0.9664"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:File 'DVI-USDT.csv' loaded in retry loop, 104 left\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   2297/Unknown - 1171s 507ms/step - loss: 1.0932 - mae: 0.9659"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:File 'ZEC-USDT.csv' loaded, 103 left\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   2310/Unknown - 1180s 508ms/step - loss: 1.0927 - mae: 0.9657"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:File 'HNS-USDT.csv' loaded, 102 left\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   2345/Unknown - 1198s 508ms/step - loss: 1.0891 - mae: 0.9639"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:File 'ADABULL-USDT.csv' loaded, 101 left\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   2409/Unknown - 1231s 508ms/step - loss: 1.0891 - mae: 0.9641"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:File 'OXEN-USDT.csv' loaded, 100 left\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   2492/Unknown - 1273s 509ms/step - loss: 1.0900 - mae: 0.9645"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:File 'ELA-USDT.csv' loaded, 99 left\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   3726/Unknown - 1898s 508ms/step - loss: 1.1319 - mae: 0.9818"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:File 'CRFI-USDT.csv' loaded, 98 left\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   3840/Unknown - 1956s 508ms/step - loss: 1.1304 - mae: 0.9808"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:File 'AAVE-USDT.csv' loaded, 97 left\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   3859/Unknown - 1966s 508ms/step - loss: 1.1304 - mae: 0.9809"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:File 'TFC-USDT.csv' loaded, 96 left\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   3981/Unknown - 2028s 508ms/step - loss: 1.1330 - mae: 0.9818"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:File 'SUKU-USDT.csv' loaded, 95 left\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   4309/Unknown - 2193s 508ms/step - loss: 1.1330 - mae: 0.9805"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:File 'GAME-USDT.csv' loaded, 94 left\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   4363/Unknown - 2221s 508ms/step - loss: 1.1316 - mae: 0.9801"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:File 'XRP-USDT.csv' loaded, 93 left\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   4566/Unknown - 2324s 508ms/step - loss: 1.1274 - mae: 0.9785"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:File 'UMA-USDT.csv' loaded, 92 left\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   4639/Unknown - 2362s 508ms/step - loss: 1.1295 - mae: 0.9796"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[86], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtfGenTraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m          \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m200\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m          \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m          \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mtensorboard_callback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcc\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/engine/training.py:1564\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1556\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1557\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1558\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1561\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1562\u001b[0m ):\n\u001b[1;32m   1563\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1564\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1565\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1566\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    944\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    945\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    946\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 947\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stateless_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    948\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    949\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    950\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    951\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/function.py:2496\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2493\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m   2494\u001b[0m   (graph_function,\n\u001b[1;32m   2495\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2496\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2497\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/function.py:1862\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1858\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1859\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1860\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1861\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1862\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1863\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1864\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1865\u001b[0m     args,\n\u001b[1;32m   1866\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1867\u001b[0m     executing_eagerly)\n\u001b[1;32m   1868\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    497\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    498\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 499\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    505\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    506\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    507\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[1;32m    508\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    511\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[1;32m    512\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(tfGenTraining,\n",
    "          epochs=200,\n",
    "          verbose = 1,\n",
    "          callbacks=[tensorboard_callback, cc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2Nh12BlMEOBF",
    "outputId": "8bb69110-e6ee-48e6-e62b-1547db0c5ee4"
   },
   "outputs": [],
   "source": [
    "# copy_filenames = ['gs://crypto_nlp_training/chk/RobertaMLMTraining_1_GPU_512LB_10000VC_MaskedPrediction/cp_daily_valid_01_06000/model.h5'\n",
    "#                   ]\n",
    "\n",
    "# for p in copy_filenames:\n",
    "#   fn = p.split(\"/\")[-1]\n",
    "#   cpnt = p.split(\"/\")[-2]\n",
    "\n",
    "#   os.mkdir(os.path.join(\"/content\", cpnt))\n",
    "\n",
    "#   localPath = os.path.join(\"/content\", cpnt, fn)\n",
    "\n",
    "#   if (\"model.h5\" in p):\n",
    "#     localPathModel = localPath\n",
    "#   elif (\"w.pickle\" in p):\n",
    "#     localPathW = localPath\n",
    "\n",
    "#   with file_io.FileIO(p, mode='rb') as input_f:\n",
    "#     with file_io.FileIO(localPath, mode='wb+') as output_f:\n",
    "#       output_f.write(input_f.read())\n",
    "#       print(\"Pulled from bucket: '\" + fn + \"'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nYu7qfd3IsMu",
    "outputId": "d24bd442-2144-459f-eec5-0437fdd2cde3"
   },
   "outputs": [],
   "source": [
    "# print(f\"Loading {localPathModel}\")\n",
    "# model.load_weights(localPathModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HRuwJfh2l7nS"
   },
   "outputs": [],
   "source": [
    "# model.load_weights(\"/content/model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3HLXTKPAfZ04"
   },
   "outputs": [],
   "source": [
    "# modelOld = CreateModelRobertaMLMTrainingDropout()\n",
    "# modelOld.load_weights(\"/content/cp_daily_valid_49_end/model.h5\")\n",
    "# modelOld.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NWKr6ROif078"
   },
   "outputs": [],
   "source": [
    "# model.get_layer(\"Roberta\").set_weights(modelOld.get_layer(\"Roberta\").get_weights())\n",
    "# model.get_layer(\"Categories\").set_weights(modelOld.get_layer(\"Categories\").get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_mV2OpQAGDja"
   },
   "outputs": [],
   "source": [
    "# with open(\"/content/w.pickle\", 'rb') as pickle_file:\n",
    "#   w = pickle.load(pickle_file)\n",
    "# model.optimizer.set_weights(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kXHVjhsDHHF9"
   },
   "outputs": [],
   "source": [
    "# model.optimizer.learning_rate = 5e-2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HyBFN04Q-qcU"
   },
   "source": [
    "LR 5e-4  5000/Unknown - 5576s 1s/step - loss: 296.81093730\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zvFil-4dStzq"
   },
   "source": [
    "# Full sentence as y\n",
    "20000/Unknown - 21155s 1s/step - loss: 0.9579\n",
    "Saved model to: 'gs://crypto_nlp_training/chk/RobertaMLMTraining_1_GPU_512LB_10000VC_FullPrediction/cp_daily_valid_00_20000/model.h5'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5le0oPyfbE79"
   },
   "source": [
    "# Masked sentence as y, LR 5e-4, Random state 11\n",
    "14000/Unknown - 15387s 1s/step - loss: 5.3956\n",
    "Saved model to: 'gs://crypto_nlp_training/chk/RobertaMLMTraining_1_GPU_512LB_10000VC_MaskedPrediction/cp_daily_valid_00_14000/model.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P2BZv38mgNQs"
   },
   "outputs": [],
   "source": [
    "# A python generator function has to be applied on the dataStream\n",
    "\n",
    "def pythonGeneratorMLMTraining():\n",
    "  # Initialize the FileListToDataStream generator\n",
    "  dataStreamTraining = DataStreamCreator.FileListToDataStream(fileList = TRAIN_FILES,\n",
    "                                                      batch_size = BATCH_SIZE,\n",
    "                                                      X_Block_lenght = X_BLOCK_LENGHT,\n",
    "                                                      y_type_dict=Y_TYPE_DICT,\n",
    "                                                      shuffle=True,\n",
    "                                                      parallel_generators = 8,\n",
    "                                                      random_seed = RANDOM_SEED,\n",
    "                                                      **DATA_STREAM_PARAMETERS\n",
    "                                                      )\n",
    "  \n",
    "  # Calculate how many word shall be replaced\n",
    "  mask_number = int(np.round(X_BLOCK_LENGHT * MLM_MASK_FACTOR))\n",
    "  logging.info(f\"In each batch of X-Blocks, {mask_number*BATCH_SIZE} elements will be randomly masked. This is an average of {mask_number} per X-Block\")\n",
    "\n",
    "  # This while has to integrated into the FileListToDataStream method\n",
    "  while True:  \n",
    "    try:\n",
    "      ne = next(dataStreamTraining)\n",
    "      _X = ne['X']\n",
    "\n",
    "      # Convert the X-Block into a sentence\n",
    "      with tf.device('/CPU:0'):        \n",
    "        four_float_sentence = fourFloatClassifierModel.predict(_X, batch_size = BATCH_SIZE, verbose = 0)\n",
    "        int_sentence = ConvertFourFloatDataToWords(four_float_sentence, digitLimits)\n",
    "\n",
    "        # _X_sentence = intClassifierModel.predict(_X, batch_size = BATCH_SIZE, verbose = 0)\n",
    "\n",
    "      # Round to avoid too many categories\n",
    "      # Todo: Better classifier model!\n",
    "      # _X_sentence = np.round(_X_sentence / 10.0).astype(int)\n",
    "\n",
    "      # Create random indices, to replace 'words' with MASK_TOKEN_I\n",
    "      mask_positions = np.round(np.random.rand(BATCH_SIZE, mask_number) * X_BLOCK_LENGHT * BATCH_SIZE).astype(int)\n",
    "      mask_positions[mask_positions == X_BLOCK_LENGHT * BATCH_SIZE] -= 1  # Avoid the upper array limit\n",
    "\n",
    "      # Mask the chosen tokens\n",
    "      int_sentence_masked = np.array(int_sentence).flatten()\n",
    "      int_sentence_masked[mask_positions] = MASK_TOKEN_ID\n",
    "      int_sentence_masked = int_sentence_masked.reshape(int_sentence.shape)\n",
    "\n",
    "      # print(mask_positions[0,0])\n",
    "\n",
    "      # 'Remove' all tokens that shall not be predicted from the training y data (the full sentence), so that the network can focus on the missing tokens\n",
    "      # More precise: Setting them to -1 tells the loss function to ignore them\n",
    "      int_sentence[int_sentence_masked != MASK_TOKEN_ID] = -1\n",
    "\n",
    "      # Not required here, as the network shall predict back its original input\n",
    "      # _y = ne['y']\n",
    "      \n",
    "      # Return the masked senteces as X data, the full ones are the y-data --> The network shall predict the missing tokens\n",
    "      yield (int_sentence_masked, int_sentence)\n",
    "    except StopIteration as si:\n",
    "      logging.warning(\"StopIteration in pythonGenerator\")\n",
    "      logging.warning(si)\n",
    "      return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RLmWNTDIUpt6"
   },
   "outputs": [],
   "source": [
    "# A python generator function has to be applied on the dataStream\n",
    "\n",
    "def pythonGeneratorMLMEval():\n",
    "  # Initialize the FileListToDataStream generator\n",
    "  dataStreamTraining = DataStreamCreator.FileListToDataStream(fileList = TRAIN_FILES,\n",
    "                                                      batch_size = BATCH_SIZE,\n",
    "                                                      X_Block_lenght = X_BLOCK_LENGHT,\n",
    "                                                      y_type_dict=Y_TYPE_DICT,\n",
    "                                                      shuffle=True,\n",
    "                                                      parallel_generators = BATCH_SIZE,\n",
    "                                                      random_seed = RANDOM_SEED,\n",
    "                                                      **DATA_STREAM_PARAMETERS\n",
    "                                                      )\n",
    "  \n",
    "  # Calculate how many word shall be replaced\n",
    "  mask_number = int(np.round(X_BLOCK_LENGHT * MLM_MASK_FACTOR))\n",
    "  logging.info(f\"In each batch of X-Blocks, {mask_number*BATCH_SIZE} elements will be randomly masked. This is an average of {mask_number} per X-Block\")\n",
    "\n",
    "  # This while has to integrated into the FileListToDataStream method\n",
    "  while True:  \n",
    "    try:\n",
    "      ne = next(dataStreamTraining)\n",
    "      _X = ne['X']\n",
    "\n",
    "      # Convert the X-Block into a sentence\n",
    "      with tf.device('/CPU:0'):        \n",
    "        four_float_sentence = fourFloatClassifierModel.predict(_X, batch_size = BATCH_SIZE, verbose = 0)\n",
    "        int_sentence = ConvertFourFloatDataToWords(four_float_sentence, digitLimits)\n",
    "\n",
    "        # _X_sentence = intClassifierModel.predict(_X, batch_size = BATCH_SIZE, verbose = 0)\n",
    "\n",
    "      # Round to avoid too many categories\n",
    "      # Todo: Better classifier model!\n",
    "      # _X_sentence = np.round(_X_sentence / 10.0).astype(int)\n",
    "\n",
    "      # Create random indices, to replace 'words' with MASK_TOKEN_I\n",
    "      mask_positions = np.round(np.random.rand(BATCH_SIZE, mask_number) * X_BLOCK_LENGHT * BATCH_SIZE).astype(int)\n",
    "      mask_positions[mask_positions == X_BLOCK_LENGHT * BATCH_SIZE] -= 1  # Avoid the upper array limit\n",
    "\n",
    "      # Mask the chosen tokens\n",
    "      int_sentence_masked = np.array(int_sentence).flatten()\n",
    "      int_sentence_masked[mask_positions] = MASK_TOKEN_ID\n",
    "      int_sentence_masked = int_sentence_masked.reshape(int_sentence.shape)\n",
    "\n",
    "      # print(mask_positions[0,0])\n",
    "\n",
    "      # 'Remove' all tokens that shall not be predicted from the training y data (the full sentence), so that the network can focus on the missing tokens\n",
    "      # More precise: Setting them to -1 tells the loss function to ignore them\n",
    "      # int_sentence[int_sentence_masked != MASK_TOKEN_ID] = -1\n",
    "\n",
    "      # Not required here, as the network shall predict back its original input\n",
    "      # _y = ne['y']\n",
    "      \n",
    "      # Return the masked senteces as X data, the full ones are the y-data --> The network shall predict the missing tokens\n",
    "      yield (int_sentence_masked, int_sentence)\n",
    "    except StopIteration as si:\n",
    "      logging.warning(\"StopIteration in pythonGenerator\")\n",
    "      logging.warning(si)\n",
    "      return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iUSw95cqUuE_"
   },
   "outputs": [],
   "source": [
    "# Create a Tensorflow dataset out of the python generator, which can be fed to the network\n",
    "tfGenEval = tf.data.Dataset.from_generator(pythonGeneratorMLMEval, \n",
    "                                               output_types = (tf.int32, tf.int32),\n",
    "                                               output_shapes=(\n",
    "                                                   (BATCH_SIZE, X_BLOCK_LENGHT),\n",
    "                                                   (BATCH_SIZE, X_BLOCK_LENGHT)\n",
    "                                                   )\n",
    "                                               )\n",
    "tfGenEval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qI3WKmspUe2Z"
   },
   "outputs": [],
   "source": [
    "it = tfGenEval.as_numpy_iterator()\n",
    "ne = next(it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ktuZ3D04UzeE"
   },
   "outputs": [],
   "source": [
    "p = model.predict(ne[0])\n",
    "p.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-ZhRrApuU8M1"
   },
   "outputs": [],
   "source": [
    "gtVal = ne[1][0,:]\n",
    "gtVal.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aRfxK1DeVJWp"
   },
   "outputs": [],
   "source": [
    "porig= copy.deepcopy(p)\n",
    "# p = copy.deepcopy(porig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vgzPCL7KVXC1"
   },
   "outputs": [],
   "source": [
    "plt.plot(p[0,0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k6oO5JBsWz_j"
   },
   "outputs": [],
   "source": [
    "intPrediction = np.empty(p.shape[:-1])\n",
    "\n",
    "for b in range(p.shape[0]):\n",
    "  for ts in range(p.shape[1]):\n",
    "    classMax = np.max(p[b,ts,:])\n",
    "    maxIndex = np.where(p[b,ts,:] == classMax)\n",
    "\n",
    "    #print(f\"classMax: {classMax}, maxIndex: {maxIndex}\")\n",
    "    \n",
    "    intPrediction[b,ts] = maxIndex[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RPVXsb8mYGGL"
   },
   "outputs": [],
   "source": [
    "intPrediction.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V-utCJSuYStU"
   },
   "outputs": [],
   "source": [
    "gtVal[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3pXGXuOcYVo2"
   },
   "outputs": [],
   "source": [
    "intPrediction[0,:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "voZjwOaDDph1"
   },
   "outputs": [],
   "source": [
    "_ = plt.hist(gtVal.flatten(), bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a84-E1mj4RUY"
   },
   "outputs": [],
   "source": [
    "_ = plt.hist(intPrediction.flatten(), bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q_DfyjS2gsPi"
   },
   "outputs": [],
   "source": [
    "plt.plot(intPrediction[0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hsSenZntVcu8"
   },
   "outputs": [],
   "source": [
    "pMaxed = p * (p >= np.sort(p, axis=2)[:,[-1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "StZjtHTCV77e"
   },
   "outputs": [],
   "source": [
    "pMaxes = np.max(p, axis=2)\n",
    "pMaxes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pZzVhSx8WplK"
   },
   "outputs": [],
   "source": [
    "# p == pMaxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4sF0q8BlWQte"
   },
   "outputs": [],
   "source": [
    "# p[:] = np.where(p == pMaxes, pMaxes, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1lUV2_40WYcJ"
   },
   "outputs": [],
   "source": [
    "plt.plot(p[0,0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FtG_7-pWWC4s"
   },
   "outputs": [],
   "source": [
    "np.max(p[0,0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RPxpJLVpWF6c"
   },
   "outputs": [],
   "source": [
    "pMaxes[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cOM14p-9VxBY"
   },
   "outputs": [],
   "source": [
    "plt.plot(pMaxed[0,0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KSKQas1GQaM-",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# _save_folder = os.path.join(checkpoint_path,\n",
    "#                                 CHKPNT_NAME,\n",
    "#                                 \"robert_tpu_scratch_{:01d}_{:05d}\".format(112, 0)\n",
    "#                                 )\n",
    "\n",
    "# _model_path_local = os.path.join(\"/content/\", \"model.h5\")\n",
    "# _model_path_bucket = os.path.join(_save_folder, \"model.h5\")\n",
    "\n",
    "# model.save(_model_path_local)\n",
    "\n",
    "# # Copy model.h5 over to Google Cloud Storage\n",
    "# with file_io.FileIO(_model_path_local, mode='rb') as input_f:\n",
    "#     with file_io.FileIO(_model_path_bucket, mode='wb+') as output_f:\n",
    "#         output_f.write(input_f.read())\n",
    "#         print(\"\\nSaved model to: '\" + _model_path_bucket + \"'\")\n",
    "\n",
    "# # Save optimizer config\n",
    "# c = copy.deepcopy(model.optimizer.get_config())\n",
    "\n",
    "# fp = os.path.join(_save_folder, \"c.pickle\")\n",
    "# with file_io.FileIO(fp, mode='wb+') as handle:\n",
    "#   pickle.dump(c, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "#   print(\"Saved optimizer config to: '\" + fp + \"'\")\n",
    "\n",
    "# # Save optimizer weights\n",
    "# w = copy.deepcopy(model.optimizer.get_weights())\n",
    "\n",
    "# fp = os.path.join(_save_folder, \"w.pickle\")\n",
    "# with file_io.FileIO(fp, mode='wb+') as handle:\n",
    "#   pickle.dump(w, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "#   print(\"Saved optimizer weights to: '\" + fp + \"'\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
