{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RIbOPenP-I_d"
   },
   "source": [
    "# Mount drive and bucket\n",
    "Todo: Remove in public version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "GHybPwDjX1gZ",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Check if the notebook is run in Google Colab\n",
    "import sys\n",
    "\n",
    "COLAB = 'google.colab' in sys.modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_io.TextIOWrapper name='/content/bigdata/nb_20230217_1046.log' mode='a+' encoding='UTF-8'>\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(60000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 60 seconds\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import datetime\n",
    "import logging\n",
    "\n",
    "nblog = open(f\"/content/bigdata/nb_{datetime.datetime.utcnow().strftime('%Y%m%d_%H%M')}.log\", \"a+\")\n",
    "print(nblog)\n",
    "sys.stdout.echo = nblog\n",
    "sys.stderr.echo = nblog\n",
    "\n",
    "#get_ipython().log.handlers[0].stream = nblog\n",
    "#get_ipython().log.setLevel(logging.INFO)\n",
    "\n",
    "%autosave 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sK6Uuoy5qsua",
    "outputId": "d29d48f5-a2e5-40f9-927d-002d32fd48f9"
   },
   "outputs": [],
   "source": [
    "# if COLAB:\n",
    "#   from google.colab import drive\n",
    "#   drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "MTJ7bYMtHmvS"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run the command!\n"
     ]
    }
   ],
   "source": [
    "if COLAB:\n",
    "  from google.colab import auth\n",
    "  auth.authenticate_user()\n",
    "else:\n",
    "    print(\"Run the command!\")\n",
    "  #Todo #bring the command inside the notebook\n",
    "  #run this terminal inside docker: gcloud auth login b.girsule@gmail.com --no-launch-browser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "DOScyXpJws23"
   },
   "outputs": [],
   "source": [
    "# Todo: Check if possible in local docker\n",
    "# from google.cloud import storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "t9dbL-PU-okV",
    "outputId": "14e73bf6-881d-4bc0-96f4-8a1b79cae570"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-17 10:46:42.269285: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-17 10:46:42.391776: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-02-17 10:46:43.011141: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-17 10:46:43.011199: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-17 10:46:43.011207: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF Version is 2.10.0, ok!\n"
     ]
    }
   ],
   "source": [
    "# Check if the tf version is 2.10.0, this is required to use the 'ignore_class' in the  SparseCategoricalCrossentropy\n",
    "import tensorflow as tf\n",
    "\n",
    "if '2.10.0' != tf.__version__:\n",
    "  !pip uninstall tensorflow -y\n",
    "  !pip install tensorflow-gpu==2.10.0\n",
    "  please_restart_the_runtime\n",
    "else:\n",
    "  print(\"TF Version is 2.10.0, ok!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "FYePtDVpqtkN"
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "# import tensorflow_gcs_config\n",
    "from tensorflow.python.lib.io import file_io\n",
    "\n",
    "from keras.layers import Input, Dense #, ReLU, Add, Flatten, Concatenate, LayerNormalization, UpSampling2D, Activation, LSTM, Multiply, Dropout, Reshape, Permute, BatchNormalization, MaxPooling1D, AveragePooling1D, MaxPooling3D, AveragePooling2D, LayerNormalization, MaxPooling2D\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "pxa3Ug_JplIq"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "EcBnUrFKqyCK"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "R_3vswfeRqmj"
   },
   "outputs": [],
   "source": [
    "# Set the google cloud bucket data\n",
    "project_id = 'tweetprediction'\n",
    "bucket_name = 'crypto_nlp_training'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "X3s3eDubSFaJ",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set the checkpoint path for saving train progress\n",
    "if COLAB:\n",
    "    CHECKPOINT_PATH = f\"gs://{bucket_name}/chk/\"\n",
    "else:\n",
    "    CHECKPOINT_PATH = f\"/content/bigdata/chk/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8rvlsLwbpmWJ",
    "outputId": "12f0ff94-d55c-449f-f101-c4581499db7d"
   },
   "outputs": [],
   "source": [
    "# Check if the notebook is run in google colab, if so, clone the repo\n",
    "if COLAB:\n",
    "    print(\"Running in Colab\")\n",
    "\n",
    "    # Clone the whole repo to get all data and code if not already done\n",
    "    if not os.path.exists(\"/content/CryptoCrystalBall\"):\n",
    "      !git clone https://github.com/girsigit/CryptoCrystalBall\n",
    "\n",
    "      # cd into the notebooks directory --> Necessary to match all paths for importing\n",
    "    #%cd /content/CryptoCrystalBall/JupyterDocker/notebooks\n",
    "    %cd /content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "q9OmJ6vFthwG"
   },
   "outputs": [],
   "source": [
    "# Try importing the Ta-Lib library, if this fails, try to install it and\n",
    "# import it again afterwards\n",
    "try:\n",
    "    import talib\n",
    "except:\n",
    "    !wget http://prdownloads.sourceforge.net/ta-lib/ta-lib-0.4.0-src.tar.gz\n",
    "    !tar -xzvf ta-lib-0.4.0-src.tar.gz\n",
    "    %cd ta-lib\n",
    "    !./configure --prefix=/usr\n",
    "    !make\n",
    "    !make install\n",
    "    !pip install Ta-Lib\n",
    "    %cd ..\n",
    "\n",
    "    import talib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "2orTUN099zyA",
    "tags": []
   },
   "outputs": [],
   "source": [
    "try:\n",
    "  from transformers import TFRobertaModel, RobertaConfig\n",
    "except:\n",
    "  # Important!: Version 4.23 does not work on TPU\n",
    "  !pip install transformers==4.22\n",
    "\n",
    "  from transformers import TFRobertaModel, RobertaConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip uninstall -y tensorboard-plugin-profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qfAsp4TWHivL",
    "outputId": "a25fdba4-ad57-40a3-f725-7d4ed114d38b",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Required to do profiling\n",
    "# !pip install tensorboard-plugin-profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "axPYAbN9upgY",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nbt7oQxzL2Zy"
   },
   "source": [
    "---\n",
    "# Add custom import path for DataStreamCreator and IndicatorCalculator\n",
    "\n",
    "These libs are not in the standard python directory, so their paths have to be added to the import paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ICDL0OwbL2Zz",
    "outputId": "41c7541e-3a1e-4035-f2f3-182fed452a8e",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['', 'content']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Get the current directory\n",
    "# current_dir = os.getcwd()\n",
    "# current_dir_splitted = current_dir.split(os.sep)\n",
    "\n",
    "# Todo: is inside /content/CB in local docker\n",
    "current_dir_splitted = [\"\", \"content\"]\n",
    "current_dir_splitted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JJ8l6O2gL2Z1",
    "outputId": "de6d884a-f4be-47e2-c808-eeac3448580c",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dsc_dir: /content/CryptoCrystalBall/DataStreamCreator\n",
      "ind_dir: /content/CryptoCrystalBall/IndicatorCalculator\n"
     ]
    }
   ],
   "source": [
    "# Create the import directories for the DataStreamCreator and the IndicatorCalculator\n",
    "dsc_dir = '/content/CryptoCrystalBall/DataStreamCreator'\n",
    "print(f\"dsc_dir: {dsc_dir}\")\n",
    "\n",
    "ind_dir = '/content/CryptoCrystalBall/IndicatorCalculator'\n",
    "print(f\"ind_dir: {ind_dir}\")\n",
    "\n",
    "# Add them to the import paths\n",
    "sys.path.insert(0, dsc_dir)\n",
    "sys.path.insert(0, ind_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "iqyTbcZDttLT",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import the actual classes\n",
    "from IndicatorCalculator import IndicatorCalculator\n",
    "import DataStreamCreator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zPsG4dqRL2Z5"
   },
   "source": [
    "---\n",
    "# Define all the parameters and variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5J8ODl45L2Z6",
    "outputId": "690c2801-687e-47fe-cefc-616e029a62a5",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA_PATH: /content/DemoData\n"
     ]
    }
   ],
   "source": [
    "# Define the tick data path\n",
    "DATA_PATH = os.path.join(os.sep, *current_dir_splitted, 'DemoData')\n",
    "print(f\"DATA_PATH: {DATA_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7TUeLGiOL2Z7",
    "outputId": "00651843-f462-4c20-e6cc-7cb0d7cd6d23",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMG_SAVE_PATH: /content/Documentation/Images\n"
     ]
    }
   ],
   "source": [
    "# Define the chart image save path\n",
    "IMG_SAVE_PATH = os.path.join(os.sep, *current_dir_splitted, 'Documentation', 'Images')\n",
    "print(f\"IMG_SAVE_PATH: {IMG_SAVE_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "o23rkki9ttLZ",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define a global random seed\n",
    "RANDOM_SEED = 42+17\n",
    "\n",
    "# Set the seed in np\n",
    "np.random.seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "g9gBeRtnxKMD",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# X_BLOCK_LENGHT defines how far into the past a 'slice of a chart' shall be\n",
    "# See: https://github.com/girsigit/CryptoCrystalBall/tree/main/DataStreamCreator#xblockgenerator\n",
    "X_BLOCK_LENGHT = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "sh5dsBKr5Ko-",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# How many examples shall be processed at the same time, limited by GPU memory\n",
    "BATCH_SIZE = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "J331jHk-u345",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# A fixed number of features is used\n",
    "FEATURES = 160"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "1JVT1Z2U0lW8",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Finanical indicator timespans\n",
    "# See: https://github.com/girsigit/CryptoCrystalBall/tree/main/IndicatorCalculator\n",
    "SHORTSPAN = 6\n",
    "MIDSPAN = 48\n",
    "LONGSPAN = 120"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "AnNz-Oke3J3p",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Additional settings for the data stream\n",
    "# For this notebook, the calculation of pattern indicators is turned off\n",
    "DATA_STREAM_PARAMETERS = {\n",
    "    \"calcPatternIndicators\": False, # No patterns are used\n",
    "    \"calcVolumeInidators\": False, # No volume indicators, these are wide spread and may disturb the classifer\n",
    "    \"dropna\": True # Drop all tick/indicator table rows containing nan values instead of just replacing them by 0 (which would lead to wrong predictions)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "GKkv21lAxYEP",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# NLP token configuration\n",
    "BOS_TOKEN_ID = 0\n",
    "PAD_TOKEN_ID = 1\n",
    "EOS_TOKEN_ID = 2\n",
    "MASK_TOKEN_ID = 3\n",
    "\n",
    "MLM_MASK_FACTOR = 0.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "V5P8Nbn7F5CS",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Vocab size configuration\n",
    "# The feature vector to integer classifier model has a 5 digit output, therefore the vocab size would be 100000\n",
    "# As this is too much, the categories are rounded --> Todo: Create better classifier model\n",
    "\n",
    "VOCAB_SIZE = 10000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7xXpDFe9ROVQ"
   },
   "source": [
    "# Load the train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "b2EO18ZmppNe",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Check if the dataset already has been copy, if not, copy it\n",
    "if not os.path.exists(\"/content/dataset\") or not os.path.exists(\"/content/dataset/Train\"):\n",
    "  !mkdir /content/dataset\n",
    "  !mkdir /content/dataset/Train\n",
    "  !gsutil -m cp -r gs://cryptocrystalball_public/CryptoDataset/Hourly/significant_currencies.txt /content/dataset/significant_currencies.txt\n",
    "  !gsutil -m cp -r gs://cryptocrystalball_public/CryptoDataset/Hourly/Train/* /content/dataset/Train/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2sRVckzNtbZL",
    "outputId": "5cfd2c06-7823-40b3-eea8-2dbc3f51df57",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 121 significant files names.\n"
     ]
    }
   ],
   "source": [
    "#@markdown ### Use only significant currencies\n",
    "#@markdown Load a manually defined list of significant currencies (`significant_currencies.txt`).\n",
    "#@markdown This list contains no currencies which little or no volume or price movement, to\n",
    "#@markdown avoid training on data sample which would never be used to trade on in a real \n",
    "#@markdown application.\n",
    "\n",
    "#@markdown If enabled, only currency pairs with the base currency USDT are laoded,\n",
    "#@markdown this is important to prevent interference between different cryptocurrencies.\n",
    "#@markdown For example, in `BTC-ETH.csv`, there is influence of both the BTC and the ETH price, but we want to predict trade signals based on a 'real' currency (USDT is kind of the same as USD).\n",
    "\n",
    "significant_only = True #@param {type:\"boolean\"}\n",
    "\n",
    "if significant_only:\n",
    "  with open(\"/content/dataset/significant_currencies.txt\") as f:\n",
    "    SIGNIFICANT_CURRS = f.read().splitlines()\n",
    "\n",
    "  print(f\"Loaded {len(SIGNIFICANT_CURRS)} significant files names.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dlNAUwUTtdBE",
    "outputId": "3c614762-758a-444f-dc86-e86527a6c0ca",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The train dataset contains 121 files.\n",
      "['/content/dataset/Train/1INCH-USDT.csv', '/content/dataset/Train/4ART-USDT.csv', '/content/dataset/Train/AAVE-USDT.csv']\n"
     ]
    }
   ],
   "source": [
    "# Get train file names - Only pick the ones ending with -USDT to prevent\n",
    "# influence between different currencies\n",
    "TRAIN_PATH = \"/content/dataset/Train\"\n",
    "\n",
    "# Get all file names\n",
    "TRAIN_FILES = [os.path.join(TRAIN_PATH,f) for f in listdir(TRAIN_PATH) if isfile(join(TRAIN_PATH, f)) and \".csv\" in f ]\n",
    "\n",
    "# Filter for significant currencies only\n",
    "if significant_only:\n",
    "  TRAIN_FILES = [f for f in TRAIN_FILES if f.split(\"/\")[-1].replace(\".csv\",\"\") in SIGNIFICANT_CURRS]\n",
    "\n",
    "# Filter for USDT-based ones only\n",
    "TRAIN_FILES = [f for f in TRAIN_FILES if \"-USDT\" in f]\n",
    "\n",
    "# Sort them (as a stable basis for randomizing afterwards)\n",
    "TRAIN_FILES = sorted(TRAIN_FILES)\n",
    "\n",
    "print(f\"The train dataset contains {len(TRAIN_FILES)} files.\")\n",
    "print(TRAIN_FILES[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jhiJj_nfsmU0"
   },
   "source": [
    "# Load the classifier model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i8fWOHkSsMpz",
    "outputId": "1f57628e-dd3c-4395-a875-5d33279b4616",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Copy the feature vector to four float classifier model\n",
    "# Also copy the digit limits\n",
    "if not os.path.exists(\"/content/bottleneckToFourFloatModel.h5\"):\n",
    "  !gsutil -m cp -r gs://crypto_nlp_training/four_float_to_int/bottleneckToFourFloatModel.h5 /content/bottleneckToFourFloatModel.h5\n",
    "  !gsutil -m cp -r gs://crypto_nlp_training/four_float_to_int/digitLimits.npy /content/digitLimits.npy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3daDKjTltDTH",
    "outputId": "aee227b2-d87a-4651-bf6f-14d73592e862",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "Model: \"NNClassifierBottleneckToFourFloat\"\n",
      "____________________________________________________________________________________________________________________________________________________________________________________________________________________________\n",
      " Layer (type)                                                                                      Output Shape                                                                            Param #                          \n",
      "============================================================================================================================================================================================================================\n",
      " inputTicksAndIndicators (InputLayer)                                                              [(None, 512, 160)]                                                                      0                                \n",
      "                                                                                                                                                                                                                            \n",
      " tf.expand_dims_1 (TFOpLambda)                                                                     (None, 512, 160, 1)                                                                     0                                \n",
      "                                                                                                                                                                                                                            \n",
      " permute_1 (Permute)                                                                               (None, 512, 1, 160)                                                                     0                                \n",
      "                                                                                                                                                                                                                            \n",
      " DepthwiseConv2DInput (DepthwiseConv2D)                                                            (None, 512, 1, 160)                                                                     160                              \n",
      "                                                                                                                                                                                                                            \n",
      " tf.compat.v1.squeeze_1 (TFOpLambda)                                                               (None, 512, 160)                                                                        0                                \n",
      "                                                                                                                                                                                                                            \n",
      " Tanh_Input (Activation)                                                                           (None, 512, 160)                                                                        0                                \n",
      "                                                                                                                                                                                                                            \n",
      " tf.clip_by_value_1 (TFOpLambda)                                                                   (None, 512, 160)                                                                        0                                \n",
      "                                                                                                                                                                                                                            \n",
      " Bottleneck_1 (Dense)                                                                              (None, 512, 80)                                                                         12880                            \n",
      "                                                                                                                                                                                                                            \n",
      " Bottleneck_2 (Dense)                                                                              (None, 512, 40)                                                                         3240                             \n",
      "                                                                                                                                                                                                                            \n",
      " Bottleneck_3 (Dense)                                                                              (None, 512, 4)                                                                          164                              \n",
      "                                                                                                                                                                                                                            \n",
      "============================================================================================================================================================================================================================\n",
      "Total params: 16,444\n",
      "Trainable params: 16,444\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________________________________________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-17 10:46:44.691360: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-17 10:46:44.722667: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-17 10:46:44.722858: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-17 10:46:44.723663: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-17 10:46:44.724894: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-17 10:46:44.725096: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-17 10:46:44.725257: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-17 10:46:45.188877: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-17 10:46:45.189128: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-17 10:46:45.189274: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-17 10:46:45.189387: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 7386 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1070, pci bus id: 0000:01:00.0, compute capability: 6.1\n"
     ]
    }
   ],
   "source": [
    "# Load the model\n",
    "with tf.device('/CPU:0'):\n",
    "    fourFloatClassifierModel = keras.models.load_model(\"/content/bottleneckToFourFloatModel.h5\")\n",
    "    fourFloatClassifierModel.summary(line_length=220)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "2nLWLP3AB3gG",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load the digit limits\n",
    "digitLimits = np.load(\"/content/digitLimits.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0BeeQ7hvhXJF"
   },
   "source": [
    "# Load the class weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true,
    "id": "05AAfFUyhZdg",
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying gs://crypto_nlp_training/four_float_to_int/class_weights.npy...\n",
      "/ [1/1 files][ 78.2 KiB/ 78.2 KiB] 100% Done                                    \n",
      "Operation completed over 1 objects/78.2 KiB.                                     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{0: 1.0,\n",
       " 1: 1.0,\n",
       " 2: 1.0,\n",
       " 3: 1.0,\n",
       " 4: 1.0,\n",
       " 5: 1.0,\n",
       " 6: 1.0,\n",
       " 7: 1.0,\n",
       " 8: 1.0,\n",
       " 9: 1.0,\n",
       " 10: 1.0,\n",
       " 11: 1.0,\n",
       " 12: 1.0,\n",
       " 13: 1.0,\n",
       " 14: 1.5366002344665886,\n",
       " 15: 3.810232558139535,\n",
       " 16: 2.932259507829978,\n",
       " 17: 1.486077097505669,\n",
       " 18: 1.4777001127395717,\n",
       " 19: 1.0,\n",
       " 20: 1.0,\n",
       " 21: 1.0,\n",
       " 22: 2.56,\n",
       " 23: 3.098628841607565,\n",
       " 24: 1.1309059534081105,\n",
       " 25: 3.7664367816091953,\n",
       " 26: 1.927529411764706,\n",
       " 27: 0.8222835633626098,\n",
       " 28: 0.8021542227662178,\n",
       " 29: 2.6969547325102883,\n",
       " 30: 1.0,\n",
       " 31: 1.0,\n",
       " 32: 1.6868983268983269,\n",
       " 33: 0.7576416184971099,\n",
       " 34: 1.0561804995970991,\n",
       " 35: 0.71624043715847,\n",
       " 36: 0.584620874219447,\n",
       " 37: 0.8279974731522426,\n",
       " 38: 1.678258642765685,\n",
       " 39: 3.6207734806629834,\n",
       " 40: 5.77409691629956,\n",
       " 41: 4.664483985765124,\n",
       " 42: 0.9651840942562592,\n",
       " 43: 1.0604530744336569,\n",
       " 44: 0.3078252700798497,\n",
       " 45: 0.6488712871287129,\n",
       " 46: 0.2683701883701884,\n",
       " 47: 0.18051508056741494,\n",
       " 48: 1.4246956521739131,\n",
       " 49: 1.0,\n",
       " 50: 1.0,\n",
       " 51: 1.5348009367681499,\n",
       " 52: 1.4108934337997847,\n",
       " 53: 0.8779102478231748,\n",
       " 54: 0.2664606627363285,\n",
       " 55: 0.2194775619557937,\n",
       " 56: 0.2230633083730429,\n",
       " 57: 0.3271892161757364,\n",
       " 58: 0.6639918946301925,\n",
       " 59: 1.0,\n",
       " 60: 1.0,\n",
       " 61: 1.1212318220701454,\n",
       " 62: 1.3512577319587629,\n",
       " 63: 0.5544500846023689,\n",
       " 64: 0.29114171479342515,\n",
       " 65: 0.24322137687882725,\n",
       " 66: 0.531948051948052,\n",
       " 67: 0.3722578812837262,\n",
       " 68: 1.0,\n",
       " 69: 1.0,\n",
       " 70: 1.0,\n",
       " 71: 0.7929340592861464,\n",
       " 72: 0.4925667042465239,\n",
       " 73: 0.43144173798551677,\n",
       " 74: 0.29580681561724215,\n",
       " 75: 0.1401240111182382,\n",
       " 76: 0.27501468736886275,\n",
       " 77: 2.332241992882562,\n",
       " 78: 1.0,\n",
       " 79: 1.0,\n",
       " 80: 1.0005496183206106,\n",
       " 81: 1.2875442043222003,\n",
       " 82: 0.5938921613049388,\n",
       " 83: 0.4646295639844027,\n",
       " 84: 0.3112609831393968,\n",
       " 85: 1.7314663143989433,\n",
       " 86: 1.0,\n",
       " 87: 1.0,\n",
       " 88: 1.0,\n",
       " 89: 1.0,\n",
       " 90: 4.228129032258065,\n",
       " 91: 0.44117132278694043,\n",
       " 92: 0.9198035087719298,\n",
       " 93: 0.7589577301679212,\n",
       " 94: 0.8880216802168022,\n",
       " 95: 6.331980676328502,\n",
       " 96: 1.0,\n",
       " 97: 1.0,\n",
       " 98: 1.0,\n",
       " 99: 1.0,\n",
       " 100: 1.0,\n",
       " 101: 1.0,\n",
       " 102: 7.943757575757576,\n",
       " 103: 1.0,\n",
       " 104: 1.5402115158636898,\n",
       " 105: 2.952072072072072,\n",
       " 106: 1.0,\n",
       " 107: 1.0,\n",
       " 108: 1.0,\n",
       " 109: 1.0,\n",
       " 110: 1.0,\n",
       " 111: 6.6873469387755105,\n",
       " 112: 2.56,\n",
       " 113: 1.3797052631578948,\n",
       " 114: 1.0,\n",
       " 115: 1.0,\n",
       " 116: 1.0,\n",
       " 117: 1.0,\n",
       " 118: 1.0,\n",
       " 119: 2.56,\n",
       " 120: 1.0,\n",
       " 121: 1.6445671267252195,\n",
       " 122: 0.7058266020463112,\n",
       " 123: 1.461226309921962,\n",
       " 124: 1.0,\n",
       " 125: 2.56,\n",
       " 126: 1.0,\n",
       " 127: 3.0200921658986175,\n",
       " 128: 1.2261178671655752,\n",
       " 129: 1.2913497536945813,\n",
       " 130: 1.0,\n",
       " 131: 1.4451157662624035,\n",
       " 132: 0.9089597780859917,\n",
       " 133: 0.9781492537313433,\n",
       " 134: 2.5450873786407766,\n",
       " 135: 1.486077097505669,\n",
       " 136: 0.5092152292152292,\n",
       " 137: 0.9463682310469315,\n",
       " 138: 0.2908832667554372,\n",
       " 139: 1.7808695652173914,\n",
       " 140: 1.0,\n",
       " 141: 0.5371803278688525,\n",
       " 142: 1.021605611847233,\n",
       " 143: 1.2850196078431373,\n",
       " 144: 0.4138680138932744,\n",
       " 145: 0.4557440890125174,\n",
       " 146: 0.46364343827378846,\n",
       " 147: 0.3401816766156242,\n",
       " 148: 0.635654704170708,\n",
       " 149: 1.0,\n",
       " 150: 1.0,\n",
       " 151: 1.1937340619307832,\n",
       " 152: 2.56,\n",
       " 153: 0.5791957578435705,\n",
       " 154: 0.33859984500129164,\n",
       " 155: 0.24116283348666054,\n",
       " 156: 0.35055362396362666,\n",
       " 157: 0.2930292868321037,\n",
       " 158: 0.683735002608242,\n",
       " 159: 3.181359223300971,\n",
       " 160: 3.4675132275132277,\n",
       " 161: 1.7291820580474935,\n",
       " 162: 655.36,\n",
       " 163: 0.8472656755009697,\n",
       " 164: 1.032876280535855,\n",
       " 165: 0.48082171680117386,\n",
       " 166: 0.5130019569471624,\n",
       " 167: 0.686600314300681,\n",
       " 168: 0.40756218905472635,\n",
       " 169: 1.0,\n",
       " 170: 1.278751219512195,\n",
       " 171: 14.403516483516484,\n",
       " 172: 1.4979657142857143,\n",
       " 173: 1.8204444444444445,\n",
       " 174: 0.6905795574288724,\n",
       " 175: 0.5864519015659955,\n",
       " 176: 0.514209493919184,\n",
       " 177: 0.3628792912513843,\n",
       " 178: 1.0,\n",
       " 179: 1.0,\n",
       " 180: 0.5909467989179441,\n",
       " 181: 1.1193168232280102,\n",
       " 182: 0.8965253077975376,\n",
       " 183: 1.055330112721417,\n",
       " 184: 0.8726498002663116,\n",
       " 185: 0.8802686366689053,\n",
       " 186: 0.8197123202001251,\n",
       " 187: 1.0,\n",
       " 188: 1.0,\n",
       " 189: 1.0,\n",
       " 190: 1.0,\n",
       " 191: 0.5306558704453441,\n",
       " 192: 0.5405030927835052,\n",
       " 193: 2.2443835616438355,\n",
       " 194: 1.0,\n",
       " 195: 2.487134724857685,\n",
       " 196: 1.0,\n",
       " 197: 1.0,\n",
       " 198: 1.0,\n",
       " 199: 1.0,\n",
       " 200: 13.797052631578948,\n",
       " 201: 0.701294810058855,\n",
       " 202: 1.5622407628128725,\n",
       " 203: 3.062429906542056,\n",
       " 204: 8.511168831168831,\n",
       " 205: 1.4048445873526259,\n",
       " 206: 1.0,\n",
       " 207: 1.0,\n",
       " 208: 1.0,\n",
       " 209: 1.0,\n",
       " 210: 0.8589252948885976,\n",
       " 211: 0.6994236926360726,\n",
       " 212: 1.0,\n",
       " 213: 2.56,\n",
       " 214: 3.212549019607843,\n",
       " 215: 1.0,\n",
       " 216: 3.041113689095128,\n",
       " 217: 1.0,\n",
       " 218: 13.374693877551021,\n",
       " 219: 2.8248275862068963,\n",
       " 220: 0.4129552614996849,\n",
       " 221: 1.7593557046979866,\n",
       " 222: 1.0,\n",
       " 223: 4.94611320754717,\n",
       " 224: 2.4005860805860806,\n",
       " 225: 1.0,\n",
       " 226: 2.044804992199688,\n",
       " 227: 0.671131592421915,\n",
       " 228: 3.352225063938619,\n",
       " 229: 5.799646017699115,\n",
       " 230: 0.3969473046638401,\n",
       " 231: 1.1578798586572439,\n",
       " 232: 1.2261178671655752,\n",
       " 233: 2.4545318352059926,\n",
       " 234: 3.971878787878788,\n",
       " 235: 1.0,\n",
       " 236: 0.4157056771328893,\n",
       " 237: 0.4549531412703922,\n",
       " 238: 2.56,\n",
       " 239: 3.0696018735362998,\n",
       " 240: 0.5652091418714963,\n",
       " 241: 1.0,\n",
       " 242: 1.8697860199714693,\n",
       " 243: 1.3653333333333333,\n",
       " 244: 0.9982635186595583,\n",
       " 245: 1.28,\n",
       " 246: 0.188105625717566,\n",
       " 247: 0.18636712640409497,\n",
       " 248: 1.3988473852721452,\n",
       " 249: 1.0,\n",
       " 250: 1.8204444444444445,\n",
       " 251: 1.0,\n",
       " 252: 1.1818935978358882,\n",
       " 253: 0.5207469209376242,\n",
       " 254: 0.829044908285895,\n",
       " 255: 0.6537256857855361,\n",
       " 256: 0.3936096096096096,\n",
       " 257: 0.4085785536159601,\n",
       " 258: 1.3696133751306165,\n",
       " 259: 3.5329380053908355,\n",
       " 260: 2.56,\n",
       " 261: 0.9952315869400152,\n",
       " 262: 1.3226236125126136,\n",
       " 263: 1.2226865671641791,\n",
       " 264: 0.9210962754743499,\n",
       " 265: 0.22436152002738788,\n",
       " 266: 0.9133937282229965,\n",
       " 267: 1.155837742504409,\n",
       " 268: 1.0,\n",
       " 269: 2.56,\n",
       " 270: 1.2204096834264433,\n",
       " 271: 2.4966095238095236,\n",
       " 272: 5.9850228310502285,\n",
       " 273: 0.9781492537313433,\n",
       " 274: 0.29224526198439243,\n",
       " 275: 0.15376818395119662,\n",
       " 276: 0.7714655679811654,\n",
       " 277: 1.44352422907489,\n",
       " 278: 3.6207734806629834,\n",
       " 279: 1.0,\n",
       " 280: 0.544997920997921,\n",
       " 281: 0.99221801665405,\n",
       " 282: 1.7546452476572958,\n",
       " 283: 0.9990243902439024,\n",
       " 284: 0.23523330940416368,\n",
       " 285: 0.3085499058380414,\n",
       " 286: 1.45797552836485,\n",
       " 287: 1.0,\n",
       " 288: 1.0,\n",
       " 289: 1.0,\n",
       " 290: 2.56,\n",
       " 291: 1.531214953271028,\n",
       " 292: 2.007228177641654,\n",
       " 293: 0.23629349197764557,\n",
       " 294: 0.3336014252990583,\n",
       " 295: 2.830928725701944,\n",
       " 296: 1.0,\n",
       " 297: 1.0,\n",
       " 298: 1.0,\n",
       " 299: 1.0,\n",
       " 300: 0.4888922044013428,\n",
       " 301: 5.08031007751938,\n",
       " 302: 1.6612420785804816,\n",
       " 303: 1.0,\n",
       " 304: 0.9070726643598616,\n",
       " 305: 1.0,\n",
       " 306: 1.0,\n",
       " 307: 1.0,\n",
       " 308: 4.255584415584416,\n",
       " 309: 1.0,\n",
       " 310: 0.3942015037593985,\n",
       " 311: 1310.72,\n",
       " 312: 1.0320629921259843,\n",
       " 313: 1.0850331125827815,\n",
       " 314: 9.637647058823529,\n",
       " 315: 1.0,\n",
       " 316: 2.4138489871086555,\n",
       " 317: 1.2400378429517502,\n",
       " 318: 4.383678929765886,\n",
       " 319: 1.0,\n",
       " 320: 0.511201248049922,\n",
       " 321: 2.103884430176565,\n",
       " 322: 1.6675826972010177,\n",
       " 323: 2.3280994671403197,\n",
       " 324: 3.2283743842364534,\n",
       " 325: 0.9602344322344323,\n",
       " 326: 3.734245014245014,\n",
       " 327: 1.3470914696813978,\n",
       " 328: 0.9058189357290947,\n",
       " 329: 1.0,\n",
       " 330: 1.28,\n",
       " 331: 2.357410071942446,\n",
       " 332: 0.5630240549828178,\n",
       " 333: 2.2755555555555556,\n",
       " 334: 1.5240930232558139,\n",
       " 335: 1.116456558773424,\n",
       " 336: 0.4178259483583041,\n",
       " 337: 8.796778523489932,\n",
       " 338: 0.9997864225781846,\n",
       " 339: 0.9436429085673146,\n",
       " 340: 1.577280385078219,\n",
       " 341: 2.7536134453781513,\n",
       " 342: 1.2506870229007634,\n",
       " 343: 0.9658953574060427,\n",
       " 344: 0.9355603140613847,\n",
       " 345: 0.3468430801799418,\n",
       " 346: 0.45669686411149824,\n",
       " 347: 1.3266396761133603,\n",
       " 348: 1.3094105894105894,\n",
       " 349: 3.2443564356435646,\n",
       " 350: 4.096,\n",
       " 351: 1.9621556886227545,\n",
       " 352: 1.4340481400437637,\n",
       " 353: 9.709037037037037,\n",
       " 354: 0.5098094126798911,\n",
       " 355: 0.28800703142166556,\n",
       " 356: 0.44431186440677967,\n",
       " 357: 0.5963239308462238,\n",
       " 358: 1.0,\n",
       " 359: 1.0,\n",
       " 360: 1.0,\n",
       " 361: 1.5152832369942197,\n",
       " 362: 2.56,\n",
       " 363: 0.4037954405422058,\n",
       " 364: 0.23256210078069553,\n",
       " 365: 0.545451518934665,\n",
       " 366: 0.6798340248962655,\n",
       " 367: 0.7760331557134399,\n",
       " 368: 2.7887659574468087,\n",
       " 369: 2.9993592677345537,\n",
       " 370: 2.56,\n",
       " 371: 1.0,\n",
       " 372: 6.24152380952381,\n",
       " 373: 0.18303588884234046,\n",
       " 374: 0.17372034459907224,\n",
       " 375: 0.5045111624326405,\n",
       " 376: 0.9416091954022988,\n",
       " 377: 0.7728301886792452,\n",
       " 378: 2.057645211930926,\n",
       " 379: 1.0,\n",
       " 380: 1.0,\n",
       " 381: 1.0,\n",
       " 382: 1.09044925124792,\n",
       " 383: 0.3374665293511843,\n",
       " 384: 0.40743549891202985,\n",
       " 385: 1.5887515151515152,\n",
       " 386: 6.24152380952381,\n",
       " 387: 2.719336099585062,\n",
       " 388: 1.0,\n",
       " 389: 1.0,\n",
       " 390: 1.0,\n",
       " 391: 1.0,\n",
       " 392: 0.11461350122420427,\n",
       " 393: 0.4429604596147347,\n",
       " 394: 6.331980676328502,\n",
       " 395: 1.0,\n",
       " 396: 1.0,\n",
       " 397: 1.0,\n",
       " 398: 1.0,\n",
       " 399: 1.0,\n",
       " 400: 0.6833785192909281,\n",
       " 401: 0.6986780383795309,\n",
       " 402: 0.94025824964132,\n",
       " 403: 1.476036036036036,\n",
       " 404: 1.0,\n",
       " 405: 1.0,\n",
       " 406: 4.909063670411985,\n",
       " 407: 1.0,\n",
       " 408: 1.0,\n",
       " 409: 1.0,\n",
       " 410: 0.5875033617212012,\n",
       " 411: 0.8820457604306864,\n",
       " 412: 1.0,\n",
       " 413: 1.0,\n",
       " 414: 1.0,\n",
       " 415: 1.9078893740902474,\n",
       " 416: 1.080560593569662,\n",
       " 417: 1.0,\n",
       " 418: 3.0062385321100917,\n",
       " 419: 2.830928725701944,\n",
       " 420: 0.992969696969697,\n",
       " 421: 2.0904625199362044,\n",
       " 422: 1.344328205128205,\n",
       " 423: 3.640888888888889,\n",
       " 424: 1.4048445873526259,\n",
       " 425: 0.5249179014817781,\n",
       " 426: 15.984390243902439,\n",
       " 427: 1.0,\n",
       " 428: 0.6139203747072599,\n",
       " 429: 1.2938993089832183,\n",
       " 430: 0.7434600113442995,\n",
       " 431: 11.497543859649122,\n",
       " 432: 1.9218768328445748,\n",
       " 433: 5.1000778210116735,\n",
       " 434: 0.8212531328320802,\n",
       " 435: 1.2272659176029963,\n",
       " 436: 1.0,\n",
       " 437: 2.2405470085470087,\n",
       " 438: 0.3874430978421519,\n",
       " 439: 3.076807511737089,\n",
       " 440: 1.2938993089832183,\n",
       " 441: 1.8644665718349929,\n",
       " 442: 2.6162075848303394,\n",
       " 443: 0.6139203747072599,\n",
       " 444: 0.5639931153184166,\n",
       " 445: 1.0137045630317092,\n",
       " 446: 0.9723442136498517,\n",
       " 447: 2.9993592677345537,\n",
       " 448: 0.7607196749854904,\n",
       " 449: 9.03944827586207,\n",
       " 450: 1.0028462127008417,\n",
       " 451: 1.0,\n",
       " 452: 0.8802686366689053,\n",
       " 453: 0.5380623973727422,\n",
       " 454: 1.6062745098039215,\n",
       " 455: 0.655687843921961,\n",
       " 456: 0.9033218470020675,\n",
       " 457: 0.7131229597388465,\n",
       " 458: 9.165874125874126,\n",
       " 459: 9.102222222222222,\n",
       " 460: 1.0,\n",
       " 461: 1.0,\n",
       " 462: 0.6916728232189974,\n",
       " 463: 0.28217868675995694,\n",
       " 464: 0.7237548315847598,\n",
       " 465: 0.8892265943012212,\n",
       " 466: 0.5475020885547202,\n",
       " 467: 0.5060694980694981,\n",
       " 468: 0.7396839729119639,\n",
       " 469: 1.0,\n",
       " 470: 3.702598870056497,\n",
       " 471: 1.3054980079681275,\n",
       " 472: 0.7039312567132116,\n",
       " 473: 0.5696305953933073,\n",
       " 474: 0.8445360824742268,\n",
       " 475: 0.39207897098414596,\n",
       " 476: 0.1875672581568403,\n",
       " 477: 0.4097280400125039,\n",
       " 478: 1.0,\n",
       " 479: 1.0,\n",
       " 480: 1.0,\n",
       " 481: 1.0280156862745098,\n",
       " 482: 0.2905608512524939,\n",
       " 483: 0.6226698337292161,\n",
       " 484: 0.8274747474747475,\n",
       " 485: 0.6107735321528425,\n",
       " 486: 0.1679764193259003,\n",
       " 487: 0.8691777188328913,\n",
       " 488: 1.0,\n",
       " 489: 1.0,\n",
       " 490: 2.56,\n",
       " 491: 0.43588959095443963,\n",
       " 492: 0.7938946093276802,\n",
       " 493: 0.7096480779642664,\n",
       " 494: 2.742092050209205,\n",
       " 495: 2.1005128205128205,\n",
       " 496: 3.4675132275132277,\n",
       " 497: 1.0,\n",
       " 498: 1.0,\n",
       " 499: 1.0,\n",
       " 500: 0.7554582132564841,\n",
       " 501: 0.23948839758816007,\n",
       " 502: 1.3470914696813978,\n",
       " 503: 1.0,\n",
       " 504: 0.8051105651105651,\n",
       " 505: 0.6823112961998958,\n",
       " 506: 5.201269841269841,\n",
       " 507: 1.0,\n",
       " 508: 1.0,\n",
       " 509: 1.0,\n",
       " 510: 0.6250453028135432,\n",
       " 511: 1.7546452476572958,\n",
       " 512: 1.0,\n",
       " 513: 2.2367235494880546,\n",
       " 514: 1.9134598540145986,\n",
       " 515: 2.4317625231910944,\n",
       " 516: 1.0,\n",
       " 517: 1.7906010928961749,\n",
       " 518: 2.7306666666666666,\n",
       " 519: 1.0,\n",
       " 520: 0.49704967766401215,\n",
       " 521: 1.0,\n",
       " 522: 0.9484225759768452,\n",
       " 523: 0.7797263533610946,\n",
       " 524: 0.723355408388521,\n",
       " 525: 1.7930506155950752,\n",
       " 526: 2.173665008291874,\n",
       " 527: 0.9959878419452888,\n",
       " 528: 6.898526315789474,\n",
       " 529: 1.0,\n",
       " 530: 0.6203123521060104,\n",
       " 531: 1.0,\n",
       " 532: 0.7150681942171304,\n",
       " 533: 0.48689450222882613,\n",
       " 534: 0.7058266020463112,\n",
       " 535: 5.002748091603054,\n",
       " 536: 0.94025824964132,\n",
       " 537: 0.42932197838191943,\n",
       " 538: 1.4003418803418803,\n",
       " 539: 1.0,\n",
       " 540: 5.02191570881226,\n",
       " 541: 8.680264900662252,\n",
       " 542: 0.30847728877382913,\n",
       " 543: 0.5393909465020577,\n",
       " 544: 1.8512994350282486,\n",
       " 545: 1.2459315589353612,\n",
       " 546: 1.1872463768115942,\n",
       " 547: 0.6701022494887525,\n",
       " 548: 0.8971389459274469,\n",
       " 549: 1.0,\n",
       " 550: 1.0,\n",
       " 551: 0.8253904282115869,\n",
       " 552: 0.4266666666666667,\n",
       " 553: 0.5944308390022676,\n",
       " 554: 2.054420062695925,\n",
       " 555: 0.4087059557218584,\n",
       " 556: 0.7787997623291741,\n",
       " 557: 0.46678062678062676,\n",
       " 558: 2.6914168377823406,\n",
       " 559: 1.0,\n",
       " 560: 0.7948574893875076,\n",
       " 561: 0.6589844142785319,\n",
       " 562: 1.0717252657399836,\n",
       " 563: 0.8533333333333334,\n",
       " 564: 0.497426944971537,\n",
       " 565: 0.40119987756351394,\n",
       " 566: 0.23983897529734674,\n",
       " 567: 0.7005451630144308,\n",
       " 568: 1.3146639919759278,\n",
       " 569: 1.0,\n",
       " 570: 0.7598376811594203,\n",
       " 571: 0.575129442738043,\n",
       " 572: 1.09044925124792,\n",
       " 573: 1.3081037924151697,\n",
       " 574: 0.30291657037208225,\n",
       " 575: 0.16593492847195848,\n",
       " 576: 0.5867144136078782,\n",
       " 577: 0.45749389179755673,\n",
       " 578: 2.9925114155251142,\n",
       " 579: 1.0,\n",
       " 580: 1.0,\n",
       " 581: 0.3859599528857479,\n",
       " 582: 1.0,\n",
       " 583: 1.0,\n",
       " 584: 0.35092904953145915,\n",
       " 585: 0.21980882106322322,\n",
       " 586: 0.7647141190198367,\n",
       " 587: 2.5700392156862746,\n",
       " 588: 1.0,\n",
       " 589: 1.0,\n",
       " 590: 0.21389033942558747,\n",
       " 591: 0.8946894197952219,\n",
       " 592: 1.0,\n",
       " 593: 0.41835939993616345,\n",
       " 594: 0.2731804918716132,\n",
       " 595: 0.9967452471482889,\n",
       " 596: 6.3015384615384615,\n",
       " 597: 1.0,\n",
       " 598: 1.0,\n",
       " 599: 1.0,\n",
       " 600: 0.3487812666311868,\n",
       " 601: 0.6085051067780873,\n",
       " 602: 2.708099173553719,\n",
       " 603: 0.5551545955103769,\n",
       " 604: 0.48545185185185186,\n",
       " 605: 1.0,\n",
       " 606: 4.269446254071661,\n",
       " 607: 1.0,\n",
       " 608: 2.837056277056277,\n",
       " 609: 1.0,\n",
       " 610: 0.4251443399286409,\n",
       " 611: 2.3405714285714287,\n",
       " 612: 0.5625407725321888,\n",
       " 613: 1.9889529590288315,\n",
       " 614: 5.799646017699115,\n",
       " 615: 1.0,\n",
       " 616: 3.777291066282421,\n",
       " 617: 1.4371929824561402,\n",
       " 618: 1.0,\n",
       " 619: 1.0,\n",
       " 620: 9.637647058823529,\n",
       " 621: 0.6690760592138847,\n",
       " 622: 0.5666753134457415,\n",
       " 623: 1.636354556803995,\n",
       " 624: 1.8280613668061367,\n",
       " 625: 1.1829602888086643,\n",
       " 626: 1.0814521452145214,\n",
       " 627: 2.56,\n",
       " 628: 1.0,\n",
       " 629: 1.0,\n",
       " 630: 19.275294117647057,\n",
       " 631: 0.38313943291435254,\n",
       " 632: 0.7515596330275229,\n",
       " 633: 0.8011735941320294,\n",
       " 634: 1.7930506155950752,\n",
       " 635: 0.4254203180785459,\n",
       " 636: 0.4671133285816108,\n",
       " 637: 7.447272727272727,\n",
       " 638: 327.68,\n",
       " 639: 1.0,\n",
       " 640: 0.5786843267108168,\n",
       " 641: 0.477319737800437,\n",
       " 642: 1.208036866359447,\n",
       " 643: 1.1723792486583184,\n",
       " 644: 1.312032032032032,\n",
       " 645: 1.2688480154888673,\n",
       " 646: 0.8691777188328913,\n",
       " 647: 1.002079510703364,\n",
       " 648: 1.0,\n",
       " 649: 1.0,\n",
       " 650: 0.521368337311058,\n",
       " 651: 1.1467366579177602,\n",
       " 652: 1.4483093922651933,\n",
       " 653: 0.7558938869665514,\n",
       " 654: 0.3433001571503405,\n",
       " 655: 0.6680530071355759,\n",
       " 656: 0.3275981004748813,\n",
       " 657: 0.9855037593984962,\n",
       " 658: 1.5384037558685446,\n",
       " 659: 1.0,\n",
       " 660: 1.9051162790697675,\n",
       " 661: 1.4293565976008724,\n",
       " 662: 0.9803440538519073,\n",
       " 663: 0.4921967705595193,\n",
       " 664: 0.18502540937323547,\n",
       " 665: 0.8600524934383202,\n",
       " 666: 1.1126655348047538,\n",
       " 667: 0.45797344514325644,\n",
       " 668: 1.0,\n",
       " 669: 1.0,\n",
       " 670: 1.2483047619047618,\n",
       " 671: 1.221547064305685,\n",
       " 672: 0.541396117306898,\n",
       " 673: 0.34285116400732407,\n",
       " 674: 0.19947040024349413,\n",
       " 675: 1.3173065326633167,\n",
       " 676: 1.7000259403372244,\n",
       " 677: 1.0,\n",
       " 678: 1.0,\n",
       " 679: 1.0,\n",
       " 680: 0.512,\n",
       " 681: 0.8832345013477089,\n",
       " 682: 0.8115913312693498,\n",
       " 683: 0.24582145536384095,\n",
       " 684: 0.3195319356411507,\n",
       " 685: 1.1427375762859633,\n",
       " 686: 2.7652320675105484,\n",
       " 687: 1.0,\n",
       " 688: 1.0,\n",
       " 689: 1.0,\n",
       " 690: 0.8483624595469256,\n",
       " 691: 2.051205007824726,\n",
       " 692: 0.3330927573062262,\n",
       " 693: 0.3108181171448897,\n",
       " 694: 0.6238553069966682,\n",
       " 695: 1.0,\n",
       " 696: 4.714820143884892,\n",
       " 697: 1.0,\n",
       " 698: 1.0,\n",
       " 699: 1.0,\n",
       " 700: 1.0,\n",
       " 701: 0.2624064064064064,\n",
       " 702: 0.3086225570991288,\n",
       " 703: 0.3559804454101032,\n",
       " 704: 0.6636556962025316,\n",
       " 705: 1.0,\n",
       " 706: 2.56,\n",
       " 707: 2.8432104121475055,\n",
       " 708: 1.0,\n",
       " 709: 1.0,\n",
       " 710: 0.7417770232031692,\n",
       " 711: 0.3933733493397359,\n",
       " 712: 0.34348008385744233,\n",
       " 713: 1.7664690026954177,\n",
       " 714: 1.0814521452145214,\n",
       " 715: 1.042736674622116,\n",
       " 716: 0.668734693877551,\n",
       " 717: 2.945438202247191,\n",
       " 718: 1.0,\n",
       " 719: 1.0,\n",
       " 720: 0.5278775674587193,\n",
       " 721: 0.5514177534707615,\n",
       " 722: 1.7360529801324502,\n",
       " 723: 1.0,\n",
       " 724: 1.221547064305685,\n",
       " 725: 0.47386840202458425,\n",
       " 726: 1.985939393939394,\n",
       " 727: 2.9388340807174886,\n",
       " 728: 1.0,\n",
       " 729: 1.0,\n",
       " 730: 0.42213204508856683,\n",
       " 731: 0.9309090909090909,\n",
       " 732: 1.8280613668061367,\n",
       " 733: 1.8434880450070323,\n",
       " 734: 0.44887671232876714,\n",
       " 735: 1.208036866359447,\n",
       " 736: 1.0,\n",
       " 737: 1.0,\n",
       " 738: 1.0,\n",
       " 739: 1.0,\n",
       " 740: 0.7589577301679212,\n",
       " 741: 0.9436429085673146,\n",
       " 742: 1.4231487513572205,\n",
       " 743: 0.8820457604306864,\n",
       " 744: 0.7261606648199446,\n",
       " 745: 0.6265391969407266,\n",
       " 746: 1.4293565976008724,\n",
       " 747: 1.0,\n",
       " 748: 2.7710782241014797,\n",
       " 749: 1.0,\n",
       " 750: 0.9416091954022988,\n",
       " 751: 6.826666666666667,\n",
       " 752: 0.5491076665270214,\n",
       " 753: 0.4408745375042045,\n",
       " 754: 0.3425823314166231,\n",
       " 755: 0.5733683289588801,\n",
       " 756: 6.721641025641025,\n",
       " 757: 1.0,\n",
       " 758: 1.0,\n",
       " 759: 1.0,\n",
       " 760: 2.56,\n",
       " 761: 6.898526315789474,\n",
       " 762: 0.5209538950715421,\n",
       " 763: 0.2580157480314961,\n",
       " 764: 0.7783372921615201,\n",
       " 765: 1.1937340619307832,\n",
       " 766: 1.1894010889292197,\n",
       " 767: 10.16062015503876,\n",
       " 768: 1.0,\n",
       " 769: 1.0,\n",
       " 770: 2.56,\n",
       " 771: 6.271387559808613,\n",
       " 772: 0.3039703153988868,\n",
       " 773: 0.6211943127962085,\n",
       " 774: 5.1000778210116735,\n",
       " 775: 1.9919756838905776,\n",
       " 776: 1.0,\n",
       " 777: 1.0,\n",
       " 778: 1.0,\n",
       " 779: 3.95987915407855,\n",
       " 780: 0.512,\n",
       " 781: 0.3731056077426701,\n",
       " 782: 0.16100233386561846,\n",
       " 783: 0.3879017460787215,\n",
       " 784: 1.0,\n",
       " 785: 0.870332005312085,\n",
       " 786: 1.3293306288032454,\n",
       " 787: 1.0,\n",
       " 788: 1.0,\n",
       " 789: 1.0,\n",
       " 790: 5.1000778210116735,\n",
       " 791: 0.4138680138932744,\n",
       " 792: 0.3321642169285352,\n",
       " 793: 0.6916728232189974,\n",
       " 794: 4.551111111111111,\n",
       " 795: 1.0,\n",
       " 796: 1.0,\n",
       " 797: 1.0,\n",
       " 798: 1.0,\n",
       " 799: 1.0,\n",
       " 800: 0.3005549185966521,\n",
       " 801: 0.11696591111904336,\n",
       " 802: 0.39325532553255327,\n",
       " 803: 0.19415197748481705,\n",
       " 804: 0.42037203335471457,\n",
       " 805: 0.35092904953145915,\n",
       " 806: 2.8493913043478263,\n",
       " 807: 1.0,\n",
       " 808: 1.0,\n",
       " 809: 1.0,\n",
       " 810: 0.20267821246327508,\n",
       " 811: 0.24721237268955112,\n",
       " 812: 0.244309412861137,\n",
       " 813: 0.3451988411904135,\n",
       " 814: 0.3944387601564851,\n",
       " 815: 1.7360529801324502,\n",
       " 816: 1.0,\n",
       " 817: 1.0,\n",
       " 818: 1.0,\n",
       " 819: 1.0,\n",
       " 820: 0.44552005438477227,\n",
       " 821: 0.246190833959429,\n",
       " 822: 0.37299943084803644,\n",
       " 823: 0.7511289398280803,\n",
       " 824: 0.7714655679811654,\n",
       " 825: 1.0,\n",
       " 826: 7.447272727272727,\n",
       " 827: 1.0,\n",
       " 828: 1.0,\n",
       " 829: 1.0,\n",
       " 830: 0.9243441466854725,\n",
       " 831: 0.38539253160835046,\n",
       " 832: 0.5174575602052902,\n",
       " 833: 0.5664304235090752,\n",
       " 834: 1.2862806673209028,\n",
       " 835: 2.719336099585062,\n",
       " 836: 1.0,\n",
       " 837: 1.0,\n",
       " 838: 1.0536334405144694,\n",
       " 839: 1.0,\n",
       " 840: 0.4004644057439658,\n",
       " 841: 0.7710117647058824,\n",
       " 842: 0.6902159031068984,\n",
       " 843: 1.048576,\n",
       " 844: 0.8533333333333334,\n",
       " 845: 3.034074074074074,\n",
       " 846: 1.0,\n",
       " 847: 1.0,\n",
       " 848: 1.0,\n",
       " 849: 1.0,\n",
       " 850: 0.33625448948178555,\n",
       " 851: 0.3237144974067671,\n",
       " 852: 0.40554455445544557,\n",
       " 853: 1.1328608470181505,\n",
       " 854: 1.0,\n",
       " 855: 1.0,\n",
       " 856: 1.0,\n",
       " 857: 1.0,\n",
       " 858: 1.0,\n",
       " 859: 4.283398692810458,\n",
       " 860: 0.5618174024860695,\n",
       " 861: 0.8186883198001249,\n",
       " 862: 0.5440929846409298,\n",
       " 863: 1.0,\n",
       " 864: 9.92969696969697,\n",
       " 865: 6.6873469387755105,\n",
       " 866: 1.0,\n",
       " 867: 1.0,\n",
       " 868: 1.0,\n",
       " 869: 1.0,\n",
       " 870: 1.2091512915129152,\n",
       " 871: 0.8784986595174262,\n",
       " 872: 0.6495143706640237,\n",
       " 873: 2.56,\n",
       " 874: 2.56,\n",
       " 875: 1.0,\n",
       " 876: 1.0,\n",
       " 877: 3.971878787878788,\n",
       " 878: 1.0,\n",
       " 879: 1.0,\n",
       " 880: 0.3764273406088455,\n",
       " 881: 0.4907225758143018,\n",
       " 882: 2.56,\n",
       " 883: 7.084972972972973,\n",
       " 884: 6.068148148148148,\n",
       " 885: 1.0,\n",
       " 886: 1.0,\n",
       " 887: 1.0,\n",
       " 888: 1.0,\n",
       " 889: 1.0,\n",
       " 890: 0.7150681942171304,\n",
       " 891: 93.62285714285714,\n",
       " 892: 1.0,\n",
       " 893: 1.0,\n",
       " 894: 1.0,\n",
       " 895: 1.0,\n",
       " 896: 1.0,\n",
       " 897: 1.0,\n",
       " 898: 1.0,\n",
       " 899: 1.0,\n",
       " 900: 0.5108028059236165,\n",
       " 901: 0.10246404002501563,\n",
       " 902: 0.07398927462602314,\n",
       " 903: 0.20871337579617835,\n",
       " 904: 2.9127111111111113,\n",
       " 905: 0.6162294311236484,\n",
       " 906: 0.6200189214758751,\n",
       " 907: 3.4952533333333333,\n",
       " 908: 1.0,\n",
       " 909: 1.0,\n",
       " 910: 0.20508840557033328,\n",
       " 911: 0.15906796116504854,\n",
       " 912: 0.2465149520406244,\n",
       " 913: 0.9623494860499265,\n",
       " 914: 4.020613496932516,\n",
       " 915: 6.0124770642201835,\n",
       " 916: 1.3016087388282025,\n",
       " 917: 3.5045989304812832,\n",
       " 918: 3.6510306406685236,\n",
       " 919: 1.0,\n",
       " 920: 0.22374871969955618,\n",
       " 921: 0.2523041385948027,\n",
       " 922: 1.147740805604203,\n",
       " 923: 3.855058823529412,\n",
       " 924: 1.0,\n",
       " 925: 1.0,\n",
       " 926: 1.0,\n",
       " 927: 1.2926232741617356,\n",
       " 928: 1.0,\n",
       " 929: 1.0,\n",
       " 930: 0.18549674497594112,\n",
       " 931: 0.6096372093023256,\n",
       " 932: 1.0,\n",
       " 933: 1.0,\n",
       " 934: 1.0,\n",
       " 935: 7.489828571428571,\n",
       " 936: 5.674112554112554,\n",
       " 937: 5.9850228310502285,\n",
       " 938: 1.0,\n",
       " 939: 1.0,\n",
       " 940: 0.2921801159161837,\n",
       " 941: 1.6528625472887768,\n",
       " 942: 1.0,\n",
       " 943: 1.0,\n",
       " 944: 3.713087818696884,\n",
       " 945: 2.68040899795501,\n",
       " 946: 1.0,\n",
       " 947: 87.38133333333333,\n",
       " 948: 100.82461538461538,\n",
       " 949: 1.0,\n",
       " 950: 2.932259507829978,\n",
       " 951: 2.56,\n",
       " 952: 1.0,\n",
       " 953: 1.968048048048048,\n",
       " 954: 1.0,\n",
       " 955: 1.0,\n",
       " 956: 1.0,\n",
       " 957: 1.518794901506373,\n",
       " 958: 109.22666666666667,\n",
       " 959: 0.7987324801950031,\n",
       " 960: 0.609353788935379,\n",
       " 961: 1.0,\n",
       " 962: 1.0,\n",
       " 963: 1.0,\n",
       " 964: 1.0,\n",
       " 965: 1.0,\n",
       " 966: 1.0,\n",
       " 967: 2.5352417794970985,\n",
       " 968: 1.0,\n",
       " 969: 2.742092050209205,\n",
       " 970: 0.7253569452130603,\n",
       " 971: 1.0,\n",
       " 972: 1.0,\n",
       " 973: 1.0,\n",
       " 974: 1.0,\n",
       " 975: 1.608245398773006,\n",
       " 976: 1.0,\n",
       " 977: 1.995007610350076,\n",
       " 978: 1.6161775585696672,\n",
       " 979: 1.1136108751062022,\n",
       " 980: 2.404990825688073,\n",
       " 981: 1.0,\n",
       " 982: 1.0,\n",
       " 983: 1.0,\n",
       " 984: 1.0,\n",
       " 985: 1.0,\n",
       " 986: 1.0,\n",
       " 987: 1.0,\n",
       " 988: 1.0,\n",
       " 989: 1.1568578993821712,\n",
       " 990: 1.0,\n",
       " 991: 1.0,\n",
       " 992: 1.0,\n",
       " 993: 1.0,\n",
       " 994: 1.0,\n",
       " 995: 1.0,\n",
       " 996: 1.0,\n",
       " 997: 1.4387705817782657,\n",
       " 998: 1.0,\n",
       " 999: 0.04456260837044844,\n",
       " ...}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Copy the class weights\n",
    "if not os.path.exists(\"/content/class_weights.npy\"):\n",
    "  !gsutil -m cp -r gs://crypto_nlp_training/four_float_to_int/class_weights.npy /content/class_weights.npy\n",
    "\n",
    "# Load the class weights\n",
    "cwnp = np.load(\"/content/class_weights.npy\")\n",
    "\n",
    "CLASS_WEIGHTS_DICT = {}\n",
    "\n",
    "for i in range(cwnp.shape[0]):\n",
    "  CLASS_WEIGHTS_DICT[i] = cwnp[i]\n",
    "\n",
    "CLASS_WEIGHTS_DICT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J9cA0AKquwZ2"
   },
   "source": [
    "---\n",
    "# Prepare data source\n",
    "\n",
    "For training a neural network, first the data source has to be prepared. For this purpose, the method `FileListToDataStream` from the `DataStreamCreator` class is used. This method creates a stream of `X-Block` and `y-data` arrays out of a list of .csv file names, pointing to tick tables (called `EXAMPLE_FILE_PATHS` in this example). For details about `X-Blocks` and `y-data`, please refer to the documentation of the `XBlockGenerator` and the `YDataGenerator` under https://github.com/girsigit/CryptoCrystalBall/tree/main/DataStreamCreator.\n",
    "\n",
    "<br>\n",
    "\n",
    "Target values (y-data) from the data generator would not be necessary in this notebook, but since it cannot be switched off, the future direction and its derviation of the price have been chosen in `Y_TYPE_DICT` since they are not expensive to compute. A switch flag will be added in a future release."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pqze4dT8uz6V",
    "outputId": "985dae70-a5db-4972-bde2-b52e5b15c6b5",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dataType': 0,\n",
       " 'direction_ma_timespan': 200,\n",
       " 'derivation_ma_timespan': 100,\n",
       " 'direction_derivation_shift_span': 0}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set direction and derivation information as y target\n",
    "# Both y values (direction & derivation) are in the interval [-1.0,1.0]\n",
    "\n",
    "Y_TYPE_DICT = copy.deepcopy(DataStreamCreator.YDataGenerator.PARAM_DICT_TEMPLATE_Y_DATA_TYPE_DIRECTION_FLOAT)\n",
    "Y_TYPE_DICT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mlb37_K21h7j",
    "outputId": "473038a5-e93d-4ba8-e917-4da2ba5ba05f",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "77"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate how many word shall be replaced\n",
    "replace_index_number = int(np.round(X_BLOCK_LENGHT * MLM_MASK_FACTOR))\n",
    "replace_index_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1gVe75Q51mHH",
    "outputId": "3dba72d9-8963-4293-b88c-f11421c1d0e3",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 77)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[473,  81, 444,  43, 294, 144, 131, 289, 113, 332, 321, 210, 206,\n",
       "        230, 120,  69,  54, 242,  58, 146, 429, 161,  39, 394, 132, 478,\n",
       "        414, 172, 252, 114, 222, 330, 492, 225, 225, 328, 468, 285, 274,\n",
       "        227,  71, 479, 327, 486, 232, 199, 315, 344, 391, 159, 151, 103,\n",
       "        146, 358, 473, 175, 359, 328,  22, 379,  10, 416, 145, 224, 476,\n",
       "        277, 462, 201, 304, 459,  83, 415,  95, 324, 263, 373,  19],\n",
       "       [467, 395, 491, 116, 346, 184, 134, 201, 388, 199, 469, 323, 508,\n",
       "        370, 246, 115, 337, 297, 302,  82, 410, 317, 441,  73, 279, 187,\n",
       "        276, 137, 395, 454,   6, 154,  17, 113, 130,  14, 139, 283, 122,\n",
       "        280, 115, 336, 408, 510, 327, 479, 404, 436,  41, 275, 352, 230,\n",
       "        479, 332,  58, 416, 282, 475, 331, 316,  25, 207, 228, 290,  87,\n",
       "        253, 387, 371, 118, 266, 302, 178, 292, 472, 122, 347, 328],\n",
       "       [456, 250, 215, 242, 115, 234, 454, 242, 174,  73, 460, 128, 366,\n",
       "        429, 299, 322,  99,  84,  65, 511, 145, 264,  97, 372, 485, 436,\n",
       "        401, 108, 371,  74,  76, 414, 476, 480, 177, 198,   3, 280, 292,\n",
       "        394,  38, 117, 462, 139,  97, 313, 209, 328, 486, 125, 232, 365,\n",
       "        458,  35, 182, 389, 228, 400, 111, 190, 345, 313, 506, 250, 415,\n",
       "        457, 414, 171, 296, 113, 265, 374, 174,  28,  41,  84, 440],\n",
       "       [430, 507, 288, 145, 189, 434, 357,  66, 226, 387,  33, 180,  80,\n",
       "        345, 486, 123, 194,  97, 381, 198, 353, 386, 429, 192, 191,  25,\n",
       "        492, 400, 109, 293, 474, 263, 468,   8, 233, 253, 388, 236, 257,\n",
       "        453,  81, 157, 439, 497, 126, 103, 467,   4, 182, 423, 487, 166,\n",
       "         94, 277,   8, 489, 273,  79, 330, 329,  94, 465, 195, 294, 151,\n",
       "          0, 373, 487, 120, 333, 366,  69,  19, 435, 246, 212,  81],\n",
       "       [151, 380,   2, 408,  44, 290, 181,  80, 262, 105,  60, 258, 141,\n",
       "        248, 176, 135, 126, 424, 433, 226, 343, 432, 293,  21, 396,  52,\n",
       "         90, 441, 244, 268,  54, 309, 416, 367, 228,  82,  94,  17,  27,\n",
       "        348, 369, 298, 243, 370, 348, 200, 399, 205, 494, 356, 423,  75,\n",
       "        471, 179, 447, 415, 385,  99,  20,  59,   9, 431, 397,  56, 418,\n",
       "        362, 113, 218, 334,  44, 336, 326, 138, 432, 499, 286, 452]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create random indices, to replace 'words' with MASK_TOKEN_I\n",
    "mask_positions = np.round(np.random.rand(BATCH_SIZE, replace_index_number) * X_BLOCK_LENGHT).astype(int)\n",
    "print(mask_positions.shape)\n",
    "mask_positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 336
    },
    "id": "vVctAErd2wzo",
    "outputId": "435f0cae-bf0a-4446-9078-bafb66dd4fbf",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([30., 40., 45., 33., 38., 39., 40., 40., 40., 40.]),\n",
       " array([  0. ,  51.1, 102.2, 153.3, 204.4, 255.5, 306.6, 357.7, 408.8,\n",
       "        459.9, 511. ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(mask_positions.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "a7iuksPdCSrZ",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Method for normalizing the distribution of one digit\n",
    "def NormalizeDigitDistribution(dataIn, categoryLimitValues):\n",
    "  normalizedDistribution = np.empty(dataIn.shape)\n",
    "\n",
    "  for i, lim in enumerate(categoryLimitValues):\n",
    "    normalizedDistribution[(dataIn >= lim[0]) & (dataIn <= lim[1])] = i\n",
    "\n",
    "  return normalizedDistribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "d4kZzefRCRhB",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Method for converting a four-float vector into an integer 'word' in the range of 0-10000\n",
    "def ConvertFourFloatDataToWords(fourFloatIn, digitLimits):\n",
    "  # Normalize each digit\n",
    "  digitsNormalized = []\n",
    "\n",
    "  for digit in range(4):\n",
    "    digitsNormalized.append(\n",
    "        NormalizeDigitDistribution(fourFloatIn[:,:,digit], digitLimits[digit])\n",
    "        )\n",
    "    \n",
    "  # Combine the digits to one integer (creating the 'word')\n",
    "  intData = digitsNormalized[0] * 1000 + digitsNormalized[1] * 100 + digitsNormalized[2] * 10 + digitsNormalized[3]\n",
    "  intData = intData.astype(np.int32)  \n",
    "\n",
    "  del digitsNormalized\n",
    "\n",
    "  return intData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "S2e6q_2su26o",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# A python generator function has to be applied on the dataStream\n",
    "\n",
    "def pythonGeneratorMLMTraining():\n",
    "  # Initialize the FileListToDataStream generator\n",
    "  dataStreamTraining = DataStreamCreator.FileListToDataStream(fileList = TRAIN_FILES,\n",
    "                                                      batch_size = BATCH_SIZE,\n",
    "                                                      X_Block_lenght = X_BLOCK_LENGHT,\n",
    "                                                      y_type_dict=Y_TYPE_DICT,\n",
    "                                                      shuffle=True,\n",
    "                                                      parallel_generators = BATCH_SIZE,\n",
    "                                                      random_seed = RANDOM_SEED,\n",
    "                                                      **DATA_STREAM_PARAMETERS\n",
    "                                                      )\n",
    "  \n",
    "  # Calculate how many word shall be replaced\n",
    "  mask_number = int(np.round(X_BLOCK_LENGHT * MLM_MASK_FACTOR))\n",
    "  logging.info(f\"In each batch of X-Blocks, {mask_number*BATCH_SIZE} elements will be randomly masked. This is an average of {mask_number} per X-Block\")\n",
    "\n",
    "  # This while has to integrated into the FileListToDataStream method\n",
    "  while True:  \n",
    "    try:\n",
    "      ne = next(dataStreamTraining)\n",
    "      _X = ne['X']\n",
    "\n",
    "      # Convert the X-Block into a sentence\n",
    "      with tf.device('/CPU:0'):        \n",
    "        four_float_sentence = fourFloatClassifierModel.predict(_X, batch_size = BATCH_SIZE, verbose = 0)\n",
    "        int_sentence = ConvertFourFloatDataToWords(four_float_sentence, digitLimits)\n",
    "\n",
    "        # _X_sentence = intClassifierModel.predict(_X, batch_size = BATCH_SIZE, verbose = 0)\n",
    "\n",
    "      # Round to avoid too many categories\n",
    "      # Todo: Better classifier model!\n",
    "      # _X_sentence = np.round(_X_sentence / 10.0).astype(int)\n",
    "\n",
    "      # Create random indices, to replace 'words' with MASK_TOKEN_I\n",
    "      mask_positions = np.round(np.random.rand(BATCH_SIZE, mask_number) * X_BLOCK_LENGHT * BATCH_SIZE).astype(int)\n",
    "      mask_positions[mask_positions == X_BLOCK_LENGHT * BATCH_SIZE] -= 1  # Avoid the upper array limit\n",
    "\n",
    "      # Mask the chosen tokens\n",
    "      int_sentence_masked = np.array(int_sentence).flatten()\n",
    "      int_sentence_masked[mask_positions] = MASK_TOKEN_ID\n",
    "      int_sentence_masked = int_sentence_masked.reshape(int_sentence.shape)\n",
    "\n",
    "      # print(mask_positions[0,0])\n",
    "\n",
    "      # 'Remove' all tokens that shall not be predicted from the training y data (the full sentence), so that the network can focus on the missing tokens\n",
    "      # More precise: Setting them to -1 tells the loss function to ignore them\n",
    "      int_sentence[int_sentence_masked != MASK_TOKEN_ID] = -1\n",
    "\n",
    "      # Not required here, as the network shall predict back its original input\n",
    "      # _y = ne['y']\n",
    "      \n",
    "      # Return the masked senteces as X data, the full ones are the y-data --> The network shall predict the missing tokens\n",
    "      yield (int_sentence_masked, int_sentence)\n",
    "    except StopIteration as si:\n",
    "      logging.warning(\"StopIteration in pythonGenerator\")\n",
    "      logging.warning(si)\n",
    "      return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FoTRNHyEvnyg",
    "outputId": "d7fb1944-9236-47c2-c749-8a999e6fe3e3",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<FlatMapDataset element_spec=(TensorSpec(shape=(5, 512), dtype=tf.int32, name=None), TensorSpec(shape=(5, 512), dtype=tf.int32, name=None))>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a Tensorflow dataset out of the python generator, which can be fed to the network\n",
    "tfGenTraining = tf.data.Dataset.from_generator(pythonGeneratorMLMTraining, \n",
    "                                               output_types = (tf.int32, tf.int32),\n",
    "                                               output_shapes=(\n",
    "                                                   (BATCH_SIZE, X_BLOCK_LENGHT),\n",
    "                                                   (BATCH_SIZE, X_BLOCK_LENGHT)\n",
    "                                                   )\n",
    "                                               )\n",
    "tfGenTraining.prefetch(buffer_size=2)\n",
    "tfGenTraining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YST-Iwzsv4GO",
    "outputId": "5bcf6d64-6742-46d2-a6da-860fd98e47b2",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:File 'GOLD-USDT.csv' loaded, 120 left\n",
      "INFO:root:File 'FIL-USDT.csv' loaded, 119 left\n",
      "INFO:root:File 'OCEAN-USDT.csv' loaded, 118 left\n",
      "INFO:root:File 'COMP-USDT.csv' loaded, 117 left\n",
      "INFO:root:File 'VLX-USDT.csv' loaded, 116 left\n",
      "INFO:root:In each batch of X-Blocks, 385 elements will be randomly masked. This is an average of 77 per X-Block\n"
     ]
    }
   ],
   "source": [
    "it = tfGenTraining.as_numpy_iterator()\n",
    "\n",
    "ne = next(it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fUxLLmbB3gu2",
    "outputId": "47b8b7f0-9e8e-4ca1-e7de-fe1619e0193a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4443, 4443, 4443, ..., 5764,    3, 6751],\n",
       "       [4443,    3, 4443, ...,    3, 5605, 7704],\n",
       "       [   3, 4443, 4443, ..., 3510,    3, 3610],\n",
       "       [4443, 4443, 4443, ..., 9653, 7741, 6730],\n",
       "       [   3, 4443, 4443, ..., 2196, 2197, 9579]], dtype=int32)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ne[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wh8PxiukwI4r",
    "outputId": "08907604-1651-4f5e-9552-228b10bb71fb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  -1,   -1,   -1, ...,   -1, 5653,   -1],\n",
       "       [  -1, 4443,   -1, ..., 4606,   -1,   -1],\n",
       "       [4443,   -1,   -1, ...,   -1, 2510,   -1],\n",
       "       [  -1,   -1,   -1, ...,   -1,   -1,   -1],\n",
       "       [4443,   -1,   -1, ...,   -1,   -1,   -1]], dtype=int32)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ne[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 354
    },
    "id": "n7Ge9vX8C2q3",
    "outputId": "0dfd442e-7bcc-43fc-951c-3be50f20a210"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([532., 196., 241., 236., 343., 236., 205., 201., 183., 187.]),\n",
       " array([3.000e+00, 1.001e+03, 1.999e+03, 2.997e+03, 3.995e+03, 4.993e+03,\n",
       "        5.991e+03, 6.989e+03, 7.987e+03, 8.985e+03, 9.983e+03]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAigAAAGdCAYAAAA44ojeAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/P9b71AAAACXBIWXMAAA9hAAAPYQGoP6dpAAAhj0lEQVR4nO3dbXBU5f3/8c+amyXEZEuSknUlYJjGerPB0mARSguaEIrc1KFTVBBxSmdAIJICRTCdkTqaUGYE6lDpyDBATTFOR7FaLSVpNcoEBAOpCbTejBGCZk3VuBskbiBc/wf9cf5dAupCkr0C79fMPsg53yzXuXDMe87uEpcxxggAAMAil8V6AQAAAGciUAAAgHUIFAAAYB0CBQAAWIdAAQAA1iFQAACAdQgUAABgHQIFAABYJz7WCzgfp06d0ocffqiUlBS5XK5YLwcAAHwNxhi1tbXJ5/Ppssu+/B5JnwyUDz/8UFlZWbFeBgAAOA9NTU0aNGjQl870yUBJSUmR9N8LTE1NjfFqAADA1xEKhZSVleX8HP8yfTJQTr+sk5qaSqAAANDHfJ23Z/AmWQAAYB0CBQAAWIdAAQAA1iFQAACAdQgUAABgHQIFAABYh0ABAADWIVAAAIB1CBQAAGAdAgUAAFiHQAEAANYhUAAAgHUIFAAAYB0CBQAAWCc+1guw0VXLX4z1EqL2/qpJsV4CAADdhjsoAADAOgQKAACwDoECAACsQ6AAAADrECgAAMA6BAoAALAOgQIAAKxDoAAAAOsQKAAAwDoECgAAsA6BAgAArEOgAAAA6xAoAADAOgQKAACwDoECAACsQ6AAAADrRBUoK1eulMvlinh4vV7nvDFGK1eulM/nU1JSksaNG6eDBw9GPEc4HFZRUZEyMjKUnJysqVOn6ujRo91zNQAA4KIQ9R2U66+/Xs3Nzc6jvr7eObd69WqtWbNG69ev1759++T1ejV+/Hi1tbU5M8XFxdq+fbsqKiq0a9cuHTt2TJMnT1ZnZ2f3XBEAAOjz4qP+hvj4iLsmpxljtG7dOpWUlGjatGmSpK1btyozM1Pbtm3T3LlzFQwGtWnTJj355JMqKCiQJJWXlysrK0tVVVWaMGHCBV4OAAC4GER9B+Wdd96Rz+dTdna27rjjDr333nuSpMbGRgUCARUWFjqzbrdbY8eOVU1NjSSptrZWJ06ciJjx+Xzy+/3OzNmEw2GFQqGIBwAAuHhFFSgjR47UH/7wB/3tb3/Txo0bFQgENHr0aH3yyScKBAKSpMzMzIjvyczMdM4FAgElJiZqwIAB55w5m7KyMnk8HueRlZUVzbIBAEAfE1WgTJw4UT/5yU+Um5urgoICvfjii5L++1LOaS6XK+J7jDFdjp3pq2ZWrFihYDDoPJqamqJZNgAA6GMu6GPGycnJys3N1TvvvOO8L+XMOyEtLS3OXRWv16uOjg61traec+Zs3G63UlNTIx4AAODidUGBEg6H9a9//UtXXHGFsrOz5fV6VVlZ6Zzv6OhQdXW1Ro8eLUnKy8tTQkJCxExzc7MaGhqcGQAAgKg+xbN06VJNmTJFgwcPVktLix5++GGFQiHNnj1bLpdLxcXFKi0tVU5OjnJyclRaWqr+/ftrxowZkiSPx6M5c+ZoyZIlSk9PV1pampYuXeq8ZAQAACBFGShHjx7VnXfeqY8//ljf/OY3ddNNN2nPnj0aMmSIJGnZsmVqb2/X/Pnz1draqpEjR2rnzp1KSUlxnmPt2rWKj4/X9OnT1d7ervz8fG3ZskVxcXHde2UAAKDPchljTKwXEa1QKCSPx6NgMNgj70e5avmL3f6cPe39VZNivQQAAL5UND+/+V08AADAOgQKAACwDoECAACsQ6AAAADrECgAAMA6BAoAALAOgQIAAKxDoAAAAOsQKAAAwDoECgAAsA6BAgAArEOgAAAA6xAoAADAOgQKAACwDoECAACsQ6AAAADrECgAAMA6BAoAALAOgQIAAKxDoAAAAOsQKAAAwDoECgAAsA6BAgAArEOgAAAA6xAoAADAOgQKAACwDoECAACsQ6AAAADrECgAAMA6BAoAALAOgQIAAKxDoAAAAOsQKAAAwDoECgAAsA6BAgAArEOgAAAA6xAoAADAOgQKAACwDoECAACsQ6AAAADrECgAAMA6BAoAALAOgQIAAKxDoAAAAOsQKAAAwDoECgAAsA6BAgAArEOgAAAA6xAoAADAOgQKAACwDoECAACsQ6AAAADrECgAAMA6BAoAALAOgQIAAKxzQYFSVlYml8ul4uJi55gxRitXrpTP51NSUpLGjRungwcPRnxfOBxWUVGRMjIylJycrKlTp+ro0aMXshQAAHAROe9A2bdvn5544gkNGzYs4vjq1au1Zs0arV+/Xvv27ZPX69X48ePV1tbmzBQXF2v79u2qqKjQrl27dOzYMU2ePFmdnZ3nfyUAAOCicV6BcuzYMc2cOVMbN27UgAEDnOPGGK1bt04lJSWaNm2a/H6/tm7dquPHj2vbtm2SpGAwqE2bNunRRx9VQUGBhg8frvLyctXX16uqqqp7rgoAAPRp5xUoCxYs0KRJk1RQUBBxvLGxUYFAQIWFhc4xt9utsWPHqqamRpJUW1urEydORMz4fD75/X5nBgAAXNrio/2GiooK7d+/X/v27etyLhAISJIyMzMjjmdmZurw4cPOTGJiYsSdl9Mzp7//TOFwWOFw2Pk6FApFu2wAANCHRHUHpampSYsWLVJ5ebn69et3zjmXyxXxtTGmy7EzfdlMWVmZPB6P88jKyopm2QAAoI+JKlBqa2vV0tKivLw8xcfHKz4+XtXV1XrssccUHx/v3Dk5805IS0uLc87r9aqjo0Otra3nnDnTihUrFAwGnUdTU1M0ywYAAH1MVIGSn5+v+vp61dXVOY8RI0Zo5syZqqur09ChQ+X1elVZWel8T0dHh6qrqzV69GhJUl5enhISEiJmmpub1dDQ4Mycye12KzU1NeIBAAAuXlG9ByUlJUV+vz/iWHJystLT053jxcXFKi0tVU5OjnJyclRaWqr+/ftrxowZkiSPx6M5c+ZoyZIlSk9PV1pampYuXarc3Nwub7oFAACXpqjfJPtVli1bpvb2ds2fP1+tra0aOXKkdu7cqZSUFGdm7dq1io+P1/Tp09Xe3q78/Hxt2bJFcXFx3b0cAADQB7mMMSbWi4hWKBSSx+NRMBjskZd7rlr+Yrc/Z097f9WkWC8BAIAvFc3Pb34XDwAAsA6BAgAArEOgAAAA6xAoAADAOgQKAACwDoECAACsQ6AAAADrECgAAMA6BAoAALAOgQIAAKxDoAAAAOsQKAAAwDoECgAAsA6BAgAArEOgAAAA6xAoAADAOgQKAACwDoECAACsQ6AAAADrECgAAMA6BAoAALAOgQIAAKxDoAAAAOsQKAAAwDoECgAAsA6BAgAArEOgAAAA6xAoAADAOgQKAACwDoECAACsQ6AAAADrxMd6AQB61lXLX4z1EqL2/qpJsV4CgBjjDgoAALAOgQIAAKxDoAAAAOsQKAAAwDoECgAAsA6BAgAArEOgAAAA6xAoAADAOgQKAACwDoECAACsQ6AAAADrECgAAMA6BAoAALAOgQIAAKxDoAAAAOsQKAAAwDoECgAAsA6BAgAArEOgAAAA6xAoAADAOgQKAACwDoECAACsQ6AAAADrECgAAMA6UQXKhg0bNGzYMKWmpio1NVWjRo3SX//6V+e8MUYrV66Uz+dTUlKSxo0bp4MHD0Y8RzgcVlFRkTIyMpScnKypU6fq6NGj3XM1AADgohBVoAwaNEirVq3SG2+8oTfeeEO33HKLfvzjHzsRsnr1aq1Zs0br16/Xvn375PV6NX78eLW1tTnPUVxcrO3bt6uiokK7du3SsWPHNHnyZHV2dnbvlQEAgD4rqkCZMmWKbr31Vl199dW6+uqr9cgjj+jyyy/Xnj17ZIzRunXrVFJSomnTpsnv92vr1q06fvy4tm3bJkkKBoPatGmTHn30URUUFGj48OEqLy9XfX29qqqqeuQCAQBA33Pe70Hp7OxURUWFPv/8c40aNUqNjY0KBAIqLCx0Ztxut8aOHauamhpJUm1trU6cOBEx4/P55Pf7nZmzCYfDCoVCEQ8AAHDxijpQ6uvrdfnll8vtdmvevHnavn27rrvuOgUCAUlSZmZmxHxmZqZzLhAIKDExUQMGDDjnzNmUlZXJ4/E4j6ysrGiXDQAA+pCoA+Xb3/626urqtGfPHt17772aPXu2Dh065Jx3uVwR88aYLsfO9FUzK1asUDAYdB5NTU3RLhsAAPQhUQdKYmKivvWtb2nEiBEqKyvTDTfcoN/+9rfyer2S1OVOSEtLi3NXxev1qqOjQ62treecORu32+18cuj0AwAAXLwu+N9BMcYoHA4rOztbXq9XlZWVzrmOjg5VV1dr9OjRkqS8vDwlJCREzDQ3N6uhocGZAQAAiI9m+IEHHtDEiROVlZWltrY2VVRU6JVXXtGOHTvkcrlUXFys0tJS5eTkKCcnR6Wlperfv79mzJghSfJ4PJozZ46WLFmi9PR0paWlaenSpcrNzVVBQUGPXCAAAOh7ogqUjz76SLNmzVJzc7M8Ho+GDRumHTt2aPz48ZKkZcuWqb29XfPnz1dra6tGjhypnTt3KiUlxXmOtWvXKj4+XtOnT1d7e7vy8/O1ZcsWxcXFde+VAQCAPstljDGxXkS0QqGQPB6PgsFgj7wf5arlL3b7c/a091dNivUSYCn+ewZgi2h+fvO7eAAAgHUIFAAAYB0CBQAAWIdAAQAA1iFQAACAdQgUAABgHQIFAABYh0ABAADWIVAAAIB1CBQAAGAdAgUAAFiHQAEAANYhUAAAgHUIFAAAYB0CBQAAWIdAAQAA1iFQAACAdQgUAABgHQIFAABYh0ABAADWIVAAAIB1CBQAAGAdAgUAAFiHQAEAANYhUAAAgHUIFAAAYB0CBQAAWIdAAQAA1iFQAACAdQgUAABgHQIFAABYh0ABAADWiY/1AnDpumr5i7FeQtTeXzUp1ksAgEsCd1AAAIB1CBQAAGAdXuIBotAXX5bqi/riPvPyH9C9uIMCAACsQ6AAAADrECgAAMA6BAoAALAOgQIAAKxDoAAAAOsQKAAAwDoECgAAsA6BAgAArEOgAAAA6xAoAADAOgQKAACwDoECAACsQ6AAAADrECgAAMA6BAoAALAOgQIAAKxDoAAAAOsQKAAAwDpRBUpZWZluvPFGpaSkaODAgbrtttv01ltvRcwYY7Ry5Ur5fD4lJSVp3LhxOnjwYMRMOBxWUVGRMjIylJycrKlTp+ro0aMXfjUAAOCiEB/NcHV1tRYsWKAbb7xRJ0+eVElJiQoLC3Xo0CElJydLklavXq01a9Zoy5Ytuvrqq/Xwww9r/Pjxeuutt5SSkiJJKi4u1gsvvKCKigqlp6dryZIlmjx5smpraxUXF9f9VwkAPeyq5S/Gegnn5f1Vk2K9BOCsogqUHTt2RHy9efNmDRw4ULW1tfrhD38oY4zWrVunkpISTZs2TZK0detWZWZmatu2bZo7d66CwaA2bdqkJ598UgUFBZKk8vJyZWVlqaqqShMmTOimSwMAAH1VVIFypmAwKElKS0uTJDU2NioQCKiwsNCZcbvdGjt2rGpqajR37lzV1tbqxIkTETM+n09+v181NTVnDZRwOKxwOOx8HQqFLmTZAID/0xfv/HDX59Jw3m+SNcZo8eLFGjNmjPx+vyQpEAhIkjIzMyNmMzMznXOBQECJiYkaMGDAOWfOVFZWJo/H4zyysrLOd9kAAKAPOO9AWbhwod5880099dRTXc65XK6Ir40xXY6d6ctmVqxYoWAw6DyamprOd9kAAKAPOK9AKSoq0vPPP6+XX35ZgwYNco57vV5J6nInpKWlxbmr4vV61dHRodbW1nPOnMntdis1NTXiAQAALl5RvQfFGKOioiJt375dr7zyirKzsyPOZ2dny+v1qrKyUsOHD5ckdXR0qLq6Wr/5zW8kSXl5eUpISFBlZaWmT58uSWpublZDQ4NWr17dHdd0SeqLryMDAHAuUQXKggULtG3bNv35z39WSkqKc6fE4/EoKSlJLpdLxcXFKi0tVU5OjnJyclRaWqr+/ftrxowZzuycOXO0ZMkSpaenKy0tTUuXLlVubq7zqR4AAHBpiypQNmzYIEkaN25cxPHNmzfrnnvukSQtW7ZM7e3tmj9/vlpbWzVy5Ejt3LnT+TdQJGnt2rWKj4/X9OnT1d7ervz8fG3ZsoV/AwUAAEiSXMYYE+tFRCsUCsnj8SgYDPbI+1F4uQQA7MXHjPuuaH5+87t4AACAdQgUAABgnQv6l2QBAMBX64tvHYj1S2ncQQEAANbhDgoAoE/pi3cjED3uoAAAAOsQKAAAwDoECgAAsA6BAgAArEOgAAAA6xAoAADAOgQKAACwDoECAACsQ6AAAADrECgAAMA6BAoAALAOgQIAAKxDoAAAAOsQKAAAwDoECgAAsA6BAgAArEOgAAAA6xAoAADAOgQKAACwDoECAACsQ6AAAADrECgAAMA6BAoAALAOgQIAAKxDoAAAAOsQKAAAwDoECgAAsA6BAgAArEOgAAAA6xAoAADAOgQKAACwDoECAACsQ6AAAADrECgAAMA6BAoAALAOgQIAAKxDoAAAAOsQKAAAwDoECgAAsA6BAgAArEOgAAAA6xAoAADAOgQKAACwDoECAACsQ6AAAADrECgAAMA6BAoAALAOgQIAAKxDoAAAAOsQKAAAwDpRB8qrr76qKVOmyOfzyeVy6bnnnos4b4zRypUr5fP5lJSUpHHjxungwYMRM+FwWEVFRcrIyFBycrKmTp2qo0ePXtCFAACAi0fUgfL555/rhhtu0Pr16896fvXq1VqzZo3Wr1+vffv2yev1avz48Wpra3NmiouLtX37dlVUVGjXrl06duyYJk+erM7OzvO/EgAAcNGIj/YbJk6cqIkTJ571nDFG69atU0lJiaZNmyZJ2rp1qzIzM7Vt2zbNnTtXwWBQmzZt0pNPPqmCggJJUnl5ubKyslRVVaUJEyZcwOUAAICLQbe+B6WxsVGBQECFhYXOMbfbrbFjx6qmpkaSVFtbqxMnTkTM+Hw++f1+Z+ZM4XBYoVAo4gEAAC5e3RoogUBAkpSZmRlxPDMz0zkXCASUmJioAQMGnHPmTGVlZfJ4PM4jKyurO5cNAAAs0yOf4nG5XBFfG2O6HDvTl82sWLFCwWDQeTQ1NXXbWgEAgH26NVC8Xq8kdbkT0tLS4txV8Xq96ujoUGtr6zlnzuR2u5WamhrxAAAAF69uDZTs7Gx5vV5VVlY6xzo6OlRdXa3Ro0dLkvLy8pSQkBAx09zcrIaGBmcGAABc2qL+FM+xY8f07rvvOl83Njaqrq5OaWlpGjx4sIqLi1VaWqqcnBzl5OSotLRU/fv314wZMyRJHo9Hc+bM0ZIlS5Senq60tDQtXbpUubm5zqd6AADApS3qQHnjjTd08803O18vXrxYkjR79mxt2bJFy5YtU3t7u+bPn6/W1laNHDlSO3fuVEpKivM9a9euVXx8vKZPn6729nbl5+dry5YtiouL64ZLAgAAfZ3LGGNivYhohUIheTweBYPBHnk/ylXLX+z25wQAoC95f9Wkbn/OaH5+87t4AACAdQgUAABgHQIFAABYh0ABAADWIVAAAIB1CBQAAGAdAgUAAFiHQAEAANYhUAAAgHUIFAAAYB0CBQAAWIdAAQAA1iFQAACAdQgUAABgHQIFAABYh0ABAADWIVAAAIB1CBQAAGAdAgUAAFiHQAEAANYhUAAAgHUIFAAAYB0CBQAAWIdAAQAA1iFQAACAdQgUAABgHQIFAABYh0ABAADWIVAAAIB1CBQAAGAdAgUAAFiHQAEAANYhUAAAgHUIFAAAYB0CBQAAWIdAAQAA1iFQAACAdQgUAABgHQIFAABYh0ABAADWIVAAAIB1CBQAAGAdAgUAAFiHQAEAANYhUAAAgHUIFAAAYB0CBQAAWIdAAQAA1iFQAACAdQgUAABgHQIFAABYh0ABAADWIVAAAIB1CBQAAGAdAgUAAFgnpoHy+OOPKzs7W/369VNeXp5ee+21WC4HAABYImaB8vTTT6u4uFglJSU6cOCAfvCDH2jixIk6cuRIrJYEAAAsEbNAWbNmjebMmaOf//znuvbaa7Vu3TplZWVpw4YNsVoSAACwRHws/tCOjg7V1tZq+fLlEccLCwtVU1PTZT4cDiscDjtfB4NBSVIoFOqR9Z0KH++R5wUAoK/oiZ+xp5/TGPOVszEJlI8//lidnZ3KzMyMOJ6ZmalAINBlvqysTL/+9a+7HM/KyuqxNQIAcCnzrOu5525ra5PH4/nSmZgEymkulyvia2NMl2OStGLFCi1evNj5+tSpU/r000+Vnp5+1vkLEQqFlJWVpaamJqWmpnbrc+P/Y597B/vce9jr3sE+956e2GtjjNra2uTz+b5yNiaBkpGRobi4uC53S1paWrrcVZEkt9stt9sdcewb3/hGTy5Rqamp/MffC9jn3sE+9x72unewz72nu/f6q+6cnBaTN8kmJiYqLy9PlZWVEccrKys1evToWCwJAABYJGYv8SxevFizZs3SiBEjNGrUKD3xxBM6cuSI5s2bF6slAQAAS8QsUG6//XZ98skneuihh9Tc3Cy/36+XXnpJQ4YMidWSJP335aQHH3ywy0tK6F7sc+9gn3sPe9072OfeE+u9dpmv81kfAACAXsTv4gEAANYhUAAAgHUIFAAAYB0CBQAAWIdA+R+PP/64srOz1a9fP+Xl5em1116L9ZKsVVZWphtvvFEpKSkaOHCgbrvtNr311lsRM8YYrVy5Uj6fT0lJSRo3bpwOHjwYMRMOh1VUVKSMjAwlJydr6tSpOnr0aMRMa2urZs2aJY/HI4/Ho1mzZumzzz7r6Uu0UllZmVwul4qLi51j7HP3+eCDD3TXXXcpPT1d/fv313e+8x3V1tY659nrC3fy5En96le/UnZ2tpKSkjR06FA99NBDOnXqlDPDPp+fV199VVOmTJHP55PL5dJzzz0Xcb439/XIkSOaMmWKkpOTlZGRofvuu08dHR3RXZCBMcaYiooKk5CQYDZu3GgOHTpkFi1aZJKTk83hw4djvTQrTZgwwWzevNk0NDSYuro6M2nSJDN48GBz7NgxZ2bVqlUmJSXFPPPMM6a+vt7cfvvt5oorrjChUMiZmTdvnrnyyitNZWWl2b9/v7n55pvNDTfcYE6ePOnM/OhHPzJ+v9/U1NSYmpoa4/f7zeTJk3v1em2wd+9ec9VVV5lhw4aZRYsWOcfZ5+7x6aefmiFDhph77rnHvP7666axsdFUVVWZd99915lhry/cww8/bNLT081f/vIX09jYaP70pz+Zyy+/3Kxbt86ZYZ/Pz0svvWRKSkrMM888YySZ7du3R5zvrX09efKk8fv95uabbzb79+83lZWVxufzmYULF0Z1PQTK//ne975n5s2bF3HsmmuuMcuXL4/RivqWlpYWI8lUV1cbY4w5deqU8Xq9ZtWqVc7MF198YTwej/n9739vjDHms88+MwkJCaaiosKZ+eCDD8xll11mduzYYYwx5tChQ0aS2bNnjzOze/duI8n8+9//7o1Ls0JbW5vJyckxlZWVZuzYsU6gsM/d5/777zdjxow553n2untMmjTJ/OxnP4s4Nm3aNHPXXXcZY9jn7nJmoPTmvr700kvmsssuMx988IEz89RTTxm3222CweDXvgZe4pHU0dGh2tpaFRYWRhwvLCxUTU1NjFbVtwSDQUlSWlqaJKmxsVGBQCBiT91ut8aOHevsaW1trU6cOBEx4/P55Pf7nZndu3fL4/Fo5MiRzsxNN90kj8dzSf3dLFiwQJMmTVJBQUHEcfa5+zz//PMaMWKEfvrTn2rgwIEaPny4Nm7c6Jxnr7vHmDFj9Pe//11vv/22JOmf//yndu3apVtvvVUS+9xTenNfd+/eLb/fH/ELASdMmKBwOBzxkulXielvM7bFxx9/rM7Ozi6/qDAzM7PLLzREV8YYLV68WGPGjJHf75ckZ9/OtqeHDx92ZhITEzVgwIAuM6e/PxAIaODAgV3+zIEDB14yfzcVFRXav3+/9u3b1+Uc+9x93nvvPW3YsEGLFy/WAw88oL179+q+++6T2+3W3XffzV53k/vvv1/BYFDXXHON4uLi1NnZqUceeUR33nmnJP6b7im9ua+BQKDLnzNgwAAlJiZGtfcEyv9wuVwRXxtjuhxDVwsXLtSbb76pXbt2dTl3Pnt65szZ5i+Vv5umpiYtWrRIO3fuVL9+/c45xz5fuFOnTmnEiBEqLS2VJA0fPlwHDx7Uhg0bdPfddztz7PWFefrpp1VeXq5t27bp+uuvV11dnYqLi+Xz+TR79mxnjn3uGb21r92x97zEIykjI0NxcXFdyq6lpaVLBSJSUVGRnn/+eb388ssaNGiQc9zr9UrSl+6p1+tVR0eHWltbv3Tmo48+6vLn/uc//7kk/m5qa2vV0tKivLw8xcfHKz4+XtXV1XrssccUHx/v7AH7fOGuuOIKXXfddRHHrr32Wh05ckQS/013l1/+8pdavny57rjjDuXm5mrWrFn6xS9+obKyMknsc0/pzX31er1d/pzW1ladOHEiqr0nUCQlJiYqLy9PlZWVEccrKys1evToGK3KbsYYLVy4UM8++6z+8Y9/KDs7O+J8dna2vF5vxJ52dHSourra2dO8vDwlJCREzDQ3N6uhocGZGTVqlILBoPbu3evMvP766woGg5fE301+fr7q6+tVV1fnPEaMGKGZM2eqrq5OQ4cOZZ+7yfe///0uH5V/++23nV9gyn/T3eP48eO67LLIHz1xcXHOx4zZ557Rm/s6atQoNTQ0qLm52ZnZuXOn3G638vLyvv6iv/bbaS9ypz9mvGnTJnPo0CFTXFxskpOTzfvvvx/rpVnp3nvvNR6Px7zyyiumubnZeRw/ftyZWbVqlfF4PObZZ5819fX15s477zzrR9oGDRpkqqqqzP79+80tt9xy1o+0DRs2zOzevdvs3r3b5ObmXtQfFfwq//spHmPY5+6yd+9eEx8fbx555BHzzjvvmD/+8Y+mf//+pry83Jlhry/c7NmzzZVXXul8zPjZZ581GRkZZtmyZc4M+3x+2trazIEDB8yBAweMJLNmzRpz4MAB55/L6K19Pf0x4/z8fLN//35TVVVlBg0axMeML8Tvfvc7M2TIEJOYmGi++93vOh+ZRVeSzvrYvHmzM3Pq1Cnz4IMPGq/Xa9xut/nhD39o6uvrI56nvb3dLFy40KSlpZmkpCQzefJkc+TIkYiZTz75xMycOdOkpKSYlJQUM3PmTNPa2toLV2mnMwOFfe4+L7zwgvH7/cbtdptrrrnGPPHEExHn2esLFwqFzKJFi8zgwYNNv379zNChQ01JSYkJh8PODPt8fl5++eWz/n959uzZxpje3dfDhw+bSZMmmaSkJJOWlmYWLlxovvjii6iux2WMMV//fgsAAEDP4z0oAADAOgQKAACwDoECAACsQ6AAAADrECgAAMA6BAoAALAOgQIAAKxDoAAAAOsQKAAAwDoECgAAsA6BAgAArEOgAAAA6/w/Mwj/ycWi4v4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(ne[0].flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 372
    },
    "id": "5_UA09HxC48E",
    "outputId": "9e36f4da-0996-4cd8-d316-abee0fcf3e76"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([2241.,   29.,   39.,   40.,   52.,   31.,   43.,   27.,   36.,\n",
       "          22.]),\n",
       " array([-1.0000e+00,  9.9070e+02,  1.9824e+03,  2.9741e+03,  3.9658e+03,\n",
       "         4.9575e+03,  5.9492e+03,  6.9409e+03,  7.9326e+03,  8.9243e+03,\n",
       "         9.9160e+03]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(ne[1].flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3Ow2UkYNIB2X",
    "outputId": "c9667f3f-ddfd-423c-ab3e-fafb1db5b396"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  -1,   -1,   -1, ...,   -1, 5653,   -1],\n",
       "       [  -1, 4443,   -1, ..., 4606,   -1,   -1],\n",
       "       [4443,   -1,   -1, ...,   -1, 2510,   -1],\n",
       "       [  -1,   -1,   -1, ...,   -1,   -1,   -1],\n",
       "       [4443,   -1,   -1, ...,   -1,   -1,   -1]], dtype=int32)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wurst = np.array(ne[1])\n",
    "wurst[ne[0] != MASK_TOKEN_ID] = -1\n",
    "wurst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LGFj4aix8P9y",
    "outputId": "c5a2d142-40b7-4f8a-c075-8f351858b62a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(ne[0][0,:] == 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "moBea0tTbFbX"
   },
   "source": [
    "---\n",
    "# Create the NLP model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7V1gTRpwWvV_",
    "outputId": "0eacc029-3de8-4c13-a15d-0852238cfac7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RobertaConfig {\n",
       "  \"attention_probs_dropout_prob\": 0.1,\n",
       "  \"bos_token_id\": 0,\n",
       "  \"classifier_dropout\": null,\n",
       "  \"eos_token_id\": 2,\n",
       "  \"hidden_act\": \"gelu\",\n",
       "  \"hidden_dropout_prob\": 0.1,\n",
       "  \"hidden_size\": 768,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"intermediate_size\": 3072,\n",
       "  \"layer_norm_eps\": 1e-12,\n",
       "  \"max_position_embeddings\": 513,\n",
       "  \"model_type\": \"roberta\",\n",
       "  \"num_attention_heads\": 12,\n",
       "  \"num_hidden_layers\": 12,\n",
       "  \"pad_token_id\": 1,\n",
       "  \"position_embedding_type\": \"absolute\",\n",
       "  \"transformers_version\": \"4.22.0\",\n",
       "  \"type_vocab_size\": 2,\n",
       "  \"use_cache\": true,\n",
       "  \"vocab_size\": 10000\n",
       "}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg = RobertaConfig()\n",
    "\n",
    "cfg.vocab_size = VOCAB_SIZE\n",
    "cfg.max_position_embeddings = X_BLOCK_LENGHT + 1\n",
    "\n",
    "cfg.bos_token_id = BOS_TOKEN_ID\n",
    "cfg.pad_token_id = PAD_TOKEN_ID\n",
    "cfg.eos_token_id = EOS_TOKEN_ID\n",
    "\n",
    "cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LE3ZxhjDuZmA",
    "outputId": "819b43b3-72b8-4f41-f8f3-286efc50804d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"RobertaMLMTraining_1\"\n",
      "____________________________________________________________________________________________________________________________________________________________________________________________________________________________\n",
      " Layer (type)                                                                                      Output Shape                                                                            Param #                          \n",
      "============================================================================================================================================================================================================================\n",
      " input (InputLayer)                                                                                [(None, 512)]                                                                           0                                \n",
      "                                                                                                                                                                                                                            \n",
      " tf_roberta_model (TFRobertaModel)                                                                 TFBaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=(None, 512, 768),      93722112                         \n",
      "                                                                                                    pooler_output=(None, 768),                                                                                              \n",
      "                                                                                                    past_key_values=None, hidden_states=None, attentions=None, cross_attentions=None)                                       \n",
      "                                                                                                                                                                                                                            \n",
      " Categories (Dense)                                                                                (None, 512, 10000)                                                                      7690000                          \n",
      "                                                                                                                                                                                                                            \n",
      "============================================================================================================================================================================================================================\n",
      "Total params: 101,412,112\n",
      "Trainable params: 101,412,112\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________________________________________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#@title CreateModelRobertaMLMTraining\n",
    "def CreateModelRobertaMLMTraining():\n",
    "\n",
    "  # A sentence as input\n",
    "  inputSentence = Input(shape=(X_BLOCK_LENGHT), name='input', dtype='int32')\n",
    "  \n",
    "  # The NLP model\n",
    "  nlp = TFRobertaModel(cfg)(inputSentence)\n",
    "\n",
    "  # A dense layer to predict back the full sentence\n",
    "  predicted_sentence = Dense(VOCAB_SIZE, activation='softmax', name=\"Categories\")(nlp['last_hidden_state'])\n",
    "\n",
    "  outputs = [predicted_sentence]\n",
    "\n",
    "  # And combine it all in a model object\n",
    "  model = Model(inputs=inputSentence, outputs=outputs, name='RobertaMLMTraining_1')\n",
    "\n",
    "  return model\n",
    "\n",
    "model = CreateModelRobertaMLMTraining()\n",
    "model.summary(line_length=220)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ufsD_eAeSSXi"
   },
   "source": [
    "### Todo: Check if weighted classed are required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "PrUGwBcoYfxV"
   },
   "outputs": [],
   "source": [
    "# #@title Load the class weights\n",
    "# with file_io.FileIO('gs://ticks_with_indicators_with_volume/sentences/set2/weightArray.npy', mode='rb') as input_f:\n",
    "#   with file_io.FileIO('/content/weightArray.npy', mode='wb+') as output_f:\n",
    "#     output_f.write(input_f.read())\n",
    "\n",
    "# CLASS_WEIGHTS = np.empty((1,1,1024))\n",
    "# CLASS_WEIGHTS[0,0,:] = np.load('/content/weightArray.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "1QdZbG6kYg-1"
   },
   "outputs": [],
   "source": [
    "# plt.plot(CLASS_WEIGHTS[0,0,:])\n",
    "# plt.yscale(\"log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "Rpigcso1YiwV"
   },
   "outputs": [],
   "source": [
    "# CLASS_WEIGHTS_TF_CONST = tf.constant(tf.convert_to_tensor(CLASS_WEIGHTS,dtype=tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "cellView": "form",
    "id": "jg3ngnAVYlZI"
   },
   "outputs": [],
   "source": [
    "#@title CreateModelRobertaMLMTrainingWeighted - Todo change to new style\n",
    "def CreateModelRobertaMLMTrainingWeighted():\n",
    "\n",
    "  # Build your model input\n",
    "  inputSentence = Input(shape=(X_LOOKBACK_CNT), name='input', dtype='int32')\n",
    "  \n",
    "  nlp = TFRobertaModel(cfg)(inputSentence)\n",
    "\n",
    "  categories = Dense(1024, activation='softmax', name=\"Categories\")(nlp['last_hidden_state'])\n",
    "  categories_weighted = tf.multiply(categories, CLASS_WEIGHTS_TF_CONST)\n",
    "\n",
    "  outputs = [categories_weighted]\n",
    "\n",
    "  mnamesuffix = \"_1\"\n",
    "\n",
    "  # And combine it all in a model object\n",
    "  model = Model(inputs=inputSentence, outputs=outputs, name='ModelRobertaMLMTrainingWeighted'+mnamesuffix)\n",
    "\n",
    "  return model\n",
    "\n",
    "# model = CreateModelRobertaMLMTrainingWeighted()\n",
    "# model.summary(line_length=220)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "cellView": "form",
    "id": "RQbpCGz8fHAi"
   },
   "outputs": [],
   "source": [
    "#@title CreateModelRobertaMLMTrainingDropout - Todo change to new style\n",
    "def CreateModelRobertaMLMTrainingDropout():\n",
    "\n",
    "  # Build your model input\n",
    "  inputSentence = Input(shape=(X_LOOKBACK_CNT), name='input', dtype='int32')\n",
    "  \n",
    "  nlp = TFRobertaModel(cfg, name=\"Roberta\")(inputSentence)\n",
    "\n",
    "  categories = Dense(VOCAB_SIZE, activation='softmax', name=\"Categories\")(nlp['last_hidden_state'])\n",
    "  drp = Dropout(0.15, name=\"CategoriesDropout\")(categories)\n",
    "\n",
    "  # categories_weighted = tf.multiply(drp, CLASS_WEIGHTS_TF_CONST)\n",
    "\n",
    "  outputs = [drp]\n",
    "\n",
    "  mnamesuffix = \"_1\"\n",
    "\n",
    "  # And combine it all in a model object\n",
    "  model = Model(inputs=inputSentence, outputs=outputs, name='ModelRobertaMLMTrainingDropout'+mnamesuffix)\n",
    "\n",
    "  return model\n",
    "\n",
    "# model = CreateModelRobertaMLMTrainingDropout()\n",
    "# model.summary(line_length=220)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "cellView": "form",
    "id": "ZDpFvhHH7hEi"
   },
   "outputs": [],
   "source": [
    "#@title CreateModelRobertaLastWordPrediction - Todo change to new style\n",
    "def CreateModelRobertaLastWordPrediction():\n",
    "\n",
    "  # Build your model input\n",
    "  inputSentence = Input(shape=(X_LOOKBACK_CNT), name='input', dtype='int32')\n",
    "  \n",
    "  nlp = TFRobertaModel(cfg, name=\"Roberta\")(inputSentence)\n",
    "\n",
    "  flat = Flatten(name=\"FlattenNLP\")(nlp['last_hidden_state'])\n",
    "  lastWord = Dense(VOCAB_SIZE, activation='softmax', name=\"Categories\", dtype=tf.float32)(flat)\n",
    "\n",
    "  outputs = [lastWord]\n",
    "\n",
    "  mnamesuffix = \"_1\"\n",
    "\n",
    "  # And combine it all in a model object\n",
    "  model = Model(inputs=inputSentence, outputs=outputs, name='ModelRobertaLastWordPrediction'+mnamesuffix)\n",
    "\n",
    "  return model\n",
    "\n",
    "# model = CreateModelRobertaLastWordPrediction()\n",
    "# model.summary(line_length=220)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kXE8AjjoEWE4"
   },
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QfwL7EWInGWB"
   },
   "source": [
    "### Train strategy in the paper\n",
    "https://huggingface.co/roberta-base\n",
    "\n",
    "The model was trained on 1024 V100 GPUs for 500K steps with a batch size of 8K and a sequence length of 512. The optimizer used is Adam with a learning rate of 6e-4, 1=0.9\\beta_{1} = 0.91=0.9, 2=0.98\\beta_{2} = 0.982=0.98 and =1e6\\epsilon = 1e-6=1e6, a weight decay of 0.01, learning rate warmup for 24,000 steps and linear decay of the learning rate after."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "_jkOrQ01hZnE",
    "outputId": "afe655bf-d35c-4f71-ced0-d225a2ff6155"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'RobertaMLMTraining_1_GPU_512LB_10000VC_MaskedPrediction'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CHKPNT_NAME = f\"{model.name}_GPU_{X_BLOCK_LENGHT}LB_{VOCAB_SIZE}VC_MaskedPrediction\"\n",
    "CHKPNT_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "g0VmovApkwAB"
   },
   "outputs": [],
   "source": [
    "# Set an optimizer\n",
    "optimizer = Adam(\n",
    "    learning_rate=1e-03,\n",
    "    epsilon=1e-06,\n",
    "    beta_1=0.9,\n",
    "    beta_2=0.98,\n",
    "    decay=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "id": "yMoJi05f0JKp"
   },
   "outputs": [],
   "source": [
    "# # Create a masked loss to predict only the missing tokens\n",
    "# # https://stackoverflow.com/questions/56328140/how-do-i-implement-a-masked-softmax-cross-entropy-loss-function-in-keras\n",
    "\n",
    "# SCCE = tf.keras.losses.SparseCategoricalCrossentropy(reduction=tf.keras.losses.Reduction.NONE, from_logits=False)\n",
    "\n",
    "# def sparse_crossentropy_masked(y_true, y_pred):\n",
    "#   y_true_masked = tf.boolean_mask(y_true, tf.not_equal(y_true, -1))\n",
    "#   y_pred_masked = tf.boolean_mask(y_pred, tf.not_equal(y_true, -1))\n",
    "\n",
    "#   return tf.reduce_sum(SCCE(y_true_masked, y_pred_masked)) * (1. / BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "id": "mhCAE0Ujne49"
   },
   "outputs": [],
   "source": [
    "# # Create a masked loss to predict only the missing tokens\n",
    "# # https://stackoverflow.com/questions/56328140/how-do-i-implement-a-masked-softmax-cross-entropy-loss-function-in-keras\n",
    "\n",
    "# SCCE = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False)\n",
    "\n",
    "# def sparse_crossentropy_masked(y_true, y_pred):\n",
    "#   # y_true_masked = tf.boolean_mask(y_true, tf.not_equal(y_true, -1))\n",
    "#   # y_pred_masked = tf.boolean_mask(y_pred, tf.not_equal(y_true, -1))\n",
    "\n",
    "#   maskTensor = tf.not_equal(y_true, -1)\n",
    "#   a\n",
    "#   y_true_masked = y_true * tf.cast(maskTensor, tf.int32)\n",
    "#   y_pred_masked = y_pred * tf.cast(maskTensor, tf.float32)\n",
    "\n",
    "#   return SCCE(y_true_masked, y_pred_masked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "id": "AOLSygN7Ut7_"
   },
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "# model.compile(\n",
    "#     optimizer = optimizer,\n",
    "#     loss = [tf.keras.losses.MeanSquaredError()], \n",
    "#     metrics=[tf.keras.losses.MeanAbsoluteError(), tf.keras.losses.MeanAbsolutePercentageError()])\n",
    "\n",
    "model.compile(\n",
    "    optimizer = optimizer,\n",
    "    loss = tf.keras.losses.SparseCategoricalCrossentropy(ignore_class=-1),\n",
    "    metrics=None)\n",
    "\n",
    "# model.compile(\n",
    "#     optimizer = optimizer,\n",
    "#     loss = sparse_crossentropy_masked, \n",
    "#     metrics=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TFa0iWcaqli5",
    "outputId": "0ec595c6-7c5c-4723-8a2c-64d0d7a07f08"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"RobertaMLMTraining_1\"\n",
      "____________________________________________________________________________________________________________________________________________________________________________________________________________________________\n",
      " Layer (type)                                                                                      Output Shape                                                                            Param #                          \n",
      "============================================================================================================================================================================================================================\n",
      " input (InputLayer)                                                                                [(None, 512)]                                                                           0                                \n",
      "                                                                                                                                                                                                                            \n",
      " tf_roberta_model (TFRobertaModel)                                                                 TFBaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=(None, 512, 768),      93722112                         \n",
      "                                                                                                    pooler_output=(None, 768),                                                                                              \n",
      "                                                                                                    past_key_values=None, hidden_states=None, attentions=None, cross_attentions=None)                                       \n",
      "                                                                                                                                                                                                                            \n",
      " Categories (Dense)                                                                                (None, 512, 10000)                                                                      7690000                          \n",
      "                                                                                                                                                                                                                            \n",
      "============================================================================================================================================================================================================================\n",
      "Total params: 101,412,112\n",
      "Trainable params: 101,412,112\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________________________________________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary(line_length=220)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "id": "iGC1RvizroRS"
   },
   "outputs": [],
   "source": [
    "# # Callback for colab\n",
    "# # Todo: Adapt the callback to be suitable for both colab (store to bucket) and local (store to disk)\n",
    "# #@title CustomCallback\n",
    "# class CustomCallback(tf.keras.callbacks.Callback):\n",
    "#   def __init__(self, save_freq, val_freq, checkpoint_path, model_name, epoch_add=0):\n",
    "#     self.save_freq = save_freq\n",
    "#     self.val_freq = val_freq\n",
    "#     self.checkpoint_path = checkpoint_path\n",
    "#     self.model_name = model_name\n",
    "#     self.current_epoch = 0\n",
    "#     self.epoch_add = epoch_add\n",
    "\n",
    "#   def on_epoch_begin(self, epoch, logs=None):\n",
    "#     self.current_epoch = epoch + self.epoch_add\n",
    "#     # keys = list(logs.keys())\n",
    "#     # print(\"Start epoch {} of training; got log keys: {}\".format(epoch, keys))\n",
    "\n",
    "#   def on_epoch_end(self, epoch, logs=None):\n",
    "#     self.saveTheModel(-1, logs)\n",
    "\n",
    "#   def on_train_batch_end(self, batch, logs=None):\n",
    "#     self.saveTheModel(batch, logs)\n",
    "\n",
    "#   def saveTheModel(self, batch, logs=None):\n",
    "#     if (0 < batch and 0 == batch % self.save_freq) or (0 > batch):\n",
    "#       if 0 > batch:\n",
    "#         _save_folder = os.path.join(self.checkpoint_path,\n",
    "#                                     self.model_name,\n",
    "#                                     \"cp_daily_valid_{:02d}_end\".format(self.current_epoch)\n",
    "#                                     )\n",
    "#       else:\n",
    "#         _save_folder = os.path.join(self.checkpoint_path,\n",
    "#                                     self.model_name,\n",
    "#                                     \"cp_daily_valid_{:02d}_{:05d}\".format(self.current_epoch, batch)\n",
    "#                                     )\n",
    "\n",
    "#       _model_path_local = os.path.join(\"/content/\", \"model.h5\")\n",
    "#       _model_path_bucket = os.path.join(_save_folder, \"model.h5\")\n",
    "\n",
    "#       model.save(_model_path_local)\n",
    "     \n",
    "#       # Copy model.h5 over to Google Cloud Storage\n",
    "#       with file_io.FileIO(_model_path_local, mode='rb') as input_f:\n",
    "#           with file_io.FileIO(_model_path_bucket, mode='wb+') as output_f:\n",
    "#               output_f.write(input_f.read())\n",
    "#               print(\"\\nSaved model to: '\" + _model_path_bucket + \"'\")\n",
    "\n",
    "#       # Save optimizer config\n",
    "#       c = copy.deepcopy(self.model.optimizer.get_config())\n",
    "\n",
    "#       fp = os.path.join(_save_folder, \"c.pickle\")\n",
    "#       with file_io.FileIO(fp, mode='wb+') as handle:\n",
    "#         pickle.dump(c, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "#         print(\"Saved optimizer config to: '\" + fp + \"'\")\n",
    "\n",
    "#       # Save optimizer weights\n",
    "#       # w = copy.deepcopy(self.model.optimizer.get_weights())\n",
    "\n",
    "#       # fp = os.path.join(_save_folder, \"w.pickle\")\n",
    "#       # with file_io.FileIO(fp, mode='wb+') as handle:\n",
    "#       #   pickle.dump(w, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "#       #   print(\"Saved optimizer weights to: '\" + fp + \"'\")\n",
    "\n",
    "#     # if 0 < batch and 0 == batch % self.val_freq:\n",
    "#     #   print(\"-------------------------EVAL-------------------------\")\n",
    "#     #   model.evaluate(tfgenTest)\n",
    "#     #   print(\"\\n-------------------------EVAL-------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title CustomCallback\n",
    "class CustomCallback(tf.keras.callbacks.Callback):\n",
    "  def __init__(self, save_freq, val_freq, checkpoint_path, model_name, epoch_add=0):\n",
    "    self.save_freq = save_freq\n",
    "    self.val_freq = val_freq\n",
    "    self.checkpoint_path = checkpoint_path\n",
    "    self.model_name = model_name\n",
    "    self.current_epoch = 0\n",
    "    self.epoch_add = epoch_add\n",
    "\n",
    "  def on_epoch_begin(self, epoch, logs=None):\n",
    "    self.current_epoch = epoch + self.epoch_add\n",
    "    # keys = list(logs.keys())\n",
    "    # print(\"Start epoch {} of training; got log keys: {}\".format(epoch, keys))\n",
    "\n",
    "  def on_epoch_end(self, epoch, logs=None):\n",
    "    self.saveTheModel(-1, logs)\n",
    "\n",
    "  def on_train_batch_end(self, batch, logs=None):\n",
    "    self.saveTheModel(batch, logs)\n",
    "\n",
    "  def saveTheModel(self, batch, logs=None):\n",
    "    if (0 < batch and 0 == batch % self.save_freq) or (0 > batch):\n",
    "      logging.info(str(datetime.datetime.utcnow()))\n",
    "    \n",
    "      if 0 > batch:\n",
    "        _save_folder = os.path.join(self.checkpoint_path,\n",
    "                                    self.model_name,\n",
    "                                    \"cp_daily_valid_{:02d}_end\".format(self.current_epoch)\n",
    "                                    )\n",
    "      else:\n",
    "        _save_folder = os.path.join(self.checkpoint_path,\n",
    "                                    self.model_name,\n",
    "                                    \"cp_daily_valid_{:02d}_{:05d}\".format(self.current_epoch, batch)\n",
    "                                    )\n",
    "      \n",
    "      fp = os.path.join(_save_folder, \"model.h5\")\n",
    "      model.save(fp)\n",
    "      logging.info(f\"Saved model to '{fp}'\")\n",
    "      \n",
    "      # Save optimizer config\n",
    "      # c = copy.deepcopy(self.model.optimizer.get_config())\n",
    "\n",
    "      fp = os.path.join(_save_folder, \"c.pickle\")\n",
    "      with file_io.FileIO(fp, mode='wb+') as handle:\n",
    "        pickle.dump(self.model.optimizer.get_config(), handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "        \n",
    "      logging.info(f\"Saved optimizer config to '{fp}'\")\n",
    "\n",
    "      # Save optimizer weights\n",
    "      # w = copy.deepcopy(self.model.optimizer.get_weights())\n",
    "\n",
    "      fp = os.path.join(_save_folder, \"w.pickle\")\n",
    "      with open(fp, \"wb\") as handle:\n",
    "        # with file_io.FileIO(fp, mode='wb+') as handle:\n",
    "        pickle.dump(self.model.optimizer.get_weights(), handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "      \n",
    "      logging.info(f\"Saved optimizer weights to '{fp}'\")\n",
    "        \n",
    "      logging.info(f\"Did a gc collect: {gc.collect()}\")\n",
    "\n",
    "    # if 0 < batch and 0 == batch % self.val_freq:\n",
    "    #   print(\"-------------------------EVAL-------------------------\")\n",
    "    #   model.evaluate(tfgenTest)\n",
    "    #   print(\"\\n-------------------------EVAL-------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25085"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "id": "TczoGFYOStmg"
   },
   "outputs": [],
   "source": [
    "# CLASS_WEIGHTS_DICT = None\n",
    "# CLASS_WEIGHTS_DICT = {}\n",
    "\n",
    "# for i, cw in enumerate(CLASS_WEIGHTS[0,0,:]):\n",
    "#   CLASS_WEIGHTS_DICT[i] = cw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "id": "JyggHiDGNTEX"
   },
   "outputs": [],
   "source": [
    "epoch_add = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "id": "-pJ08IBN7cgB"
   },
   "outputs": [],
   "source": [
    "CALLBACK_EVERY_N_BATCHES = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "id": "CuGT0rFvzH1n"
   },
   "outputs": [],
   "source": [
    "cc = CustomCallback(checkpoint_path = CHECKPOINT_PATH,\n",
    "                    model_name = CHKPNT_NAME,\n",
    "                    save_freq = CALLBACK_EVERY_N_BATCHES,\n",
    "                    val_freq = CALLBACK_EVERY_N_BATCHES,\n",
    "                    epoch_add = epoch_add)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "id": "LuuH0xBKGE1g",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "id": "0noHN-UeSCQ-"
   },
   "outputs": [],
   "source": [
    "%reload_ext tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u7xAyqce3qYJ"
   },
   "source": [
    "The TensorBoard UI is displayed in a browser window. In this colab, perform the following steps to prepare to capture profile information.\n",
    "1.  Click on the dropdown menu box on the top right side and scroll down and click PROFILE. A new window appears that shows: **No profile data was found** at the top.\n",
    "1.  Click on the CAPTURE PROFILE button. A new dialog appears. The top input line shows: **Profile Service URL or TPU name**. Copy and paste the Profile Service URL (the service_addr value shown before launching TensorBoard) into the top input line. While still on the dialog box, start the training with the next step.\n",
    "1.  Click on the next colab cell to start training the model.\n",
    "1.  Watch the output from the training until several epochs have completed. This allows time for the profile data to start being collected. Return to the dialog box and click on the CAPTURE button. If the capture succeeds, the page will auto refresh and redirect you to the profiling results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "mpUXurxwSp_3",
    "outputId": "8d57d014-c4bc-49e1-a434-179a5be0529c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/content/bigdata/log/RobertaMLMTraining_1_GPU_512LB_10000VC_MaskedPrediction20230217-104655'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Todo: Create more elegant solution\n",
    "log_dir = \"gs://ticks_with_indicators_with_volume/logs/TPU/\" + CHKPNT_NAME + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "if not COLAB:\n",
    "    log_dir = os.path.join(\"/content/bigdata/log\",log_dir.split(\"/\")[-1])\n",
    "\n",
    "log_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "He5Jna87RsPN",
    "outputId": "efab0e32-2cca-4c12-bc49-8cd1fb7492b9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/content/bigdata/log/RobertaMLMTraining_1_GPU_512LB_10000VC_MaskedPrediction20230217-104655'"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "id": "_X-ab7uc3gTt"
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(\n",
    "    log_dir=log_dir,\n",
    "    histogram_freq=1,\n",
    "    update_freq=CALLBACK_EVERY_N_BATCHES    \n",
    "    )\n",
    "#profile_batch=(5,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "CLASS_WEIGHTS_DICT = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(\"/content/bigdata/chk/RobertaMLMTraining_1_GPU_512LB_10000VC_MaskedPrediction_LR1e-5TooLow/cp_daily_valid_01_202000/model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-f89753660a30c1aa\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-f89753660a30c1aa\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir $log_dir --host 0.0.0.0 --port 6006"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DcUTfAbHb2FW",
    "outputId": "a6b2d3a2-f00f-4733-fd4b-268b42e7f2a6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model/roberta/pooler/dense/kernel:0', 'tf_roberta_model/roberta/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model/roberta/pooler/dense/kernel:0', 'tf_roberta_model/roberta/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model/roberta/pooler/dense/kernel:0', 'tf_roberta_model/roberta/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model/roberta/pooler/dense/kernel:0', 'tf_roberta_model/roberta/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "INFO:root:File 'GOLD-USDT.csv' loaded, 120 left\n",
      "INFO:root:File 'FIL-USDT.csv' loaded, 119 left\n",
      "INFO:root:File 'OCEAN-USDT.csv' loaded, 118 left\n",
      "INFO:root:File 'COMP-USDT.csv' loaded, 117 left\n",
      "INFO:root:File 'VLX-USDT.csv' loaded, 116 left\n",
      "INFO:root:In each batch of X-Blocks, 385 elements will be randomly masked. This is an average of 77 per X-Block\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    311/Unknown - 211s 644ms/step - loss: 7.6821"
     ]
    }
   ],
   "source": [
    "model.fit(tfGenTraining,\n",
    "          epochs=200,\n",
    "          verbose = 1,\n",
    "          callbacks=[tensorboard_callback, cc],\n",
    "          class_weight=CLASS_WEIGHTS_DICT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2Nh12BlMEOBF",
    "outputId": "8bb69110-e6ee-48e6-e62b-1547db0c5ee4"
   },
   "outputs": [],
   "source": [
    "# copy_filenames = ['gs://crypto_nlp_training/chk/RobertaMLMTraining_1_GPU_512LB_10000VC_MaskedPrediction/cp_daily_valid_01_06000/model.h5'\n",
    "#                   ]\n",
    "\n",
    "# for p in copy_filenames:\n",
    "#   fn = p.split(\"/\")[-1]\n",
    "#   cpnt = p.split(\"/\")[-2]\n",
    "\n",
    "#   os.mkdir(os.path.join(\"/content\", cpnt))\n",
    "\n",
    "#   localPath = os.path.join(\"/content\", cpnt, fn)\n",
    "\n",
    "#   if (\"model.h5\" in p):\n",
    "#     localPathModel = localPath\n",
    "#   elif (\"w.pickle\" in p):\n",
    "#     localPathW = localPath\n",
    "\n",
    "#   with file_io.FileIO(p, mode='rb') as input_f:\n",
    "#     with file_io.FileIO(localPath, mode='wb+') as output_f:\n",
    "#       output_f.write(input_f.read())\n",
    "#       print(\"Pulled from bucket: '\" + fn + \"'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nYu7qfd3IsMu",
    "outputId": "d24bd442-2144-459f-eec5-0437fdd2cde3"
   },
   "outputs": [],
   "source": [
    "# print(f\"Loading {localPathModel}\")\n",
    "# model.load_weights(localPathModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HRuwJfh2l7nS"
   },
   "outputs": [],
   "source": [
    "# model.load_weights(\"/content/model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3HLXTKPAfZ04"
   },
   "outputs": [],
   "source": [
    "# modelOld = CreateModelRobertaMLMTrainingDropout()\n",
    "# modelOld.load_weights(\"/content/cp_daily_valid_49_end/model.h5\")\n",
    "# modelOld.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NWKr6ROif078"
   },
   "outputs": [],
   "source": [
    "# model.get_layer(\"Roberta\").set_weights(modelOld.get_layer(\"Roberta\").get_weights())\n",
    "# model.get_layer(\"Categories\").set_weights(modelOld.get_layer(\"Categories\").get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_mV2OpQAGDja"
   },
   "outputs": [],
   "source": [
    "# with open(\"/content/w.pickle\", 'rb') as pickle_file:\n",
    "#   w = pickle.load(pickle_file)\n",
    "# model.optimizer.set_weights(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kXHVjhsDHHF9"
   },
   "outputs": [],
   "source": [
    "# model.optimizer.learning_rate = 5e-2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HyBFN04Q-qcU"
   },
   "source": [
    "LR 5e-4  5000/Unknown - 5576s 1s/step - loss: 296.81093730\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zvFil-4dStzq"
   },
   "source": [
    "# Full sentence as y\n",
    "20000/Unknown - 21155s 1s/step - loss: 0.9579\n",
    "Saved model to: 'gs://crypto_nlp_training/chk/RobertaMLMTraining_1_GPU_512LB_10000VC_FullPrediction/cp_daily_valid_00_20000/model.h5'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5le0oPyfbE79"
   },
   "source": [
    "# Masked sentence as y, LR 5e-4, Random state 11\n",
    "14000/Unknown - 15387s 1s/step - loss: 5.3956\n",
    "Saved model to: 'gs://crypto_nlp_training/chk/RobertaMLMTraining_1_GPU_512LB_10000VC_MaskedPrediction/cp_daily_valid_00_14000/model.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P2BZv38mgNQs"
   },
   "outputs": [],
   "source": [
    "# A python generator function has to be applied on the dataStream\n",
    "\n",
    "def pythonGeneratorMLMTraining():\n",
    "  # Initialize the FileListToDataStream generator\n",
    "  dataStreamTraining = DataStreamCreator.FileListToDataStream(fileList = TRAIN_FILES,\n",
    "                                                      batch_size = BATCH_SIZE,\n",
    "                                                      X_Block_lenght = X_BLOCK_LENGHT,\n",
    "                                                      y_type_dict=Y_TYPE_DICT,\n",
    "                                                      shuffle=True,\n",
    "                                                      parallel_generators = 8,\n",
    "                                                      random_seed = RANDOM_SEED,\n",
    "                                                      **DATA_STREAM_PARAMETERS\n",
    "                                                      )\n",
    "  \n",
    "  # Calculate how many word shall be replaced\n",
    "  mask_number = int(np.round(X_BLOCK_LENGHT * MLM_MASK_FACTOR))\n",
    "  logging.info(f\"In each batch of X-Blocks, {mask_number*BATCH_SIZE} elements will be randomly masked. This is an average of {mask_number} per X-Block\")\n",
    "\n",
    "  # This while has to integrated into the FileListToDataStream method\n",
    "  while True:  \n",
    "    try:\n",
    "      ne = next(dataStreamTraining)\n",
    "      _X = ne['X']\n",
    "\n",
    "      # Convert the X-Block into a sentence\n",
    "      with tf.device('/CPU:0'):        \n",
    "        four_float_sentence = fourFloatClassifierModel.predict(_X, batch_size = BATCH_SIZE, verbose = 0)\n",
    "        int_sentence = ConvertFourFloatDataToWords(four_float_sentence, digitLimits)\n",
    "\n",
    "        # _X_sentence = intClassifierModel.predict(_X, batch_size = BATCH_SIZE, verbose = 0)\n",
    "\n",
    "      # Round to avoid too many categories\n",
    "      # Todo: Better classifier model!\n",
    "      # _X_sentence = np.round(_X_sentence / 10.0).astype(int)\n",
    "\n",
    "      # Create random indices, to replace 'words' with MASK_TOKEN_I\n",
    "      mask_positions = np.round(np.random.rand(BATCH_SIZE, mask_number) * X_BLOCK_LENGHT * BATCH_SIZE).astype(int)\n",
    "      mask_positions[mask_positions == X_BLOCK_LENGHT * BATCH_SIZE] -= 1  # Avoid the upper array limit\n",
    "\n",
    "      # Mask the chosen tokens\n",
    "      int_sentence_masked = np.array(int_sentence).flatten()\n",
    "      int_sentence_masked[mask_positions] = MASK_TOKEN_ID\n",
    "      int_sentence_masked = int_sentence_masked.reshape(int_sentence.shape)\n",
    "\n",
    "      # print(mask_positions[0,0])\n",
    "\n",
    "      # 'Remove' all tokens that shall not be predicted from the training y data (the full sentence), so that the network can focus on the missing tokens\n",
    "      # More precise: Setting them to -1 tells the loss function to ignore them\n",
    "      int_sentence[int_sentence_masked != MASK_TOKEN_ID] = -1\n",
    "\n",
    "      # Not required here, as the network shall predict back its original input\n",
    "      # _y = ne['y']\n",
    "      \n",
    "      # Return the masked senteces as X data, the full ones are the y-data --> The network shall predict the missing tokens\n",
    "      yield (int_sentence_masked, int_sentence)\n",
    "    except StopIteration as si:\n",
    "      logging.warning(\"StopIteration in pythonGenerator\")\n",
    "      logging.warning(si)\n",
    "      return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RLmWNTDIUpt6"
   },
   "outputs": [],
   "source": [
    "# A python generator function has to be applied on the dataStream\n",
    "\n",
    "def pythonGeneratorMLMEval():\n",
    "  # Initialize the FileListToDataStream generator\n",
    "  dataStreamTraining = DataStreamCreator.FileListToDataStream(fileList = TRAIN_FILES,\n",
    "                                                      batch_size = BATCH_SIZE,\n",
    "                                                      X_Block_lenght = X_BLOCK_LENGHT,\n",
    "                                                      y_type_dict=Y_TYPE_DICT,\n",
    "                                                      shuffle=True,\n",
    "                                                      parallel_generators = BATCH_SIZE,\n",
    "                                                      random_seed = RANDOM_SEED,\n",
    "                                                      **DATA_STREAM_PARAMETERS\n",
    "                                                      )\n",
    "  \n",
    "  # Calculate how many word shall be replaced\n",
    "  mask_number = int(np.round(X_BLOCK_LENGHT * MLM_MASK_FACTOR))\n",
    "  logging.info(f\"In each batch of X-Blocks, {mask_number*BATCH_SIZE} elements will be randomly masked. This is an average of {mask_number} per X-Block\")\n",
    "\n",
    "  # This while has to integrated into the FileListToDataStream method\n",
    "  while True:  \n",
    "    try:\n",
    "      ne = next(dataStreamTraining)\n",
    "      _X = ne['X']\n",
    "\n",
    "      # Convert the X-Block into a sentence\n",
    "      with tf.device('/CPU:0'):        \n",
    "        four_float_sentence = fourFloatClassifierModel.predict(_X, batch_size = BATCH_SIZE, verbose = 0)\n",
    "        int_sentence = ConvertFourFloatDataToWords(four_float_sentence, digitLimits)\n",
    "\n",
    "        # _X_sentence = intClassifierModel.predict(_X, batch_size = BATCH_SIZE, verbose = 0)\n",
    "\n",
    "      # Round to avoid too many categories\n",
    "      # Todo: Better classifier model!\n",
    "      # _X_sentence = np.round(_X_sentence / 10.0).astype(int)\n",
    "\n",
    "      # Create random indices, to replace 'words' with MASK_TOKEN_I\n",
    "      mask_positions = np.round(np.random.rand(BATCH_SIZE, mask_number) * X_BLOCK_LENGHT * BATCH_SIZE).astype(int)\n",
    "      mask_positions[mask_positions == X_BLOCK_LENGHT * BATCH_SIZE] -= 1  # Avoid the upper array limit\n",
    "\n",
    "      # Mask the chosen tokens\n",
    "      int_sentence_masked = np.array(int_sentence).flatten()\n",
    "      int_sentence_masked[mask_positions] = MASK_TOKEN_ID\n",
    "      int_sentence_masked = int_sentence_masked.reshape(int_sentence.shape)\n",
    "\n",
    "      # print(mask_positions[0,0])\n",
    "\n",
    "      # 'Remove' all tokens that shall not be predicted from the training y data (the full sentence), so that the network can focus on the missing tokens\n",
    "      # More precise: Setting them to -1 tells the loss function to ignore them\n",
    "      # int_sentence[int_sentence_masked != MASK_TOKEN_ID] = -1\n",
    "\n",
    "      # Not required here, as the network shall predict back its original input\n",
    "      # _y = ne['y']\n",
    "      \n",
    "      # Return the masked senteces as X data, the full ones are the y-data --> The network shall predict the missing tokens\n",
    "      yield (int_sentence_masked, int_sentence)\n",
    "    except StopIteration as si:\n",
    "      logging.warning(\"StopIteration in pythonGenerator\")\n",
    "      logging.warning(si)\n",
    "      return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iUSw95cqUuE_"
   },
   "outputs": [],
   "source": [
    "# Create a Tensorflow dataset out of the python generator, which can be fed to the network\n",
    "tfGenEval = tf.data.Dataset.from_generator(pythonGeneratorMLMEval, \n",
    "                                               output_types = (tf.int32, tf.int32),\n",
    "                                               output_shapes=(\n",
    "                                                   (BATCH_SIZE, X_BLOCK_LENGHT),\n",
    "                                                   (BATCH_SIZE, X_BLOCK_LENGHT)\n",
    "                                                   )\n",
    "                                               )\n",
    "tfGenEval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qI3WKmspUe2Z"
   },
   "outputs": [],
   "source": [
    "it = tfGenEval.as_numpy_iterator()\n",
    "ne = next(it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ktuZ3D04UzeE"
   },
   "outputs": [],
   "source": [
    "p = model.predict(ne[0])\n",
    "p.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-ZhRrApuU8M1"
   },
   "outputs": [],
   "source": [
    "gtVal = ne[1][0,:]\n",
    "gtVal.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aRfxK1DeVJWp"
   },
   "outputs": [],
   "source": [
    "porig= copy.deepcopy(p)\n",
    "# p = copy.deepcopy(porig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vgzPCL7KVXC1"
   },
   "outputs": [],
   "source": [
    "plt.plot(p[0,0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k6oO5JBsWz_j"
   },
   "outputs": [],
   "source": [
    "intPrediction = np.empty(p.shape[:-1])\n",
    "\n",
    "for b in range(p.shape[0]):\n",
    "  for ts in range(p.shape[1]):\n",
    "    classMax = np.max(p[b,ts,:])\n",
    "    maxIndex = np.where(p[b,ts,:] == classMax)\n",
    "\n",
    "    #print(f\"classMax: {classMax}, maxIndex: {maxIndex}\")\n",
    "    \n",
    "    intPrediction[b,ts] = maxIndex[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RPVXsb8mYGGL"
   },
   "outputs": [],
   "source": [
    "intPrediction.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V-utCJSuYStU"
   },
   "outputs": [],
   "source": [
    "gtVal[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3pXGXuOcYVo2"
   },
   "outputs": [],
   "source": [
    "intPrediction[0,:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "voZjwOaDDph1"
   },
   "outputs": [],
   "source": [
    "_ = plt.hist(gtVal.flatten(), bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a84-E1mj4RUY"
   },
   "outputs": [],
   "source": [
    "_ = plt.hist(intPrediction.flatten(), bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q_DfyjS2gsPi"
   },
   "outputs": [],
   "source": [
    "plt.plot(intPrediction[0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hsSenZntVcu8"
   },
   "outputs": [],
   "source": [
    "pMaxed = p * (p >= np.sort(p, axis=2)[:,[-1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "StZjtHTCV77e"
   },
   "outputs": [],
   "source": [
    "pMaxes = np.max(p, axis=2)\n",
    "pMaxes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pZzVhSx8WplK"
   },
   "outputs": [],
   "source": [
    "# p == pMaxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4sF0q8BlWQte"
   },
   "outputs": [],
   "source": [
    "# p[:] = np.where(p == pMaxes, pMaxes, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1lUV2_40WYcJ"
   },
   "outputs": [],
   "source": [
    "plt.plot(p[0,0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FtG_7-pWWC4s"
   },
   "outputs": [],
   "source": [
    "np.max(p[0,0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RPxpJLVpWF6c"
   },
   "outputs": [],
   "source": [
    "pMaxes[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cOM14p-9VxBY"
   },
   "outputs": [],
   "source": [
    "plt.plot(pMaxed[0,0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KSKQas1GQaM-",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# _save_folder = os.path.join(checkpoint_path,\n",
    "#                                 CHKPNT_NAME,\n",
    "#                                 \"robert_tpu_scratch_{:01d}_{:05d}\".format(112, 0)\n",
    "#                                 )\n",
    "\n",
    "# _model_path_local = os.path.join(\"/content/\", \"model.h5\")\n",
    "# _model_path_bucket = os.path.join(_save_folder, \"model.h5\")\n",
    "\n",
    "# model.save(_model_path_local)\n",
    "\n",
    "# # Copy model.h5 over to Google Cloud Storage\n",
    "# with file_io.FileIO(_model_path_local, mode='rb') as input_f:\n",
    "#     with file_io.FileIO(_model_path_bucket, mode='wb+') as output_f:\n",
    "#         output_f.write(input_f.read())\n",
    "#         print(\"\\nSaved model to: '\" + _model_path_bucket + \"'\")\n",
    "\n",
    "# # Save optimizer config\n",
    "# c = copy.deepcopy(model.optimizer.get_config())\n",
    "\n",
    "# fp = os.path.join(_save_folder, \"c.pickle\")\n",
    "# with file_io.FileIO(fp, mode='wb+') as handle:\n",
    "#   pickle.dump(c, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "#   print(\"Saved optimizer config to: '\" + fp + \"'\")\n",
    "\n",
    "# # Save optimizer weights\n",
    "# w = copy.deepcopy(model.optimizer.get_weights())\n",
    "\n",
    "# fp = os.path.join(_save_folder, \"w.pickle\")\n",
    "# with file_io.FileIO(fp, mode='wb+') as handle:\n",
    "#   pickle.dump(w, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "#   print(\"Saved optimizer weights to: '\" + fp + \"'\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
