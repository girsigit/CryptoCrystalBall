{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RIbOPenP-I_d"
   },
   "source": [
    "# Mount drive and bucket\n",
    "Todo: Remove in public version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "GHybPwDjX1gZ",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Check if the notebook is run in Google Colab\n",
    "import sys\n",
    "\n",
    "COLAB = 'google.colab' in sys.modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_io.TextIOWrapper name='/content/bigdata/nb_20230303_1013.log' mode='a+' encoding='UTF-8'>\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(60000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 60 seconds\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import datetime\n",
    "import logging\n",
    "\n",
    "nblog = open(f\"/content/bigdata/nb_{datetime.datetime.utcnow().strftime('%Y%m%d_%H%M')}.log\", \"a+\")\n",
    "print(nblog)\n",
    "sys.stdout.echo = nblog\n",
    "sys.stderr.echo = nblog\n",
    "\n",
    "#get_ipython().log.handlers[0].stream = nblog\n",
    "#get_ipython().log.setLevel(logging.INFO)\n",
    "\n",
    "%autosave 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sK6Uuoy5qsua",
    "outputId": "d29d48f5-a2e5-40f9-927d-002d32fd48f9"
   },
   "outputs": [],
   "source": [
    "# if COLAB:\n",
    "#   from google.colab import drive\n",
    "#   drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "MTJ7bYMtHmvS"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run the command!\n"
     ]
    }
   ],
   "source": [
    "if COLAB:\n",
    "  from google.colab import auth\n",
    "  auth.authenticate_user()\n",
    "else:\n",
    "    print(\"Run the command!\")\n",
    "  #Todo #bring the command inside the notebook\n",
    "  #run this terminal inside docker: gcloud auth login b.girsule@gmail.com --no-launch-browser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "DOScyXpJws23"
   },
   "outputs": [],
   "source": [
    "# Todo: Check if possible in local docker\n",
    "# from google.cloud import storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "t9dbL-PU-okV",
    "outputId": "14e73bf6-881d-4bc0-96f4-8a1b79cae570"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-03 10:13:27.924941: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-03 10:13:28.055173: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-03-03 10:13:28.697443: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-03-03 10:13:28.697524: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-03-03 10:13:28.697534: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF Version is 2.10.0, ok!\n"
     ]
    }
   ],
   "source": [
    "# Check if the tf version is 2.10.0, this is required to use the 'ignore_class' in the  SparseCategoricalCrossentropy\n",
    "import tensorflow as tf\n",
    "\n",
    "if '2.10.0' != tf.__version__:\n",
    "  !pip uninstall tensorflow -y\n",
    "  !pip install tensorflow-gpu==2.10.0\n",
    "  please_restart_the_runtime\n",
    "else:\n",
    "  print(\"TF Version is 2.10.0, ok!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "FYePtDVpqtkN"
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "# import tensorflow_gcs_config\n",
    "from tensorflow.python.lib.io import file_io\n",
    "\n",
    "from keras.layers import Input, Dense, Flatten #, ReLU, Add, Flatten, Concatenate, LayerNormalization, UpSampling2D, Activation, LSTM, Multiply, Dropout, Reshape, Permute, BatchNormalization, MaxPooling1D, AveragePooling1D, MaxPooling3D, AveragePooling2D, LayerNormalization, MaxPooling2D\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "pxa3Ug_JplIq"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "EcBnUrFKqyCK"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "R_3vswfeRqmj"
   },
   "outputs": [],
   "source": [
    "# Set the google cloud bucket data\n",
    "project_id = 'tweetprediction'\n",
    "bucket_name = 'crypto_nlp_training'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "X3s3eDubSFaJ",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set the checkpoint path for saving train progress\n",
    "if COLAB:\n",
    "    CHECKPOINT_PATH = f\"gs://{bucket_name}/chk/\"\n",
    "else:\n",
    "    CHECKPOINT_PATH = f\"/content/bigdata/chk/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8rvlsLwbpmWJ",
    "outputId": "12f0ff94-d55c-449f-f101-c4581499db7d"
   },
   "outputs": [],
   "source": [
    "# Check if the notebook is run in google colab, if so, clone the repo\n",
    "if COLAB:\n",
    "    print(\"Running in Colab\")\n",
    "\n",
    "    # Clone the whole repo to get all data and code if not already done\n",
    "    if not os.path.exists(\"/content/CryptoCrystalBall\"):\n",
    "      !git clone https://github.com/girsigit/CryptoCrystalBall\n",
    "\n",
    "      # cd into the notebooks directory --> Necessary to match all paths for importing\n",
    "    #%cd /content/CryptoCrystalBall/JupyterDocker/notebooks\n",
    "    %cd /content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "q9OmJ6vFthwG"
   },
   "outputs": [],
   "source": [
    "# Try importing the Ta-Lib library, if this fails, try to install it and\n",
    "# import it again afterwards\n",
    "try:\n",
    "    import talib\n",
    "except:\n",
    "    !wget http://prdownloads.sourceforge.net/ta-lib/ta-lib-0.4.0-src.tar.gz\n",
    "    !tar -xzvf ta-lib-0.4.0-src.tar.gz\n",
    "    %cd ta-lib\n",
    "    !./configure --prefix=/usr\n",
    "    !make\n",
    "    !make install\n",
    "    !pip install Ta-Lib\n",
    "    %cd ..\n",
    "\n",
    "    import talib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "2orTUN099zyA",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moving 0 files to the new cache system\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db48ff155c03426499babeda0130787d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "try:\n",
    "  from transformers import TFRobertaModel, RobertaConfig\n",
    "except:\n",
    "  # Important!: Version 4.23 does not work on TPU\n",
    "  !pip install transformers==4.22\n",
    "\n",
    "  from transformers import TFRobertaModel, RobertaConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip uninstall -y tensorboard-plugin-profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qfAsp4TWHivL",
    "outputId": "a25fdba4-ad57-40a3-f725-7d4ed114d38b",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Required to do profiling\n",
    "# !pip install tensorboard-plugin-profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "axPYAbN9upgY",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nbt7oQxzL2Zy"
   },
   "source": [
    "---\n",
    "# Add custom import path for DataStreamCreator and IndicatorCalculator\n",
    "\n",
    "These libs are not in the standard python directory, so their paths have to be added to the import paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ICDL0OwbL2Zz",
    "outputId": "41c7541e-3a1e-4035-f2f3-182fed452a8e",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['', 'content']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Get the current directory\n",
    "# current_dir = os.getcwd()\n",
    "# current_dir_splitted = current_dir.split(os.sep)\n",
    "\n",
    "# Todo: is inside /content/CB in local docker\n",
    "current_dir_splitted = [\"\", \"content\"]\n",
    "current_dir_splitted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JJ8l6O2gL2Z1",
    "outputId": "de6d884a-f4be-47e2-c808-eeac3448580c",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dsc_dir: /content/CryptoCrystalBall/DataStreamCreator\n",
      "ind_dir: /content/CryptoCrystalBall/IndicatorCalculator\n"
     ]
    }
   ],
   "source": [
    "# Create the import directories for the DataStreamCreator and the IndicatorCalculator\n",
    "dsc_dir = '/content/CryptoCrystalBall/DataStreamCreator'\n",
    "print(f\"dsc_dir: {dsc_dir}\")\n",
    "\n",
    "ind_dir = '/content/CryptoCrystalBall/IndicatorCalculator'\n",
    "print(f\"ind_dir: {ind_dir}\")\n",
    "\n",
    "# Add them to the import paths\n",
    "sys.path.insert(0, dsc_dir)\n",
    "sys.path.insert(0, ind_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "iqyTbcZDttLT",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import the actual classes\n",
    "from IndicatorCalculator import IndicatorCalculator\n",
    "import DataStreamCreator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zPsG4dqRL2Z5"
   },
   "source": [
    "---\n",
    "# Define all the parameters and variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5J8ODl45L2Z6",
    "outputId": "690c2801-687e-47fe-cefc-616e029a62a5",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA_PATH: /content/DemoData\n"
     ]
    }
   ],
   "source": [
    "# Define the tick data path\n",
    "DATA_PATH = os.path.join(os.sep, *current_dir_splitted, 'DemoData')\n",
    "print(f\"DATA_PATH: {DATA_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7TUeLGiOL2Z7",
    "outputId": "00651843-f462-4c20-e6cc-7cb0d7cd6d23",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMG_SAVE_PATH: /content/Documentation/Images\n"
     ]
    }
   ],
   "source": [
    "# Define the chart image save path\n",
    "IMG_SAVE_PATH = os.path.join(os.sep, *current_dir_splitted, 'Documentation', 'Images')\n",
    "print(f\"IMG_SAVE_PATH: {IMG_SAVE_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "id": "o23rkki9ttLZ",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define a global random seed\n",
    "RANDOM_SEED = 42+3\n",
    "\n",
    "# Set the seed in np\n",
    "np.random.seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "g9gBeRtnxKMD",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# X_BLOCK_LENGHT defines how far into the past a 'slice of a chart' shall be\n",
    "# See: https://github.com/girsigit/CryptoCrystalBall/tree/main/DataStreamCreator#xblockgenerator\n",
    "X_BLOCK_LENGHT = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "sh5dsBKr5Ko-",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# How many examples shall be processed at the same time, limited by GPU memory\n",
    "BATCH_SIZE = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "J331jHk-u345",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# A fixed number of features is used\n",
    "FEATURES = 160"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "1JVT1Z2U0lW8",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Finanical indicator timespans\n",
    "# See: https://github.com/girsigit/CryptoCrystalBall/tree/main/IndicatorCalculator\n",
    "SHORTSPAN = 7\n",
    "MIDSPAN = 38\n",
    "LONGSPAN = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "AnNz-Oke3J3p",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Additional settings for the data stream\n",
    "# For this notebook, the calculation of pattern indicators is turned off\n",
    "DATA_STREAM_PARAMETERS = {\n",
    "    \"calcPatternIndicators\": False, # No patterns are used\n",
    "    \"calcVolumeInidators\": False, # No volume indicators, these are wide spread and may disturb the classifer\n",
    "    \"dropna\": True # Drop all tick/indicator table rows containing nan values instead of just replacing them by 0 (which would lead to wrong predictions)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7xXpDFe9ROVQ"
   },
   "source": [
    "# Load the train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "b2EO18ZmppNe",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Check if the dataset already has been copy, if not, copy it\n",
    "# if not os.path.exists(\"/content/dataset\") or not os.path.exists(\"/content/dataset/Train\"):\n",
    "#   !mkdir /content/dataset\n",
    "#   !mkdir /content/dataset/Train\n",
    "#   !gsutil -m cp -r gs://cryptocrystalball_public/CryptoDataset/Hourly/significant_currencies.txt /content/dataset/significant_currencies.txt\n",
    "#   !gsutil -m cp -r gs://cryptocrystalball_public/CryptoDataset/Hourly/Train/* /content/dataset/Train/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2sRVckzNtbZL",
    "outputId": "5cfd2c06-7823-40b3-eea8-2dbc3f51df57",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# #@markdown ### Use only significant currencies\n",
    "# #@markdown Load a manually defined list of significant currencies (`significant_currencies.txt`).\n",
    "# #@markdown This list contains no currencies which little or no volume or price movement, to\n",
    "# #@markdown avoid training on data sample which would never be used to trade on in a real \n",
    "# #@markdown application.\n",
    "\n",
    "# #@markdown If enabled, only currency pairs with the base currency USDT are laoded,\n",
    "# #@markdown this is important to prevent interference between different cryptocurrencies.\n",
    "# #@markdown For example, in `BTC-ETH.csv`, there is influence of both the BTC and the ETH price, but we want to predict trade signals based on a 'real' currency (USDT is kind of the same as USD).\n",
    "\n",
    "# significant_only = True #@param {type:\"boolean\"}\n",
    "\n",
    "# if significant_only:\n",
    "#   with open(\"/content/dataset/significant_currencies.txt\") as f:\n",
    "#     SIGNIFICANT_CURRS = f.read().splitlines()\n",
    "\n",
    "#   print(f\"Loaded {len(SIGNIFICANT_CURRS)} significant files names.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dlNAUwUTtdBE",
    "outputId": "3c614762-758a-444f-dc86-e86527a6c0ca",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Get train file names - Only pick the ones ending with -USDT to prevent\n",
    "# # influence between different currencies\n",
    "# TRAIN_PATH = \"/content/dataset/Train\"\n",
    "\n",
    "# # Get all file names\n",
    "# TRAIN_FILES = [os.path.join(TRAIN_PATH,f) for f in listdir(TRAIN_PATH) if isfile(join(TRAIN_PATH, f)) and \".csv\" in f ]\n",
    "\n",
    "# # Filter for significant currencies only\n",
    "# if significant_only:\n",
    "#   TRAIN_FILES = [f for f in TRAIN_FILES if f.split(\"/\")[-1].replace(\".csv\",\"\") in SIGNIFICANT_CURRS]\n",
    "\n",
    "# # Filter for USDT-based ones only\n",
    "# TRAIN_FILES = [f for f in TRAIN_FILES if \"-USDT\" in f]\n",
    "\n",
    "# # Sort them (as a stable basis for randomizing afterwards)\n",
    "# TRAIN_FILES = sorted(TRAIN_FILES)\n",
    "\n",
    "# print(f\"The train dataset contains {len(TRAIN_FILES)} files.\")\n",
    "# print(TRAIN_FILES[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The train dataset contains 1064 files.\n",
      "['/content/dataset/etffancy/DE0002635265.csv', '/content/dataset/etffancy/DE0002635273.csv', '/content/dataset/etffancy/DE0002635281.csv']\n"
     ]
    }
   ],
   "source": [
    "# Get train file names - Only pick the ones ending with -USDT to prevent\n",
    "# influence between different currencies\n",
    "TRAIN_PATH = \"/content/dataset/etffancy\"\n",
    "\n",
    "# Get all file names\n",
    "TRAIN_FILES = [os.path.join(TRAIN_PATH,f) for f in listdir(TRAIN_PATH) if isfile(join(TRAIN_PATH, f)) and \".csv\" in f ]\n",
    "\n",
    "# Sort them (as a stable basis for randomizing afterwards)\n",
    "TRAIN_FILES = sorted(TRAIN_FILES)\n",
    "\n",
    "print(f\"The train dataset contains {len(TRAIN_FILES)} files.\")\n",
    "print(TRAIN_FILES[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J9cA0AKquwZ2"
   },
   "source": [
    "---\n",
    "# Prepare data source\n",
    "\n",
    "For training a neural network, first the data source has to be prepared. For this purpose, the method `FileListToDataStream` from the `DataStreamCreator` class is used. This method creates a stream of `X-Block` and `y-data` arrays out of a list of .csv file names, pointing to tick tables (called `EXAMPLE_FILE_PATHS` in this example). For details about `X-Blocks` and `y-data`, please refer to the documentation of the `XBlockGenerator` and the `YDataGenerator` under https://github.com/girsigit/CryptoCrystalBall/tree/main/DataStreamCreator.\n",
    "\n",
    "<br>\n",
    "\n",
    "Target values (y-data) from the data generator would not be necessary in this notebook, but since it cannot be switched off, the future direction and its derviation of the price have been chosen in `Y_TYPE_DICT` since they are not expensive to compute. A switch flag will be added in a future release."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pqze4dT8uz6V",
    "outputId": "985dae70-a5db-4972-bde2-b52e5b15c6b5",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dataType': 0,\n",
       " 'direction_ma_timespan': 200,\n",
       " 'derivation_ma_timespan': 100,\n",
       " 'direction_derivation_shift_span': 0}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set direction and derivation information as y target\n",
    "# Both y values (direction & derivation) are in the interval [-1.0,1.0]\n",
    "\n",
    "Y_TYPE_DICT = copy.deepcopy(DataStreamCreator.YDataGenerator.PARAM_DICT_TEMPLATE_Y_DATA_TYPE_DIRECTION_FLOAT)\n",
    "Y_TYPE_DICT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_FEATURE_CNT = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(512, 64, 256)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XShape = (BATCH_SIZE, X_BLOCK_LENGHT, TARGET_FEATURE_CNT)\n",
    "XShape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "id": "S2e6q_2su26o",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# A python generator function has to be applied on the dataStream\n",
    "\n",
    "def pythonGeneratorMLMTraining():\n",
    "  # Initialize the FileListToDataStream generator\n",
    "  dataStreamTraining = DataStreamCreator.FileListToDataStream(fileList = TRAIN_FILES,\n",
    "                                                      batch_size = BATCH_SIZE,\n",
    "                                                      X_Block_lenght = X_BLOCK_LENGHT,\n",
    "                                                      y_type_dict=Y_TYPE_DICT,\n",
    "                                                      shuffle=True,\n",
    "                                                      parallel_generators = np.min([BATCH_SIZE, 8]),\n",
    "                                                      random_seed = RANDOM_SEED,\n",
    "                                                      **DATA_STREAM_PARAMETERS\n",
    "                                                      )\n",
    "\n",
    "  # This while has to integrated into the FileListToDataStream method\n",
    "  while True:  \n",
    "    try:\n",
    "      ne = next(dataStreamTraining)\n",
    "      _X = ne['X']\n",
    "      _y = ne['y']\n",
    "    \n",
    "      # 'Blow up' the X array to a 2**n size\n",
    "      _X_new = np.zeros((_X.shape[0], _X.shape[1], TARGET_FEATURE_CNT))\n",
    "      _X_new[:,:,:_X.shape[2]] = _X\n",
    "\n",
    "      yield (_X_new, _y)\n",
    "    except StopIteration as si:\n",
    "      logging.warning(\"StopIteration in pythonGenerator\")\n",
    "      logging.warning(si)\n",
    "      return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FoTRNHyEvnyg",
    "outputId": "d7fb1944-9236-47c2-c749-8a999e6fe3e3",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<FlatMapDataset element_spec=(TensorSpec(shape=(512, 64, 256), dtype=tf.int32, name=None), TensorSpec(shape=(512, 2), dtype=tf.float32, name=None))>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a Tensorflow dataset out of the python generator, which can be fed to the network\n",
    "tfGenTraining = tf.data.Dataset.from_generator(pythonGeneratorMLMTraining, \n",
    "                                               output_types = (tf.int32, tf.float32),\n",
    "                                               output_shapes=(\n",
    "                                                   (BATCH_SIZE, X_BLOCK_LENGHT, TARGET_FEATURE_CNT),\n",
    "                                                   (BATCH_SIZE, 2)\n",
    "                                                   )\n",
    "                                               )\n",
    "tfGenTraining.prefetch(buffer_size=2)\n",
    "tfGenTraining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "moBea0tTbFbX"
   },
   "source": [
    "---\n",
    "# Create the neural network\n",
    "\n",
    "In the example, two Conv1D pyramids are used to extract features at different levels out of the feature and the time dimension.\n",
    "\n",
    "It is also possible to use different architecures, like LSTM, Conv2D, Attention-Based ones or even NLP-based models. I have already tried many different ones and will publish them into the model zoo.\n",
    "\n",
    "```\n",
    "Todo: Create Model Zoo\n",
    "```\n",
    "\n",
    "```\n",
    "Todo: Create Image of netwrok structure\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from keras.layers import Input, Dense, ReLU, Add, Flatten, Concatenate, LayerNormalization, UpSampling2D, Activation, LSTM, Multiply, Dropout, Reshape, Permute, BatchNormalization, MaxPooling1D, AveragePooling1D, MaxPooling3D, AveragePooling2D, LayerNormalization, MaxPooling2D, UnitNormalization, UpSampling1D\n",
    "from keras.layers import UnitNormalization, Permute, Conv1D, UpSampling1D, Add, LSTM, Concatenate, Multiply, Activation, Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256\n",
      "Step 0, using 64 filters with a kernel size of 2 at strides of 2\n",
      "attention_map.shape: (None, 128, 64)\n",
      "feature_conv_attentioned.shape: (None, 128, 64)\n",
      "Step 1, using 128 filters with a kernel size of 4 at strides of 2\n",
      "attention_map.shape: (None, 64, 128)\n",
      "feature_conv_attentioned.shape: (None, 64, 128)\n",
      "Step 2, using 256 filters with a kernel size of 8 at strides of 2\n",
      "attention_map.shape: (None, 32, 256)\n",
      "feature_conv_attentioned.shape: (None, 32, 256)\n",
      "Step 3, using 512 filters with a kernel size of 8 at strides of 2\n",
      "attention_map.shape: (None, 16, 512)\n",
      "feature_conv_attentioned.shape: (None, 16, 512)\n",
      "Step 4, using 1024 filters with a kernel size of 8 at strides of 2\n",
      "attention_map.shape: (None, 8, 1024)\n",
      "feature_conv_attentioned.shape: (None, 8, 1024)\n",
      "Step 5, using 2048 filters with a kernel size of 8 at strides of 2\n",
      "attention_map.shape: (None, 4, 2048)\n",
      "feature_conv_attentioned.shape: (None, 4, 2048)\n",
      "Building feature_map_layers, step 5. Shape of aligned_layer: (None, 4, 256)\n",
      "Building feature_map_layers, step 4. Shape of aligned_layer: (None, 8, 256)\n",
      "Building feature_map_layers, step 3. Shape of aligned_layer: (None, 16, 256)\n",
      "Building feature_map_layers, step 2. Shape of aligned_layer: (None, 32, 256)\n",
      "{'NAME': 'FPNWithAttention', 'VERSION': '1_ETF_Trained', 'CNN_INITIAL_FILTERS': 64, 'CNN_EXTRACTOR_LAYERS': 6, 'CNN_INITIAL_KERNEL_SIZE': 2, 'CNN_MAX_KERNEL_SIZE': 8, 'FEATURE_PYRAMID_START_INDEX': 2, 'HEAD_LSTM_SIZE': 32, 'HEAD_DENSE_SIZE': 16}\n",
      "Model: \"FPNWithAttention_1_ETF_Trained\"\n",
      "____________________________________________________________________________________________________________________________________________________________________________________________________________________________\n",
      " Layer (type)                                                           Output Shape                                     Param #                   Connected to                                                             \n",
      "============================================================================================================================================================================================================================\n",
      " inputTicksAndIndicators (InputLayer)                                   [(None, 64, 256)]                                0                         []                                                                       \n",
      "                                                                                                                                                                                                                            \n",
      " UnitNormalizationInput (UnitNormalization)                             (None, 64, 256)                                  0                         ['inputTicksAndIndicators[0][0]']                                        \n",
      "                                                                                                                                                                                                                            \n",
      " PermuteInput (Permute)                                                 (None, 256, 64)                                  0                         ['UnitNormalizationInput[0][0]']                                         \n",
      "                                                                                                                                                                                                                            \n",
      " Feature_Conv1D_0 (Conv1D)                                              (None, 128, 64)                                  8256                      ['PermuteInput[0][0]']                                                   \n",
      "                                                                                                                                                                                                                            \n",
      " Feature_Conv1D_1 (Conv1D)                                              (None, 64, 128)                                  32896                     ['Feature_Conv1D_0[0][0]']                                               \n",
      "                                                                                                                                                                                                                            \n",
      " Feature_Conv1D_2 (Conv1D)                                              (None, 32, 256)                                  262400                    ['Feature_Conv1D_1[0][0]']                                               \n",
      "                                                                                                                                                                                                                            \n",
      " Feature_Conv1D_3 (Conv1D)                                              (None, 16, 512)                                  1049088                   ['Feature_Conv1D_2[0][0]']                                               \n",
      "                                                                                                                                                                                                                            \n",
      " Feature_Conv1D_4 (Conv1D)                                              (None, 8, 1024)                                  4195328                   ['Feature_Conv1D_3[0][0]']                                               \n",
      "                                                                                                                                                                                                                            \n",
      " Feature_Conv1D_5 (Conv1D)                                              (None, 4, 2048)                                  16779264                  ['Feature_Conv1D_4[0][0]']                                               \n",
      "                                                                                                                                                                                                                            \n",
      " Attention_Layer_5 (Attention)                                          (None, 4, 2048)                                  0                         ['Feature_Conv1D_5[0][0]',                                               \n",
      "                                                                                                                                                    'Feature_Conv1D_5[0][0]']                                               \n",
      "                                                                                                                                                                                                                            \n",
      " Multiply_Apply_Attention_5 (Multiply)                                  (None, 4, 2048)                                  0                         ['Feature_Conv1D_5[0][0]',                                               \n",
      "                                                                                                                                                    'Attention_Layer_5[0][0]']                                              \n",
      "                                                                                                                                                                                                                            \n",
      " Attention_Layer_4 (Attention)                                          (None, 8, 1024)                                  0                         ['Feature_Conv1D_4[0][0]',                                               \n",
      "                                                                                                                                                    'Feature_Conv1D_4[0][0]']                                               \n",
      "                                                                                                                                                                                                                            \n",
      " Channel_Depth_Alignment_5 (Conv1D)                                     (None, 4, 256)                                   524544                    ['Multiply_Apply_Attention_5[0][0]']                                     \n",
      "                                                                                                                                                                                                                            \n",
      " Multiply_Apply_Attention_4 (Multiply)                                  (None, 8, 1024)                                  0                         ['Feature_Conv1D_4[0][0]',                                               \n",
      "                                                                                                                                                    'Attention_Layer_4[0][0]']                                              \n",
      "                                                                                                                                                                                                                            \n",
      " Pyramid_Upsampling_4 (UpSampling1D)                                    (None, 8, 256)                                   0                         ['Channel_Depth_Alignment_5[0][0]']                                      \n",
      "                                                                                                                                                                                                                            \n",
      " Channel_Depth_Alignment_4 (Conv1D)                                     (None, 8, 256)                                   262400                    ['Multiply_Apply_Attention_4[0][0]']                                     \n",
      "                                                                                                                                                                                                                            \n",
      " Attention_Layer_3 (Attention)                                          (None, 16, 512)                                  0                         ['Feature_Conv1D_3[0][0]',                                               \n",
      "                                                                                                                                                    'Feature_Conv1D_3[0][0]']                                               \n",
      "                                                                                                                                                                                                                            \n",
      " Pyramid_Add_4 (Add)                                                    (None, 8, 256)                                   0                         ['Pyramid_Upsampling_4[0][0]',                                           \n",
      "                                                                                                                                                    'Channel_Depth_Alignment_4[0][0]']                                      \n",
      "                                                                                                                                                                                                                            \n",
      " Multiply_Apply_Attention_3 (Multiply)                                  (None, 16, 512)                                  0                         ['Feature_Conv1D_3[0][0]',                                               \n",
      "                                                                                                                                                    'Attention_Layer_3[0][0]']                                              \n",
      "                                                                                                                                                                                                                            \n",
      " Pyramid_Upsampling_3 (UpSampling1D)                                    (None, 16, 256)                                  0                         ['Pyramid_Add_4[0][0]']                                                  \n",
      "                                                                                                                                                                                                                            \n",
      " Channel_Depth_Alignment_3 (Conv1D)                                     (None, 16, 256)                                  131328                    ['Multiply_Apply_Attention_3[0][0]']                                     \n",
      "                                                                                                                                                                                                                            \n",
      " Pyramid_Add_3 (Add)                                                    (None, 16, 256)                                  0                         ['Pyramid_Upsampling_3[0][0]',                                           \n",
      "                                                                                                                                                    'Channel_Depth_Alignment_3[0][0]']                                      \n",
      "                                                                                                                                                                                                                            \n",
      " Attention_Layer_2 (Attention)                                          (None, 32, 256)                                  0                         ['Feature_Conv1D_2[0][0]',                                               \n",
      "                                                                                                                                                    'Feature_Conv1D_2[0][0]']                                               \n",
      "                                                                                                                                                                                                                            \n",
      " Pyramid_Upsampling_2 (UpSampling1D)                                    (None, 32, 256)                                  0                         ['Pyramid_Add_3[0][0]']                                                  \n",
      "                                                                                                                                                                                                                            \n",
      " Multiply_Apply_Attention_2 (Multiply)                                  (None, 32, 256)                                  0                         ['Feature_Conv1D_2[0][0]',                                               \n",
      "                                                                                                                                                    'Attention_Layer_2[0][0]']                                              \n",
      "                                                                                                                                                                                                                            \n",
      " Pyramid_Add_2 (Add)                                                    (None, 32, 256)                                  0                         ['Pyramid_Upsampling_2[0][0]',                                           \n",
      "                                                                                                                                                    'Multiply_Apply_Attention_2[0][0]']                                     \n",
      "                                                                                                                                                                                                                            \n",
      " Anti_Alias_4 (Conv1D)                                                  (None, 8, 256)                                   196864                    ['Pyramid_Add_4[0][0]']                                                  \n",
      "                                                                                                                                                                                                                            \n",
      " Anti_Alias_3 (Conv1D)                                                  (None, 16, 256)                                  196864                    ['Pyramid_Add_3[0][0]']                                                  \n",
      "                                                                                                                                                                                                                            \n",
      " Anti_Alias_2 (Conv1D)                                                  (None, 32, 256)                                  196864                    ['Pyramid_Add_2[0][0]']                                                  \n",
      "                                                                                                                                                                                                                            \n",
      " PermutePredictorInput_5 (Permute)                                      (None, 256, 4)                                   0                         ['Channel_Depth_Alignment_5[0][0]']                                      \n",
      "                                                                                                                                                                                                                            \n",
      " PermutePredictorInput_4 (Permute)                                      (None, 256, 8)                                   0                         ['Anti_Alias_4[0][0]']                                                   \n",
      "                                                                                                                                                                                                                            \n",
      " PermutePredictorInput_3 (Permute)                                      (None, 256, 16)                                  0                         ['Anti_Alias_3[0][0]']                                                   \n",
      "                                                                                                                                                                                                                            \n",
      " PermutePredictorInput_2 (Permute)                                      (None, 256, 32)                                  0                         ['Anti_Alias_2[0][0]']                                                   \n",
      "                                                                                                                                                                                                                            \n",
      " Predictor_Head_5_LSTM (LSTM)                                           (None, 32)                                       4736                      ['PermutePredictorInput_5[0][0]']                                        \n",
      "                                                                                                                                                                                                                            \n",
      " Predictor_Head_4_LSTM (LSTM)                                           (None, 32)                                       5248                      ['PermutePredictorInput_4[0][0]']                                        \n",
      "                                                                                                                                                                                                                            \n",
      " Predictor_Head_3_LSTM (LSTM)                                           (None, 32)                                       6272                      ['PermutePredictorInput_3[0][0]']                                        \n",
      "                                                                                                                                                                                                                            \n",
      " Predictor_Head_2_LSTM (LSTM)                                           (None, 32)                                       8320                      ['PermutePredictorInput_2[0][0]']                                        \n",
      "                                                                                                                                                                                                                            \n",
      " Predictor_Head_5_Dense_Regressor (Dense)                               (None, 16)                                       528                       ['Predictor_Head_5_LSTM[0][0]']                                          \n",
      "                                                                                                                                                                                                                            \n",
      " Predictor_Head_4_Dense_Regressor (Dense)                               (None, 16)                                       528                       ['Predictor_Head_4_LSTM[0][0]']                                          \n",
      "                                                                                                                                                                                                                            \n",
      " Predictor_Head_3_Dense_Regressor (Dense)                               (None, 16)                                       528                       ['Predictor_Head_3_LSTM[0][0]']                                          \n",
      "                                                                                                                                                                                                                            \n",
      " Predictor_Head_2_Dense_Regressor (Dense)                               (None, 16)                                       528                       ['Predictor_Head_2_LSTM[0][0]']                                          \n",
      "                                                                                                                                                                                                                            \n",
      " Concatenate_regressors (Concatenate)                                   (None, 64)                                       0                         ['Predictor_Head_5_Dense_Regressor[0][0]',                               \n",
      "                                                                                                                                                    'Predictor_Head_4_Dense_Regressor[0][0]',                               \n",
      "                                                                                                                                                    'Predictor_Head_3_Dense_Regressor[0][0]',                               \n",
      "                                                                                                                                                    'Predictor_Head_2_Dense_Regressor[0][0]']                               \n",
      "                                                                                                                                                                                                                            \n",
      " Combined_Regressor_1 (Dense)                                           (None, 64)                                       4160                      ['Concatenate_regressors[0][0]']                                         \n",
      "                                                                                                                                                                                                                            \n",
      " Combined_Regressor_2 (Dense)                                           (None, 64)                                       4160                      ['Combined_Regressor_1[0][0]']                                           \n",
      "                                                                                                                                                                                                                            \n",
      " Output (Dense)                                                         (None, 2)                                        130                       ['Combined_Regressor_2[0][0]']                                           \n",
      "                                                                                                                                                                                                                            \n",
      "============================================================================================================================================================================================================================\n",
      "Total params: 23,871,234\n",
      "Trainable params: 23,871,234\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________________________________________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create the FPNWithFScaledInput model\n",
    "# Infos about the feature pyramid: https://jonathan-hui.medium.com/understanding-feature-pyramid-networks-for-object-detection-fpn-45b227b9106c\n",
    "\n",
    "def CreateModelFPNWithAttention():\n",
    "  # Define model parameters\n",
    "  mp = {\n",
    "      \"NAME\": \"FPNWithAttention\",\n",
    "      \"VERSION\": \"1_ETF_Trained\",\n",
    "      \"CNN_INITIAL_FILTERS\": 64, \n",
    "      \"CNN_EXTRACTOR_LAYERS\": 6,\n",
    "      \"CNN_INITIAL_KERNEL_SIZE\": 2,\n",
    "      \"CNN_MAX_KERNEL_SIZE\": 8,\n",
    "      \"FEATURE_PYRAMID_START_INDEX\": 2,\n",
    "      \"HEAD_LSTM_SIZE\": 32,\n",
    "      \"HEAD_DENSE_SIZE\": 16\n",
    "      }\n",
    "  \n",
    "  # Create the model input  \n",
    "  inputTicksAndIndicators = Input(shape=(X_BLOCK_LENGHT, TARGET_FEATURE_CNT), name='inputTicksAndIndicators', dtype='float32')\n",
    "\n",
    "  # Normalize the input data, as it has a wide value spread (range of 1e8)\n",
    "  normalized = UnitNormalization(name=\"UnitNormalizationInput\", axis=-2)(inputTicksAndIndicators)\n",
    "\n",
    "  # Permute it to Conv over Features\n",
    "  normalized = Permute((2, 1), name=\"PermuteInput\")(normalized)\n",
    "\n",
    "  # ----------------------------------------------------------------------------\n",
    "\n",
    "  # As an example a 1D-CNN pyramid is used to extract higher-level features out\n",
    "  # of the indicator+tick dimension\n",
    "  conv_layers = []\n",
    "  aligned_layers = []\n",
    "  feature_map_layers = []\n",
    "  anti_aliased_layers = []\n",
    "  anti_aliased_pyramid_indices = []\n",
    "  regressor_layers = []\n",
    "\n",
    "  finalFilters = mp[\"CNN_INITIAL_FILTERS\"] * 2**(mp[\"FEATURE_PYRAMID_START_INDEX\"])\n",
    "  print(finalFilters) \n",
    "\n",
    "  for i in range(mp[\"CNN_EXTRACTOR_LAYERS\"]):\n",
    "    if 0 == i:\n",
    "      source_layer = normalized\n",
    "    else:\n",
    "      source_layer = feature_conv\n",
    "    \n",
    "    filters = int(mp[\"CNN_INITIAL_FILTERS\"]*(2**i))\n",
    "    kernel_size = mp[\"CNN_INITIAL_KERNEL_SIZE\"]*(2**i)\n",
    "    kernel_size = int(np.min([mp[\"CNN_MAX_KERNEL_SIZE\"], kernel_size]))\n",
    "    strides = int(np.min([2,kernel_size]))\n",
    "\n",
    "    print(f\"Step {i}, using {filters} filters with a kernel size of {kernel_size} at strides of {strides}\")\n",
    "\n",
    "    # Create the feature extraction convolution\n",
    "    feature_conv = Conv1D(filters=filters,\n",
    "                          kernel_size=kernel_size,\n",
    "                          strides=strides, \n",
    "                          padding=\"same\",\n",
    "                          name=f\"Feature_Conv1D_{i}\")(source_layer)\n",
    "\n",
    "    # # Calculate the attention filters\n",
    "    # attention_f = Conv1D(filters=1,\n",
    "    #                      kernel_size=1,\n",
    "    #                      strides=1, \n",
    "    #                      padding=\"same\",\n",
    "    #                      name=f\"Attention_f_Conv1D_{i}\")(feature_conv)\n",
    "  \n",
    "    # attention_g = Conv1D(filters=1,\n",
    "    #                      kernel_size=1,\n",
    "    #                      strides=1, \n",
    "    #                      padding=\"same\",\n",
    "    #                      name=f\"Attention_g_Conv1D_{i}\")(feature_conv)\n",
    "   \n",
    "    # attention_h = Conv1D(filters=1,\n",
    "    #                      kernel_size=1,\n",
    "    #                      strides=1, \n",
    "    #                      padding=\"same\",\n",
    "    #                      name=f\"Attention_h_Conv1D_{i}\")(feature_conv)\n",
    "\n",
    "    # attention_map = Attention(name=f\"Attention_Layer_{i}\")([attention_f,attention_g,attention_h])\n",
    "    attention_map = Attention(name=f\"Attention_Layer_{i}\")([feature_conv,feature_conv])\n",
    "    print(f\"attention_map.shape: {attention_map.shape}\")\n",
    "\n",
    "    feature_conv_attentioned = Multiply(name=f\"Multiply_Apply_Attention_{i}\")([feature_conv, attention_map])\n",
    "    print(f\"feature_conv_attentioned.shape: {feature_conv_attentioned.shape}\")\n",
    "    \n",
    "    # feature_conv_attentioned = Conv1D(filters=filters,\n",
    "    #                                   kernel_size=1,\n",
    "    #                                   strides=1, \n",
    "    #                                   padding=\"same\",\n",
    "    #                                   name=f\"Feature_Conv1D_Attentioned_Filterextend{i}\")(feature_conv_attentioned)\n",
    "    # print(f\"feature_conv_attentioned.shape: {feature_conv_attentioned.shape}\")\n",
    "\n",
    "    conv_layers.append(feature_conv_attentioned)\n",
    "\n",
    "    # Apply the feature extraction pyramid\n",
    "    if mp[\"FEATURE_PYRAMID_START_INDEX\"] <= i:\n",
    "      # Apply a 1x1 convolution to align the channel depth    \n",
    "      if feature_conv_attentioned.shape[-1] != finalFilters:\n",
    "        aligned_layer = Conv1D(filters=finalFilters,\n",
    "                              kernel_size=1,\n",
    "                              strides=1,\n",
    "                              padding=\"same\",\n",
    "                              name=f\"Channel_Depth_Alignment_{i}\")(feature_conv_attentioned)\n",
    "      else:\n",
    "        aligned_layer = feature_conv_attentioned\n",
    "      \n",
    "      aligned_layers.append(aligned_layer)\n",
    "\n",
    "  # Go top-down through the aligned_layers to create the feature_map_layers\n",
    "  for i in range(mp[\"CNN_EXTRACTOR_LAYERS\"]-1, mp[\"FEATURE_PYRAMID_START_INDEX\"]-1, -1):\n",
    "    aligned_layers_index = i - mp[\"FEATURE_PYRAMID_START_INDEX\"]\n",
    "    aligned_layer = aligned_layers[aligned_layers_index]\n",
    "\n",
    "    print(f\"Building feature_map_layers, step {i}. Shape of aligned_layer: {aligned_layer.shape}\")\n",
    "\n",
    "    # The highest-filtered layer is taken as feature map directly\n",
    "    if i == mp[\"CNN_EXTRACTOR_LAYERS\"]-1:\n",
    "      feature_map_layers.append(aligned_layer)\n",
    "      anti_aliased_layers.append(feature_map_layers[-1])\n",
    "    else:\n",
    "      # Take the last feature_map_layer and scale it by two\n",
    "      upsampled = UpSampling1D(size=2,\n",
    "                               name=f\"Pyramid_Upsampling_{i}\")(feature_map_layers[-1])\n",
    "\n",
    "      # Add the aligned_layer\n",
    "      added = Add(name=f\"Pyramid_Add_{i}\")([upsampled, aligned_layer])\n",
    "\n",
    "      # Append as new feature_map_layer\n",
    "      feature_map_layers.append(added)\n",
    "\n",
    "      # Apply a convolution with a kernel size of 3 to \"reduce the aliasing effect\"\n",
    "      anti_aliased_layer = Conv1D(filters=feature_map_layers[-1].shape[-1],\n",
    "                                  kernel_size=3,\n",
    "                                  strides=1,\n",
    "                                  padding=\"same\",\n",
    "                                  name=f\"Anti_Alias_{i}\")(feature_map_layers[-1])\n",
    "\n",
    "      anti_aliased_layers.append(anti_aliased_layer)\n",
    "\n",
    "    # Helper storage to keep pyramid index consistent, also in predictor/regressor\n",
    "    anti_aliased_pyramid_indices.append(i)\n",
    "\n",
    "  # Apply the predictor head to each feature dimension layer\n",
    "  for n in range(len(anti_aliased_layers)):\n",
    "    predictor_input = anti_aliased_layers[n]\n",
    "\n",
    "    # Get the pyramid index\n",
    "    pyramid_index = anti_aliased_pyramid_indices[n]\n",
    "\n",
    "    # Permute the Conv output back\n",
    "    predictor_input = Permute((2, 1), name=f\"PermutePredictorInput_{pyramid_index}\")(predictor_input)\n",
    "\n",
    "    predictor = LSTM(units=mp[\"HEAD_LSTM_SIZE\"],\n",
    "                     name=f\"Predictor_Head_{pyramid_index}_LSTM\")(predictor_input)\n",
    "    \n",
    "    # Direction and derivation regressor\n",
    "    regressor = Dense(units=mp[\"HEAD_DENSE_SIZE\"],\n",
    "                      name=f\"Predictor_Head_{pyramid_index}_Dense_Regressor\",\n",
    "                      activation='relu')(predictor)\n",
    "    \n",
    "    regressor_layers.append(regressor)\n",
    "  \n",
    "  # Add all regressors together\n",
    "  regressor_conced = Concatenate(name=\"Concatenate_regressors\")(regressor_layers)\n",
    "  regressor_conced = Dense(regressor_conced.shape[1], name=\"Combined_Regressor_1\")(regressor_conced)\n",
    "  regressor_conced = Dense(regressor_conced.shape[1], name=\"Combined_Regressor_2\")(regressor_conced)\n",
    "\n",
    "  # The output are two values (direction and derivation) in the range [-1.0, 1.0]\n",
    "  output = Dense(2, activation='tanh', name=\"Output\")(regressor_conced)\n",
    "  outputs = [output]\n",
    "\n",
    "  # Combine it all into a model object\n",
    "  model = Model(inputs=inputTicksAndIndicators, outputs=outputs, name=mp[\"NAME\"] + \"_\" + str(mp[\"VERSION\"]))\n",
    "\n",
    "  return model, mp\n",
    "\n",
    "model, model_config = CreateModelFPNWithAttention()\n",
    "print(model_config)\n",
    "model.summary(line_length=220)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# model.load_weights(\"/content/bigdata/chk/FPNWithFScaledInput_3_GPU_64LB/cp_daily_valid_202_end/model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# model.get_layer(\"CryptoRoberta\").set_weights(modelMLM.get_layer(\"tf_roberta_model\").get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# model.get_layer(\"CryptoRoberta\").trainable=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# model.save(\"/content/bigdata/RobertaToDirDerv_1_init.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.load_weights(\"/content/bigdata/RobertaToDirDerv_1_init.h5\")\n",
    "#model.load_weights(\"/content/bigdata/chk/RobertaToDirDerv_1_GPU_512LB_10000VC_MaskedPrediction/cp_daily_valid_00_18000/model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kXE8AjjoEWE4"
   },
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QfwL7EWInGWB"
   },
   "source": [
    "### Train strategy in the paper\n",
    "https://huggingface.co/roberta-base\n",
    "\n",
    "The model was trained on 1024 V100 GPUs for 500K steps with a batch size of 8K and a sequence length of 512. The optimizer used is Adam with a learning rate of 6e-4, β1=0.9\\beta_{1} = 0.9β1​=0.9, β2=0.98\\beta_{2} = 0.98β2​=0.98 and ϵ=1e−6\\epsilon = 1e-6ϵ=1e−6, a weight decay of 0.01, learning rate warmup for 24,000 steps and linear decay of the learning rate after."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "_jkOrQ01hZnE",
    "outputId": "afe655bf-d35c-4f71-ced0-d225a2ff6155"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'FPNWithAttention_1_ETF_Trained_GPU_64LB'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CHKPNT_NAME = f\"{model.name}_GPU_{X_BLOCK_LENGHT}LB\"\n",
    "CHKPNT_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "g0VmovApkwAB"
   },
   "outputs": [],
   "source": [
    "# Set an optimizer\n",
    "optimizer = Adam(\n",
    "    learning_rate=5e-03,\n",
    "    epsilon=1e-06,\n",
    "    beta_1=0.9,\n",
    "    beta_2=0.98,\n",
    "    decay=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "AOLSygN7Ut7_"
   },
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer = optimizer,\n",
    "    loss = [\"mse\"], \n",
    "    metrics=[\"mae\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TFa0iWcaqli5",
    "outputId": "0ec595c6-7c5c-4723-8a2c-64d0d7a07f08"
   },
   "outputs": [],
   "source": [
    "# model.summary(line_length=220)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title CustomCallback\n",
    "class CustomCallback(tf.keras.callbacks.Callback):\n",
    "  def __init__(self, save_freq, val_freq, checkpoint_path, model_name, epoch_add=0):\n",
    "    self.save_freq = save_freq\n",
    "    self.val_freq = val_freq\n",
    "    self.checkpoint_path = checkpoint_path\n",
    "    self.model_name = model_name\n",
    "    self.current_epoch = 0\n",
    "    self.epoch_add = epoch_add\n",
    "\n",
    "  def on_epoch_begin(self, epoch, logs=None):\n",
    "    self.current_epoch = epoch + self.epoch_add\n",
    "    # keys = list(logs.keys())\n",
    "    # print(\"Start epoch {} of training; got log keys: {}\".format(epoch, keys))\n",
    "\n",
    "  def on_epoch_end(self, epoch, logs=None):\n",
    "    self.saveTheModel(-1, logs)\n",
    "\n",
    "  def on_train_batch_end(self, batch, logs=None):\n",
    "    self.saveTheModel(batch, logs)\n",
    "\n",
    "  def saveTheModel(self, batch, logs=None):\n",
    "    if (0 < batch and 0 == batch % self.save_freq) or (0 > batch):\n",
    "      logging.info(str(datetime.datetime.utcnow()))\n",
    "    \n",
    "      if 0 > batch:\n",
    "        _save_folder = os.path.join(self.checkpoint_path,\n",
    "                                    self.model_name,\n",
    "                                    \"cp_daily_valid_{:02d}_end\".format(self.current_epoch)\n",
    "                                    )\n",
    "      else:\n",
    "        _save_folder = os.path.join(self.checkpoint_path,\n",
    "                                    self.model_name,\n",
    "                                    \"cp_daily_valid_{:02d}_{:05d}\".format(self.current_epoch, batch)\n",
    "                                    )\n",
    "      \n",
    "      fp = os.path.join(_save_folder, \"model.h5\")\n",
    "      model.save(fp)\n",
    "      logging.info(f\"Saved model to '{fp}'\")\n",
    "      \n",
    "      # Save optimizer config\n",
    "      # c = copy.deepcopy(self.model.optimizer.get_config())\n",
    "\n",
    "      fp = os.path.join(_save_folder, \"c.pickle\")\n",
    "      with file_io.FileIO(fp, mode='wb+') as handle:\n",
    "        pickle.dump(self.model.optimizer.get_config(), handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "        \n",
    "      logging.info(f\"Saved optimizer config to '{fp}'\")\n",
    "\n",
    "      # Save optimizer weights\n",
    "      # w = copy.deepcopy(self.model.optimizer.get_weights())\n",
    "\n",
    "      fp = os.path.join(_save_folder, \"w.pickle\")\n",
    "      with open(fp, \"wb\") as handle:\n",
    "        # with file_io.FileIO(fp, mode='wb+') as handle:\n",
    "        pickle.dump(self.model.optimizer.get_weights(), handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "      \n",
    "      logging.info(f\"Saved optimizer weights to '{fp}'\")\n",
    "        \n",
    "      logging.info(f\"Did a gc collect: {gc.collect()}\")\n",
    "\n",
    "    # if 0 < batch and 0 == batch % self.val_freq:\n",
    "    #   print(\"-------------------------EVAL-------------------------\")\n",
    "    #   model.evaluate(tfgenTest)\n",
    "    #   print(\"\\n-------------------------EVAL-------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9665"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "TczoGFYOStmg"
   },
   "outputs": [],
   "source": [
    "# CLASS_WEIGHTS_DICT = None\n",
    "# CLASS_WEIGHTS_DICT = {}\n",
    "\n",
    "# for i, cw in enumerate(CLASS_WEIGHTS[0,0,:]):\n",
    "#   CLASS_WEIGHTS_DICT[i] = cw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "id": "JyggHiDGNTEX"
   },
   "outputs": [],
   "source": [
    "epoch_add = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "-pJ08IBN7cgB"
   },
   "outputs": [],
   "source": [
    "CALLBACK_EVERY_N_BATCHES = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "id": "CuGT0rFvzH1n"
   },
   "outputs": [],
   "source": [
    "cc = CustomCallback(checkpoint_path = CHECKPOINT_PATH,\n",
    "                    model_name = CHKPNT_NAME,\n",
    "                    save_freq = CALLBACK_EVERY_N_BATCHES,\n",
    "                    val_freq = CALLBACK_EVERY_N_BATCHES,\n",
    "                    epoch_add = epoch_add)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "LuuH0xBKGE1g",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "0noHN-UeSCQ-"
   },
   "outputs": [],
   "source": [
    "%reload_ext tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u7xAyqce3qYJ"
   },
   "source": [
    "The TensorBoard UI is displayed in a browser window. In this colab, perform the following steps to prepare to capture profile information.\n",
    "1.  Click on the dropdown menu box on the top right side and scroll down and click PROFILE. A new window appears that shows: **No profile data was found** at the top.\n",
    "1.  Click on the CAPTURE PROFILE button. A new dialog appears. The top input line shows: **Profile Service URL or TPU name**. Copy and paste the Profile Service URL (the service_addr value shown before launching TensorBoard) into the top input line. While still on the dialog box, start the training with the next step.\n",
    "1.  Click on the next colab cell to start training the model.\n",
    "1.  Watch the output from the training until several epochs have completed. This allows time for the profile data to start being collected. Return to the dialog box and click on the CAPTURE button. If the capture succeeds, the page will auto refresh and redirect you to the profiling results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "mpUXurxwSp_3",
    "outputId": "8d57d014-c4bc-49e1-a434-179a5be0529c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/content/bigdata/log/FPNWithAttention_1_ETF_Trained_GPU_64LB20230303-205333'"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Todo: Create more elegant solution\n",
    "log_dir = \"gs://ticks_with_indicators_with_volume/logs/TPU/\" + CHKPNT_NAME + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "if not COLAB:\n",
    "    log_dir = os.path.join(\"/content/bigdata/log\",log_dir.split(\"/\")[-1])\n",
    "\n",
    "log_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "_X-ab7uc3gTt"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-03 10:13:32.894701: I tensorflow/core/profiler/lib/profiler_session.cc:101] Profiler session initializing.\n",
      "2023-03-03 10:13:32.894723: I tensorflow/core/profiler/lib/profiler_session.cc:116] Profiler session started.\n",
      "2023-03-03 10:13:32.894769: I tensorflow/core/profiler/backends/gpu/cupti_tracer.cc:1664] Profiler found 1 GPUs\n",
      "2023-03-03 10:13:32.894987: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcupti.so.11.2'; dlerror: libcupti.so.11.2: cannot open shared object file: No such file or directory\n",
      "2023-03-03 10:13:33.030139: I tensorflow/core/profiler/lib/profiler_session.cc:128] Profiler session tear down.\n",
      "2023-03-03 10:13:33.030255: I tensorflow/core/profiler/backends/gpu/cupti_tracer.cc:1798] CUPTI activity buffer flushed\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(\n",
    "    log_dir=log_dir,\n",
    "    histogram_freq=1,\n",
    "    update_freq=CALLBACK_EVERY_N_BATCHES,\n",
    "    profile_batch=(5,100)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# CLASS_WEIGHTS_DICT = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.load_weights(\"/content/bigdata/chk/FPNWithFScaledInput_4_ETF_Trained_GPU_64LB/cp_daily_valid_03_04000/model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-338c7dec9137de4b\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-338c7dec9137de4b\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir $log_dir --host 0.0.0.0 --port 6006"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.optimizer.learning_rate = 1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=1e-04>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.optimizer.learning_rate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DcUTfAbHb2FW",
    "outputId": "a6b2d3a2-f00f-4733-fd4b-268b42e7f2a6",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:File 'LU1834983477.csv' loaded, 1063 left\n",
      "INFO:root:File 'IE00BDGV0415.csv' loaded, 1062 left\n",
      "INFO:root:File 'IE00BM8QRZ79.csv' loaded, 1061 left\n",
      "INFO:root:File 'IE00B0M62S72.csv' loaded, 1060 left\n",
      "INFO:root:File 'IE00BKY58G26.csv' loaded, 1059 left\n",
      "INFO:root:File 'IE00B9KNR336.csv' loaded, 1058 left\n",
      "INFO:root:File 'DE0006289465.csv' loaded, 1057 left\n",
      "INFO:root:File 'IE00BKX55Q28.csv' loaded, 1056 left\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      4/Unknown - 5s 540ms/step - loss: 0.0734 - mae: 0.1659"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-03 20:54:12.156816: I tensorflow/core/profiler/lib/profiler_session.cc:101] Profiler session initializing.\n",
      "2023-03-03 20:54:12.156841: I tensorflow/core/profiler/lib/profiler_session.cc:116] Profiler session started.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      6/Unknown - 7s 560ms/step - loss: 0.0766 - mae: 0.1686WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.2123s vs `on_train_batch_end` time: 0.3483s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.2123s vs `on_train_batch_end` time: 0.3483s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      7/Unknown - 7s 554ms/step - loss: 0.0766 - mae: 0.1678"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:File 'IE00BD3V0B10.csv' loaded, 1055 left\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     13/Unknown - 11s 572ms/step - loss: 0.0778 - mae: 0.1695"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:File 'IE00BKWQ0H23.csv' loaded, 1054 left\n"
     ]
    }
   ],
   "source": [
    "model.fit(tfGenTraining,\n",
    "          epochs=200,\n",
    "          verbose = 1,\n",
    "          callbacks=[tensorboard_callback, cc])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LR 0.0005\n",
    "\n",
    "INFO:root:2023-03-03 20:49:47.938271\n",
    "INFO:root:Saved model to '/content/bigdata/chk/FPNWithAttention_1_ETF_Trained_GPU_64LB/cp_daily_valid_09_end/model.h5'\n",
    "INFO:root:Saved optimizer config to '/content/bigdata/chk/FPNWithAttention_1_ETF_Trained_GPU_64LB/cp_daily_valid_09_end/c.pickle'\n",
    "INFO:root:Saved optimizer weights to '/content/bigdata/chk/FPNWithAttention_1_ETF_Trained_GPU_64LB/cp_daily_valid_09_end/w.pickle'\n",
    "INFO:root:Did a gc collect: 0\n",
    "\n",
    "6261/6261 [==============================] - 3817s 609ms/step - loss: 0.0631 - mae: 0.1488\n",
    "Epoch 11/200\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2Nh12BlMEOBF",
    "outputId": "8bb69110-e6ee-48e6-e62b-1547db0c5ee4"
   },
   "outputs": [],
   "source": [
    "# copy_filenames = ['gs://crypto_nlp_training/chk/RobertaMLMTraining_1_GPU_512LB_10000VC_MaskedPrediction/cp_daily_valid_01_06000/model.h5'\n",
    "#                   ]\n",
    "\n",
    "# for p in copy_filenames:\n",
    "#   fn = p.split(\"/\")[-1]\n",
    "#   cpnt = p.split(\"/\")[-2]\n",
    "\n",
    "#   os.mkdir(os.path.join(\"/content\", cpnt))\n",
    "\n",
    "#   localPath = os.path.join(\"/content\", cpnt, fn)\n",
    "\n",
    "#   if (\"model.h5\" in p):\n",
    "#     localPathModel = localPath\n",
    "#   elif (\"w.pickle\" in p):\n",
    "#     localPathW = localPath\n",
    "\n",
    "#   with file_io.FileIO(p, mode='rb') as input_f:\n",
    "#     with file_io.FileIO(localPath, mode='wb+') as output_f:\n",
    "#       output_f.write(input_f.read())\n",
    "#       print(\"Pulled from bucket: '\" + fn + \"'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nYu7qfd3IsMu",
    "outputId": "d24bd442-2144-459f-eec5-0437fdd2cde3"
   },
   "outputs": [],
   "source": [
    "# print(f\"Loading {localPathModel}\")\n",
    "# model.load_weights(localPathModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HRuwJfh2l7nS"
   },
   "outputs": [],
   "source": [
    "# model.load_weights(\"/content/model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3HLXTKPAfZ04"
   },
   "outputs": [],
   "source": [
    "# modelOld = CreateModelRobertaMLMTrainingDropout()\n",
    "# modelOld.load_weights(\"/content/cp_daily_valid_49_end/model.h5\")\n",
    "# modelOld.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NWKr6ROif078"
   },
   "outputs": [],
   "source": [
    "# model.get_layer(\"Roberta\").set_weights(modelOld.get_layer(\"Roberta\").get_weights())\n",
    "# model.get_layer(\"Categories\").set_weights(modelOld.get_layer(\"Categories\").get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_mV2OpQAGDja"
   },
   "outputs": [],
   "source": [
    "# with open(\"/content/w.pickle\", 'rb') as pickle_file:\n",
    "#   w = pickle.load(pickle_file)\n",
    "# model.optimizer.set_weights(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kXHVjhsDHHF9"
   },
   "outputs": [],
   "source": [
    "# model.optimizer.learning_rate = 5e-2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HyBFN04Q-qcU"
   },
   "source": [
    "LR 5e-4  5000/Unknown - 5576s 1s/step - loss: 296.81093730\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zvFil-4dStzq"
   },
   "source": [
    "# Full sentence as y\n",
    "20000/Unknown - 21155s 1s/step - loss: 0.9579\n",
    "Saved model to: 'gs://crypto_nlp_training/chk/RobertaMLMTraining_1_GPU_512LB_10000VC_FullPrediction/cp_daily_valid_00_20000/model.h5'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5le0oPyfbE79"
   },
   "source": [
    "# Masked sentence as y, LR 5e-4, Random state 11\n",
    "14000/Unknown - 15387s 1s/step - loss: 5.3956\n",
    "Saved model to: 'gs://crypto_nlp_training/chk/RobertaMLMTraining_1_GPU_512LB_10000VC_MaskedPrediction/cp_daily_valid_00_14000/model.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RLmWNTDIUpt6"
   },
   "outputs": [],
   "source": [
    "# A python generator function has to be applied on the dataStream\n",
    "\n",
    "def pythonGeneratorEval():\n",
    "  # Initialize the FileListToDataStream generator\n",
    "  dataStreamEval= DataStreamCreator.FileListToDataStream(fileList = [TRAIN_FILES[1]],\n",
    "                                                      batch_size = BATCH_SIZE,\n",
    "                                                      X_Block_lenght = X_BLOCK_LENGHT,\n",
    "                                                      y_type_dict=Y_TYPE_DICT,\n",
    "                                                      shuffle=False,\n",
    "                                                      parallel_generators = 1,\n",
    "                                                      random_seed = RANDOM_SEED,\n",
    "                                                      **DATA_STREAM_PARAMETERS\n",
    "                                                      )\n",
    "  \n",
    "  # This while has to integrated into the FileListToDataStream method\n",
    "  while True:  \n",
    "    try:\n",
    "      ne = next(dataStreamEval)\n",
    "      _X = ne['X']\n",
    "      _y = ne['y']\n",
    "    \n",
    "      # 'Blow up' the X array to a 2**n size\n",
    "      _X_new = np.zeros((_X.shape[0], _X.shape[1], TARGET_FEATURE_CNT))\n",
    "      _X_new[:,:,:_X.shape[2]] = _X\n",
    "\n",
    "      yield (_X_new, _y)\n",
    "    except StopIteration as si:\n",
    "      logging.warning(\"StopIteration in pythonGenerator\")\n",
    "      logging.warning(si)\n",
    "      return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iUSw95cqUuE_"
   },
   "outputs": [],
   "source": [
    "# Create a Tensorflow dataset out of the python generator, which can be fed to the network\n",
    "tfGenEval = tf.data.Dataset.from_generator(pythonGeneratorEval, \n",
    "                                               output_types = (tf.float32, tf.float32),\n",
    "                                               output_shapes=(\n",
    "                                                   (BATCH_SIZE, X_BLOCK_LENGHT, TARGET_FEATURE_CNT),\n",
    "                                                   (BATCH_SIZE, 2)\n",
    "                                                   )\n",
    "                                               )\n",
    "tfGenEval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qI3WKmspUe2Z",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# it = tfGenEval.as_numpy_iterator()\n",
    "# ne = next(it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ktuZ3D04UzeE"
   },
   "outputs": [],
   "source": [
    "p = model.predict(tfGenEval)\n",
    "p.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vgzPCL7KVXC1"
   },
   "outputs": [],
   "source": [
    "plt.plot(p[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.plot(p[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "p.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tickDF = pd.read_csv(TRAIN_FILES[1])\n",
    "tickDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tickDF.shape[0] - p.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tickDFcropped = tickDF.iloc[-p.shape[0]:, :]\n",
    "tickDFcropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "p_dir = p[:,0]\n",
    "p_dir_derivation = p[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot the prediction again, now over the open price\n",
    "chart_name=\"Predicted direction of price movement with open price\"\n",
    "fig, ax1 = plt.subplots(figsize=(20,10))\n",
    "ax1.set_title(chart_name, fontsize=14)\n",
    "\n",
    "_ = ax1.plot(p_dir, color=\"blue\", label=\"Predicted y direction\")\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "\n",
    "ax2.plot(tickDFcropped.loc[:,'open'].values, color=\"black\", label=\"Price\")\n",
    "\n",
    "ax1.set_xlabel(\"Timesteps\")\n",
    "ax1.set_ylabel(\"Direction\")\n",
    "ax2.set_ylabel(\"Price\")\n",
    "\n",
    "# Show a legend\n",
    "lines, labels = ax1.get_legend_handles_labels()\n",
    "lines2, labels2 = ax2.get_legend_handles_labels()\n",
    "ax2.legend(lines + lines2, labels + labels2, loc=\"upper left\")\n",
    "\n",
    "# Save the figure\n",
    "# fig_name = \"FileListToDataStreamExample_\" + chart_name.replace(\" \", \"_\").replace(\"'\", \"\").replace(\"(\", \"\").replace(\")\", \"\") + \".svg\"\n",
    "# plt.savefig(os.path.join(IMG_SAVE_PATH, fig_name), bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot the prediction again, now over the open price\n",
    "chart_name=\"Predicted direction derv of price movement with open price\"\n",
    "fig, ax1 = plt.subplots(figsize=(20,10))\n",
    "ax1.set_title(chart_name, fontsize=14)\n",
    "\n",
    "_ = ax1.plot(p_dir_derivation, color=\"red\", label=\"Predicted y direction derv\")\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "\n",
    "ax2.plot(tickDFcropped.loc[:,'open'].values, color=\"black\", label=\"Price\")\n",
    "\n",
    "ax1.set_xlabel(\"Timesteps\")\n",
    "ax1.set_ylabel(\"Direction\")\n",
    "ax2.set_ylabel(\"Price\")\n",
    "\n",
    "# Show a legend\n",
    "lines, labels = ax1.get_legend_handles_labels()\n",
    "lines2, labels2 = ax2.get_legend_handles_labels()\n",
    "ax2.legend(lines + lines2, labels + labels2, loc=\"upper left\")\n",
    "\n",
    "# Save the figure\n",
    "# fig_name = \"FileListToDataStreamExample_\" + chart_name.replace(\" \", \"_\").replace(\"'\", \"\").replace(\"(\", \"\").replace(\")\", \"\") + \".svg\"\n",
    "# plt.savefig(os.path.join(IMG_SAVE_PATH, fig_name), bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#@title Buy and sell signal thresholds\n",
    "BUY_SIGNAL_THRESHOLD_DIR = 0.0 #@param {type:\"number\"}\n",
    "BUY_SIGNAL_THRESHOLD_DIR_DER = -0.02 #@param {type:\"number\"}\n",
    "\n",
    "SELL_SIGNAL_THRESHOLD_DIR = 0.25 #@param {type:\"number\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#@title Plot buy and sell signals\n",
    "chart_name=\"Buy and sell signals\"\n",
    "fig, ax1 = plt.subplots(figsize=(20,10))\n",
    "ax1.set_title(chart_name)\n",
    "\n",
    "x_datetimes = [datetime.datetime.fromtimestamp(ts) for ts in tickDFcropped.loc[:,'open'].index]\n",
    "\n",
    "_ = ax1.plot(x_datetimes, tickDFcropped.loc[:,'open'].values, color=\"black\", label=\"Price\", linewidth=2)\n",
    "\n",
    "# Color area axis\n",
    "ax2 = ax1.twinx()\n",
    "\n",
    "# Convert the float value prediction into rising and falling categories\n",
    "yCategoryFall = p_dir > SELL_SIGNAL_THRESHOLD_DIR\n",
    "yCategoryRise = (p_dir < BUY_SIGNAL_THRESHOLD_DIR) & (p_dir_derivation > BUY_SIGNAL_THRESHOLD_DIR_DER)\n",
    "\n",
    "ax2.fill_between(x_datetimes, yCategoryFall , alpha=0.5, color=\"red\", label=\"'Buy' signal\")\n",
    "ax2.fill_between(x_datetimes, yCategoryRise , alpha=0.5, color=\"green\", label=\"'Sell' signal\")\n",
    "\n",
    "# Remove tick marks and set limits for color area axis\n",
    "ax2.set_yticks([])\n",
    "ax2.set_ylim(-0.05,1.05)\n",
    "\n",
    "ax3 = ax1.twinx()\n",
    "_ = ax3.plot(x_datetimes, p_dir, color=\"blue\", label=\"Predicted price direction\")\n",
    "# _ = ax3.plot(x_datetimes, 10.0*p_dir_derivation, color=\"red\", label=\"10.0 * Predicted price direction derivation\")\n",
    "# ax3.set_ylim(-1.05,1.05)\n",
    "\n",
    "ax3.plot([np.min(x_datetimes), np.max(x_datetimes)], [0.0,0.0], color=\"gray\")\n",
    "\n",
    "# Show a legend\n",
    "lines, labels = ax1.get_legend_handles_labels()\n",
    "lines2, labels2 = ax2.get_legend_handles_labels()\n",
    "lines3, labels3 = ax3.get_legend_handles_labels()\n",
    "ax2.legend(lines + lines2 + lines3, labels + labels2 + labels3, loc=\"upper left\")\n",
    "\n",
    "# Save the figure\n",
    "# fig_name = chart_name.replace(\" \", \"_\").replace(\"'\", \"\") + \".svg\"\n",
    "# plt.savefig(os.path.join(IMG_SAVE_PATH, fig_name), bbox_inches=\"tight\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
