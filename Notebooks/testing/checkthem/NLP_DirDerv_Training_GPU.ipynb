{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RIbOPenP-I_d"
   },
   "source": [
    "# Mount drive and bucket\n",
    "Todo: Remove in public version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "GHybPwDjX1gZ",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Check if the notebook is run in Google Colab\n",
    "import sys\n",
    "\n",
    "COLAB = 'google.colab' in sys.modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_io.TextIOWrapper name='/content/bigdata/nb_20230219_1820.log' mode='a+' encoding='UTF-8'>\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(60000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 60 seconds\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import datetime\n",
    "import logging\n",
    "\n",
    "nblog = open(f\"/content/bigdata/nb_{datetime.datetime.utcnow().strftime('%Y%m%d_%H%M')}.log\", \"a+\")\n",
    "print(nblog)\n",
    "sys.stdout.echo = nblog\n",
    "sys.stderr.echo = nblog\n",
    "\n",
    "#get_ipython().log.handlers[0].stream = nblog\n",
    "#get_ipython().log.setLevel(logging.INFO)\n",
    "\n",
    "%autosave 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sK6Uuoy5qsua",
    "outputId": "d29d48f5-a2e5-40f9-927d-002d32fd48f9"
   },
   "outputs": [],
   "source": [
    "# if COLAB:\n",
    "#   from google.colab import drive\n",
    "#   drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "MTJ7bYMtHmvS"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run the command!\n"
     ]
    }
   ],
   "source": [
    "if COLAB:\n",
    "  from google.colab import auth\n",
    "  auth.authenticate_user()\n",
    "else:\n",
    "    print(\"Run the command!\")\n",
    "  #Todo #bring the command inside the notebook\n",
    "  #run this terminal inside docker: gcloud auth login b.girsule@gmail.com --no-launch-browser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "DOScyXpJws23"
   },
   "outputs": [],
   "source": [
    "# Todo: Check if possible in local docker\n",
    "# from google.cloud import storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "t9dbL-PU-okV",
    "outputId": "14e73bf6-881d-4bc0-96f4-8a1b79cae570"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-19 18:20:30.385672: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-19 18:20:30.776085: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-02-19 18:20:31.681427: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-19 18:20:31.681578: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-19 18:20:31.681590: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF Version is 2.10.0, ok!\n"
     ]
    }
   ],
   "source": [
    "# Check if the tf version is 2.10.0, this is required to use the 'ignore_class' in the  SparseCategoricalCrossentropy\n",
    "import tensorflow as tf\n",
    "\n",
    "if '2.10.0' != tf.__version__:\n",
    "  !pip uninstall tensorflow -y\n",
    "  !pip install tensorflow-gpu==2.10.0\n",
    "  please_restart_the_runtime\n",
    "else:\n",
    "  print(\"TF Version is 2.10.0, ok!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "FYePtDVpqtkN"
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "# import tensorflow_gcs_config\n",
    "from tensorflow.python.lib.io import file_io\n",
    "\n",
    "from keras.layers import Input, Dense #, ReLU, Add, Flatten, Concatenate, LayerNormalization, UpSampling2D, Activation, LSTM, Multiply, Dropout, Reshape, Permute, BatchNormalization, MaxPooling1D, AveragePooling1D, MaxPooling3D, AveragePooling2D, LayerNormalization, MaxPooling2D\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "pxa3Ug_JplIq"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "EcBnUrFKqyCK"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "R_3vswfeRqmj"
   },
   "outputs": [],
   "source": [
    "# Set the google cloud bucket data\n",
    "project_id = 'tweetprediction'\n",
    "bucket_name = 'crypto_nlp_training'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "X3s3eDubSFaJ",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set the checkpoint path for saving train progress\n",
    "if COLAB:\n",
    "    CHECKPOINT_PATH = f\"gs://{bucket_name}/chk/\"\n",
    "else:\n",
    "    CHECKPOINT_PATH = f\"/content/bigdata/chk/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8rvlsLwbpmWJ",
    "outputId": "12f0ff94-d55c-449f-f101-c4581499db7d"
   },
   "outputs": [],
   "source": [
    "# Check if the notebook is run in google colab, if so, clone the repo\n",
    "if COLAB:\n",
    "    print(\"Running in Colab\")\n",
    "\n",
    "    # Clone the whole repo to get all data and code if not already done\n",
    "    if not os.path.exists(\"/content/CryptoCrystalBall\"):\n",
    "      !git clone https://github.com/girsigit/CryptoCrystalBall\n",
    "\n",
    "      # cd into the notebooks directory --> Necessary to match all paths for importing\n",
    "    #%cd /content/CryptoCrystalBall/JupyterDocker/notebooks\n",
    "    %cd /content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "q9OmJ6vFthwG"
   },
   "outputs": [],
   "source": [
    "# Try importing the Ta-Lib library, if this fails, try to install it and\n",
    "# import it again afterwards\n",
    "try:\n",
    "    import talib\n",
    "except:\n",
    "    !wget http://prdownloads.sourceforge.net/ta-lib/ta-lib-0.4.0-src.tar.gz\n",
    "    !tar -xzvf ta-lib-0.4.0-src.tar.gz\n",
    "    %cd ta-lib\n",
    "    !./configure --prefix=/usr\n",
    "    !make\n",
    "    !make install\n",
    "    !pip install Ta-Lib\n",
    "    %cd ..\n",
    "\n",
    "    import talib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "2orTUN099zyA",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moving 0 files to the new cache system\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f65647d1f3dc4c29ab49dd07b957d7fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "try:\n",
    "  from transformers import TFRobertaModel, RobertaConfig\n",
    "except:\n",
    "  # Important!: Version 4.23 does not work on TPU\n",
    "  !pip install transformers==4.22\n",
    "\n",
    "  from transformers import TFRobertaModel, RobertaConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip uninstall -y tensorboard-plugin-profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qfAsp4TWHivL",
    "outputId": "a25fdba4-ad57-40a3-f725-7d4ed114d38b",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Required to do profiling\n",
    "# !pip install tensorboard-plugin-profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "axPYAbN9upgY",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nbt7oQxzL2Zy"
   },
   "source": [
    "---\n",
    "# Add custom import path for DataStreamCreator and IndicatorCalculator\n",
    "\n",
    "These libs are not in the standard python directory, so their paths have to be added to the import paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ICDL0OwbL2Zz",
    "outputId": "41c7541e-3a1e-4035-f2f3-182fed452a8e",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['', 'content']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Get the current directory\n",
    "# current_dir = os.getcwd()\n",
    "# current_dir_splitted = current_dir.split(os.sep)\n",
    "\n",
    "# Todo: is inside /content/CB in local docker\n",
    "current_dir_splitted = [\"\", \"content\"]\n",
    "current_dir_splitted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JJ8l6O2gL2Z1",
    "outputId": "de6d884a-f4be-47e2-c808-eeac3448580c",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dsc_dir: /content/CryptoCrystalBall/DataStreamCreator\n",
      "ind_dir: /content/CryptoCrystalBall/IndicatorCalculator\n"
     ]
    }
   ],
   "source": [
    "# Create the import directories for the DataStreamCreator and the IndicatorCalculator\n",
    "dsc_dir = '/content/CryptoCrystalBall/DataStreamCreator'\n",
    "print(f\"dsc_dir: {dsc_dir}\")\n",
    "\n",
    "ind_dir = '/content/CryptoCrystalBall/IndicatorCalculator'\n",
    "print(f\"ind_dir: {ind_dir}\")\n",
    "\n",
    "# Add them to the import paths\n",
    "sys.path.insert(0, dsc_dir)\n",
    "sys.path.insert(0, ind_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "iqyTbcZDttLT",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import the actual classes\n",
    "from IndicatorCalculator import IndicatorCalculator\n",
    "import DataStreamCreator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zPsG4dqRL2Z5"
   },
   "source": [
    "---\n",
    "# Define all the parameters and variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5J8ODl45L2Z6",
    "outputId": "690c2801-687e-47fe-cefc-616e029a62a5",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA_PATH: /content/DemoData\n"
     ]
    }
   ],
   "source": [
    "# Define the tick data path\n",
    "DATA_PATH = os.path.join(os.sep, *current_dir_splitted, 'DemoData')\n",
    "print(f\"DATA_PATH: {DATA_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7TUeLGiOL2Z7",
    "outputId": "00651843-f462-4c20-e6cc-7cb0d7cd6d23",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMG_SAVE_PATH: /content/Documentation/Images\n"
     ]
    }
   ],
   "source": [
    "# Define the chart image save path\n",
    "IMG_SAVE_PATH = os.path.join(os.sep, *current_dir_splitted, 'Documentation', 'Images')\n",
    "print(f\"IMG_SAVE_PATH: {IMG_SAVE_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "o23rkki9ttLZ",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define a global random seed\n",
    "RANDOM_SEED = 42+19\n",
    "\n",
    "# Set the seed in np\n",
    "np.random.seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "g9gBeRtnxKMD",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# X_BLOCK_LENGHT defines how far into the past a 'slice of a chart' shall be\n",
    "# See: https://github.com/girsigit/CryptoCrystalBall/tree/main/DataStreamCreator#xblockgenerator\n",
    "X_BLOCK_LENGHT = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "sh5dsBKr5Ko-",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# How many examples shall be processed at the same time, limited by GPU memory\n",
    "BATCH_SIZE = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "J331jHk-u345",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# A fixed number of features is used\n",
    "FEATURES = 160"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "1JVT1Z2U0lW8",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Finanical indicator timespans\n",
    "# See: https://github.com/girsigit/CryptoCrystalBall/tree/main/IndicatorCalculator\n",
    "SHORTSPAN = 6\n",
    "MIDSPAN = 48\n",
    "LONGSPAN = 120"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "AnNz-Oke3J3p",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Additional settings for the data stream\n",
    "# For this notebook, the calculation of pattern indicators is turned off\n",
    "DATA_STREAM_PARAMETERS = {\n",
    "    \"calcPatternIndicators\": False, # No patterns are used\n",
    "    \"calcVolumeInidators\": False, # No volume indicators, these are wide spread and may disturb the classifer\n",
    "    \"dropna\": True # Drop all tick/indicator table rows containing nan values instead of just replacing them by 0 (which would lead to wrong predictions)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "GKkv21lAxYEP",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# NLP token configuration\n",
    "BOS_TOKEN_ID = 0\n",
    "PAD_TOKEN_ID = 1\n",
    "EOS_TOKEN_ID = 2\n",
    "MASK_TOKEN_ID = 3\n",
    "\n",
    "MLM_MASK_FACTOR = 0.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "V5P8Nbn7F5CS",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Vocab size configuration\n",
    "# The feature vector to integer classifier model has a 5 digit output, therefore the vocab size would be 100000\n",
    "# As this is too much, the categories are rounded --> Todo: Create better classifier model\n",
    "\n",
    "VOCAB_SIZE = 10000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7xXpDFe9ROVQ"
   },
   "source": [
    "# Load the train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "b2EO18ZmppNe",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Check if the dataset already has been copy, if not, copy it\n",
    "if not os.path.exists(\"/content/dataset\") or not os.path.exists(\"/content/dataset/Train\"):\n",
    "  !mkdir /content/dataset\n",
    "  !mkdir /content/dataset/Train\n",
    "  !gsutil -m cp -r gs://cryptocrystalball_public/CryptoDataset/Hourly/significant_currencies.txt /content/dataset/significant_currencies.txt\n",
    "  !gsutil -m cp -r gs://cryptocrystalball_public/CryptoDataset/Hourly/Train/* /content/dataset/Train/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2sRVckzNtbZL",
    "outputId": "5cfd2c06-7823-40b3-eea8-2dbc3f51df57",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 121 significant files names.\n"
     ]
    }
   ],
   "source": [
    "#@markdown ### Use only significant currencies\n",
    "#@markdown Load a manually defined list of significant currencies (`significant_currencies.txt`).\n",
    "#@markdown This list contains no currencies which little or no volume or price movement, to\n",
    "#@markdown avoid training on data sample which would never be used to trade on in a real \n",
    "#@markdown application.\n",
    "\n",
    "#@markdown If enabled, only currency pairs with the base currency USDT are laoded,\n",
    "#@markdown this is important to prevent interference between different cryptocurrencies.\n",
    "#@markdown For example, in `BTC-ETH.csv`, there is influence of both the BTC and the ETH price, but we want to predict trade signals based on a 'real' currency (USDT is kind of the same as USD).\n",
    "\n",
    "significant_only = True #@param {type:\"boolean\"}\n",
    "\n",
    "if significant_only:\n",
    "  with open(\"/content/dataset/significant_currencies.txt\") as f:\n",
    "    SIGNIFICANT_CURRS = f.read().splitlines()\n",
    "\n",
    "  print(f\"Loaded {len(SIGNIFICANT_CURRS)} significant files names.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dlNAUwUTtdBE",
    "outputId": "3c614762-758a-444f-dc86-e86527a6c0ca",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The train dataset contains 121 files.\n",
      "['/content/dataset/Train/1INCH-USDT.csv', '/content/dataset/Train/4ART-USDT.csv', '/content/dataset/Train/AAVE-USDT.csv']\n"
     ]
    }
   ],
   "source": [
    "# Get train file names - Only pick the ones ending with -USDT to prevent\n",
    "# influence between different currencies\n",
    "TRAIN_PATH = \"/content/dataset/Train\"\n",
    "\n",
    "# Get all file names\n",
    "TRAIN_FILES = [os.path.join(TRAIN_PATH,f) for f in listdir(TRAIN_PATH) if isfile(join(TRAIN_PATH, f)) and \".csv\" in f ]\n",
    "\n",
    "# Filter for significant currencies only\n",
    "if significant_only:\n",
    "  TRAIN_FILES = [f for f in TRAIN_FILES if f.split(\"/\")[-1].replace(\".csv\",\"\") in SIGNIFICANT_CURRS]\n",
    "\n",
    "# Filter for USDT-based ones only\n",
    "TRAIN_FILES = [f for f in TRAIN_FILES if \"-USDT\" in f]\n",
    "\n",
    "# Sort them (as a stable basis for randomizing afterwards)\n",
    "TRAIN_FILES = sorted(TRAIN_FILES)\n",
    "\n",
    "print(f\"The train dataset contains {len(TRAIN_FILES)} files.\")\n",
    "print(TRAIN_FILES[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jhiJj_nfsmU0"
   },
   "source": [
    "# Load the classifier model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i8fWOHkSsMpz",
    "outputId": "1f57628e-dd3c-4395-a875-5d33279b4616",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying gs://crypto_nlp_training/four_float_to_int/bottleneckToFourFloatModel.h5...\n",
      "/ [1/1 files][ 92.2 KiB/ 92.2 KiB] 100% Done                                    \n",
      "Operation completed over 1 objects/92.2 KiB.                                     \n",
      "Copying gs://crypto_nlp_training/four_float_to_int/digitLimits.npy...\n",
      "/ [1/1 files][  768.0 B/  768.0 B] 100% Done                                    \n",
      "Operation completed over 1 objects/768.0 B.                                      \n"
     ]
    }
   ],
   "source": [
    "# Copy the feature vector to four float classifier model\n",
    "# Also copy the digit limits\n",
    "if not os.path.exists(\"/content/bottleneckToFourFloatModel.h5\"):\n",
    "  !gsutil -m cp -r gs://crypto_nlp_training/four_float_to_int/bottleneckToFourFloatModel.h5 /content/bottleneckToFourFloatModel.h5\n",
    "  !gsutil -m cp -r gs://crypto_nlp_training/four_float_to_int/digitLimits.npy /content/digitLimits.npy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3daDKjTltDTH",
    "outputId": "aee227b2-d87a-4651-bf6f-14d73592e862",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "Model: \"NNClassifierBottleneckToFourFloat\"\n",
      "____________________________________________________________________________________________________________________________________________________________________________________________________________________________\n",
      " Layer (type)                                                                                      Output Shape                                                                            Param #                          \n",
      "============================================================================================================================================================================================================================\n",
      " inputTicksAndIndicators (InputLayer)                                                              [(None, 512, 160)]                                                                      0                                \n",
      "                                                                                                                                                                                                                            \n",
      " tf.expand_dims_1 (TFOpLambda)                                                                     (None, 512, 160, 1)                                                                     0                                \n",
      "                                                                                                                                                                                                                            \n",
      " permute_1 (Permute)                                                                               (None, 512, 1, 160)                                                                     0                                \n",
      "                                                                                                                                                                                                                            \n",
      " DepthwiseConv2DInput (DepthwiseConv2D)                                                            (None, 512, 1, 160)                                                                     160                              \n",
      "                                                                                                                                                                                                                            \n",
      " tf.compat.v1.squeeze_1 (TFOpLambda)                                                               (None, 512, 160)                                                                        0                                \n",
      "                                                                                                                                                                                                                            \n",
      " Tanh_Input (Activation)                                                                           (None, 512, 160)                                                                        0                                \n",
      "                                                                                                                                                                                                                            \n",
      " tf.clip_by_value_1 (TFOpLambda)                                                                   (None, 512, 160)                                                                        0                                \n",
      "                                                                                                                                                                                                                            \n",
      " Bottleneck_1 (Dense)                                                                              (None, 512, 80)                                                                         12880                            \n",
      "                                                                                                                                                                                                                            \n",
      " Bottleneck_2 (Dense)                                                                              (None, 512, 40)                                                                         3240                             \n",
      "                                                                                                                                                                                                                            \n",
      " Bottleneck_3 (Dense)                                                                              (None, 512, 4)                                                                          164                              \n",
      "                                                                                                                                                                                                                            \n",
      "============================================================================================================================================================================================================================\n",
      "Total params: 16,444\n",
      "Trainable params: 16,444\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________________________________________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-19 18:20:38.936588: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-19 18:20:38.994718: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-19 18:20:38.994905: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-19 18:20:38.996622: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-19 18:20:38.997866: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-19 18:20:38.998039: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-19 18:20:38.998183: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-19 18:20:39.725918: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-19 18:20:39.726335: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-19 18:20:39.726483: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-19 18:20:39.726599: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 7386 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1070, pci bus id: 0000:01:00.0, compute capability: 6.1\n"
     ]
    }
   ],
   "source": [
    "# Load the model\n",
    "with tf.device('/CPU:0'):\n",
    "    fourFloatClassifierModel = keras.models.load_model(\"/content/bottleneckToFourFloatModel.h5\")\n",
    "    fourFloatClassifierModel.summary(line_length=220)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "2nLWLP3AB3gG",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load the digit limits\n",
    "digitLimits = np.load(\"/content/digitLimits.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0BeeQ7hvhXJF"
   },
   "source": [
    "# Load the class weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true,
    "id": "05AAfFUyhZdg",
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying gs://crypto_nlp_training/four_float_to_int/class_weights.npy...\n",
      "/ [1/1 files][ 78.2 KiB/ 78.2 KiB] 100% Done                                    \n",
      "Operation completed over 1 objects/78.2 KiB.                                     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{0: 1.0,\n",
       " 1: 1.0,\n",
       " 2: 1.0,\n",
       " 3: 1.0,\n",
       " 4: 1.0,\n",
       " 5: 1.0,\n",
       " 6: 1.0,\n",
       " 7: 1.0,\n",
       " 8: 1.0,\n",
       " 9: 1.0,\n",
       " 10: 1.0,\n",
       " 11: 1.0,\n",
       " 12: 1.0,\n",
       " 13: 1.0,\n",
       " 14: 1.5366002344665886,\n",
       " 15: 3.810232558139535,\n",
       " 16: 2.932259507829978,\n",
       " 17: 1.486077097505669,\n",
       " 18: 1.4777001127395717,\n",
       " 19: 1.0,\n",
       " 20: 1.0,\n",
       " 21: 1.0,\n",
       " 22: 2.56,\n",
       " 23: 3.098628841607565,\n",
       " 24: 1.1309059534081105,\n",
       " 25: 3.7664367816091953,\n",
       " 26: 1.927529411764706,\n",
       " 27: 0.8222835633626098,\n",
       " 28: 0.8021542227662178,\n",
       " 29: 2.6969547325102883,\n",
       " 30: 1.0,\n",
       " 31: 1.0,\n",
       " 32: 1.6868983268983269,\n",
       " 33: 0.7576416184971099,\n",
       " 34: 1.0561804995970991,\n",
       " 35: 0.71624043715847,\n",
       " 36: 0.584620874219447,\n",
       " 37: 0.8279974731522426,\n",
       " 38: 1.678258642765685,\n",
       " 39: 3.6207734806629834,\n",
       " 40: 5.77409691629956,\n",
       " 41: 4.664483985765124,\n",
       " 42: 0.9651840942562592,\n",
       " 43: 1.0604530744336569,\n",
       " 44: 0.3078252700798497,\n",
       " 45: 0.6488712871287129,\n",
       " 46: 0.2683701883701884,\n",
       " 47: 0.18051508056741494,\n",
       " 48: 1.4246956521739131,\n",
       " 49: 1.0,\n",
       " 50: 1.0,\n",
       " 51: 1.5348009367681499,\n",
       " 52: 1.4108934337997847,\n",
       " 53: 0.8779102478231748,\n",
       " 54: 0.2664606627363285,\n",
       " 55: 0.2194775619557937,\n",
       " 56: 0.2230633083730429,\n",
       " 57: 0.3271892161757364,\n",
       " 58: 0.6639918946301925,\n",
       " 59: 1.0,\n",
       " 60: 1.0,\n",
       " 61: 1.1212318220701454,\n",
       " 62: 1.3512577319587629,\n",
       " 63: 0.5544500846023689,\n",
       " 64: 0.29114171479342515,\n",
       " 65: 0.24322137687882725,\n",
       " 66: 0.531948051948052,\n",
       " 67: 0.3722578812837262,\n",
       " 68: 1.0,\n",
       " 69: 1.0,\n",
       " 70: 1.0,\n",
       " 71: 0.7929340592861464,\n",
       " 72: 0.4925667042465239,\n",
       " 73: 0.43144173798551677,\n",
       " 74: 0.29580681561724215,\n",
       " 75: 0.1401240111182382,\n",
       " 76: 0.27501468736886275,\n",
       " 77: 2.332241992882562,\n",
       " 78: 1.0,\n",
       " 79: 1.0,\n",
       " 80: 1.0005496183206106,\n",
       " 81: 1.2875442043222003,\n",
       " 82: 0.5938921613049388,\n",
       " 83: 0.4646295639844027,\n",
       " 84: 0.3112609831393968,\n",
       " 85: 1.7314663143989433,\n",
       " 86: 1.0,\n",
       " 87: 1.0,\n",
       " 88: 1.0,\n",
       " 89: 1.0,\n",
       " 90: 4.228129032258065,\n",
       " 91: 0.44117132278694043,\n",
       " 92: 0.9198035087719298,\n",
       " 93: 0.7589577301679212,\n",
       " 94: 0.8880216802168022,\n",
       " 95: 6.331980676328502,\n",
       " 96: 1.0,\n",
       " 97: 1.0,\n",
       " 98: 1.0,\n",
       " 99: 1.0,\n",
       " 100: 1.0,\n",
       " 101: 1.0,\n",
       " 102: 7.943757575757576,\n",
       " 103: 1.0,\n",
       " 104: 1.5402115158636898,\n",
       " 105: 2.952072072072072,\n",
       " 106: 1.0,\n",
       " 107: 1.0,\n",
       " 108: 1.0,\n",
       " 109: 1.0,\n",
       " 110: 1.0,\n",
       " 111: 6.6873469387755105,\n",
       " 112: 2.56,\n",
       " 113: 1.3797052631578948,\n",
       " 114: 1.0,\n",
       " 115: 1.0,\n",
       " 116: 1.0,\n",
       " 117: 1.0,\n",
       " 118: 1.0,\n",
       " 119: 2.56,\n",
       " 120: 1.0,\n",
       " 121: 1.6445671267252195,\n",
       " 122: 0.7058266020463112,\n",
       " 123: 1.461226309921962,\n",
       " 124: 1.0,\n",
       " 125: 2.56,\n",
       " 126: 1.0,\n",
       " 127: 3.0200921658986175,\n",
       " 128: 1.2261178671655752,\n",
       " 129: 1.2913497536945813,\n",
       " 130: 1.0,\n",
       " 131: 1.4451157662624035,\n",
       " 132: 0.9089597780859917,\n",
       " 133: 0.9781492537313433,\n",
       " 134: 2.5450873786407766,\n",
       " 135: 1.486077097505669,\n",
       " 136: 0.5092152292152292,\n",
       " 137: 0.9463682310469315,\n",
       " 138: 0.2908832667554372,\n",
       " 139: 1.7808695652173914,\n",
       " 140: 1.0,\n",
       " 141: 0.5371803278688525,\n",
       " 142: 1.021605611847233,\n",
       " 143: 1.2850196078431373,\n",
       " 144: 0.4138680138932744,\n",
       " 145: 0.4557440890125174,\n",
       " 146: 0.46364343827378846,\n",
       " 147: 0.3401816766156242,\n",
       " 148: 0.635654704170708,\n",
       " 149: 1.0,\n",
       " 150: 1.0,\n",
       " 151: 1.1937340619307832,\n",
       " 152: 2.56,\n",
       " 153: 0.5791957578435705,\n",
       " 154: 0.33859984500129164,\n",
       " 155: 0.24116283348666054,\n",
       " 156: 0.35055362396362666,\n",
       " 157: 0.2930292868321037,\n",
       " 158: 0.683735002608242,\n",
       " 159: 3.181359223300971,\n",
       " 160: 3.4675132275132277,\n",
       " 161: 1.7291820580474935,\n",
       " 162: 655.36,\n",
       " 163: 0.8472656755009697,\n",
       " 164: 1.032876280535855,\n",
       " 165: 0.48082171680117386,\n",
       " 166: 0.5130019569471624,\n",
       " 167: 0.686600314300681,\n",
       " 168: 0.40756218905472635,\n",
       " 169: 1.0,\n",
       " 170: 1.278751219512195,\n",
       " 171: 14.403516483516484,\n",
       " 172: 1.4979657142857143,\n",
       " 173: 1.8204444444444445,\n",
       " 174: 0.6905795574288724,\n",
       " 175: 0.5864519015659955,\n",
       " 176: 0.514209493919184,\n",
       " 177: 0.3628792912513843,\n",
       " 178: 1.0,\n",
       " 179: 1.0,\n",
       " 180: 0.5909467989179441,\n",
       " 181: 1.1193168232280102,\n",
       " 182: 0.8965253077975376,\n",
       " 183: 1.055330112721417,\n",
       " 184: 0.8726498002663116,\n",
       " 185: 0.8802686366689053,\n",
       " 186: 0.8197123202001251,\n",
       " 187: 1.0,\n",
       " 188: 1.0,\n",
       " 189: 1.0,\n",
       " 190: 1.0,\n",
       " 191: 0.5306558704453441,\n",
       " 192: 0.5405030927835052,\n",
       " 193: 2.2443835616438355,\n",
       " 194: 1.0,\n",
       " 195: 2.487134724857685,\n",
       " 196: 1.0,\n",
       " 197: 1.0,\n",
       " 198: 1.0,\n",
       " 199: 1.0,\n",
       " 200: 13.797052631578948,\n",
       " 201: 0.701294810058855,\n",
       " 202: 1.5622407628128725,\n",
       " 203: 3.062429906542056,\n",
       " 204: 8.511168831168831,\n",
       " 205: 1.4048445873526259,\n",
       " 206: 1.0,\n",
       " 207: 1.0,\n",
       " 208: 1.0,\n",
       " 209: 1.0,\n",
       " 210: 0.8589252948885976,\n",
       " 211: 0.6994236926360726,\n",
       " 212: 1.0,\n",
       " 213: 2.56,\n",
       " 214: 3.212549019607843,\n",
       " 215: 1.0,\n",
       " 216: 3.041113689095128,\n",
       " 217: 1.0,\n",
       " 218: 13.374693877551021,\n",
       " 219: 2.8248275862068963,\n",
       " 220: 0.4129552614996849,\n",
       " 221: 1.7593557046979866,\n",
       " 222: 1.0,\n",
       " 223: 4.94611320754717,\n",
       " 224: 2.4005860805860806,\n",
       " 225: 1.0,\n",
       " 226: 2.044804992199688,\n",
       " 227: 0.671131592421915,\n",
       " 228: 3.352225063938619,\n",
       " 229: 5.799646017699115,\n",
       " 230: 0.3969473046638401,\n",
       " 231: 1.1578798586572439,\n",
       " 232: 1.2261178671655752,\n",
       " 233: 2.4545318352059926,\n",
       " 234: 3.971878787878788,\n",
       " 235: 1.0,\n",
       " 236: 0.4157056771328893,\n",
       " 237: 0.4549531412703922,\n",
       " 238: 2.56,\n",
       " 239: 3.0696018735362998,\n",
       " 240: 0.5652091418714963,\n",
       " 241: 1.0,\n",
       " 242: 1.8697860199714693,\n",
       " 243: 1.3653333333333333,\n",
       " 244: 0.9982635186595583,\n",
       " 245: 1.28,\n",
       " 246: 0.188105625717566,\n",
       " 247: 0.18636712640409497,\n",
       " 248: 1.3988473852721452,\n",
       " 249: 1.0,\n",
       " 250: 1.8204444444444445,\n",
       " 251: 1.0,\n",
       " 252: 1.1818935978358882,\n",
       " 253: 0.5207469209376242,\n",
       " 254: 0.829044908285895,\n",
       " 255: 0.6537256857855361,\n",
       " 256: 0.3936096096096096,\n",
       " 257: 0.4085785536159601,\n",
       " 258: 1.3696133751306165,\n",
       " 259: 3.5329380053908355,\n",
       " 260: 2.56,\n",
       " 261: 0.9952315869400152,\n",
       " 262: 1.3226236125126136,\n",
       " 263: 1.2226865671641791,\n",
       " 264: 0.9210962754743499,\n",
       " 265: 0.22436152002738788,\n",
       " 266: 0.9133937282229965,\n",
       " 267: 1.155837742504409,\n",
       " 268: 1.0,\n",
       " 269: 2.56,\n",
       " 270: 1.2204096834264433,\n",
       " 271: 2.4966095238095236,\n",
       " 272: 5.9850228310502285,\n",
       " 273: 0.9781492537313433,\n",
       " 274: 0.29224526198439243,\n",
       " 275: 0.15376818395119662,\n",
       " 276: 0.7714655679811654,\n",
       " 277: 1.44352422907489,\n",
       " 278: 3.6207734806629834,\n",
       " 279: 1.0,\n",
       " 280: 0.544997920997921,\n",
       " 281: 0.99221801665405,\n",
       " 282: 1.7546452476572958,\n",
       " 283: 0.9990243902439024,\n",
       " 284: 0.23523330940416368,\n",
       " 285: 0.3085499058380414,\n",
       " 286: 1.45797552836485,\n",
       " 287: 1.0,\n",
       " 288: 1.0,\n",
       " 289: 1.0,\n",
       " 290: 2.56,\n",
       " 291: 1.531214953271028,\n",
       " 292: 2.007228177641654,\n",
       " 293: 0.23629349197764557,\n",
       " 294: 0.3336014252990583,\n",
       " 295: 2.830928725701944,\n",
       " 296: 1.0,\n",
       " 297: 1.0,\n",
       " 298: 1.0,\n",
       " 299: 1.0,\n",
       " 300: 0.4888922044013428,\n",
       " 301: 5.08031007751938,\n",
       " 302: 1.6612420785804816,\n",
       " 303: 1.0,\n",
       " 304: 0.9070726643598616,\n",
       " 305: 1.0,\n",
       " 306: 1.0,\n",
       " 307: 1.0,\n",
       " 308: 4.255584415584416,\n",
       " 309: 1.0,\n",
       " 310: 0.3942015037593985,\n",
       " 311: 1310.72,\n",
       " 312: 1.0320629921259843,\n",
       " 313: 1.0850331125827815,\n",
       " 314: 9.637647058823529,\n",
       " 315: 1.0,\n",
       " 316: 2.4138489871086555,\n",
       " 317: 1.2400378429517502,\n",
       " 318: 4.383678929765886,\n",
       " 319: 1.0,\n",
       " 320: 0.511201248049922,\n",
       " 321: 2.103884430176565,\n",
       " 322: 1.6675826972010177,\n",
       " 323: 2.3280994671403197,\n",
       " 324: 3.2283743842364534,\n",
       " 325: 0.9602344322344323,\n",
       " 326: 3.734245014245014,\n",
       " 327: 1.3470914696813978,\n",
       " 328: 0.9058189357290947,\n",
       " 329: 1.0,\n",
       " 330: 1.28,\n",
       " 331: 2.357410071942446,\n",
       " 332: 0.5630240549828178,\n",
       " 333: 2.2755555555555556,\n",
       " 334: 1.5240930232558139,\n",
       " 335: 1.116456558773424,\n",
       " 336: 0.4178259483583041,\n",
       " 337: 8.796778523489932,\n",
       " 338: 0.9997864225781846,\n",
       " 339: 0.9436429085673146,\n",
       " 340: 1.577280385078219,\n",
       " 341: 2.7536134453781513,\n",
       " 342: 1.2506870229007634,\n",
       " 343: 0.9658953574060427,\n",
       " 344: 0.9355603140613847,\n",
       " 345: 0.3468430801799418,\n",
       " 346: 0.45669686411149824,\n",
       " 347: 1.3266396761133603,\n",
       " 348: 1.3094105894105894,\n",
       " 349: 3.2443564356435646,\n",
       " 350: 4.096,\n",
       " 351: 1.9621556886227545,\n",
       " 352: 1.4340481400437637,\n",
       " 353: 9.709037037037037,\n",
       " 354: 0.5098094126798911,\n",
       " 355: 0.28800703142166556,\n",
       " 356: 0.44431186440677967,\n",
       " 357: 0.5963239308462238,\n",
       " 358: 1.0,\n",
       " 359: 1.0,\n",
       " 360: 1.0,\n",
       " 361: 1.5152832369942197,\n",
       " 362: 2.56,\n",
       " 363: 0.4037954405422058,\n",
       " 364: 0.23256210078069553,\n",
       " 365: 0.545451518934665,\n",
       " 366: 0.6798340248962655,\n",
       " 367: 0.7760331557134399,\n",
       " 368: 2.7887659574468087,\n",
       " 369: 2.9993592677345537,\n",
       " 370: 2.56,\n",
       " 371: 1.0,\n",
       " 372: 6.24152380952381,\n",
       " 373: 0.18303588884234046,\n",
       " 374: 0.17372034459907224,\n",
       " 375: 0.5045111624326405,\n",
       " 376: 0.9416091954022988,\n",
       " 377: 0.7728301886792452,\n",
       " 378: 2.057645211930926,\n",
       " 379: 1.0,\n",
       " 380: 1.0,\n",
       " 381: 1.0,\n",
       " 382: 1.09044925124792,\n",
       " 383: 0.3374665293511843,\n",
       " 384: 0.40743549891202985,\n",
       " 385: 1.5887515151515152,\n",
       " 386: 6.24152380952381,\n",
       " 387: 2.719336099585062,\n",
       " 388: 1.0,\n",
       " 389: 1.0,\n",
       " 390: 1.0,\n",
       " 391: 1.0,\n",
       " 392: 0.11461350122420427,\n",
       " 393: 0.4429604596147347,\n",
       " 394: 6.331980676328502,\n",
       " 395: 1.0,\n",
       " 396: 1.0,\n",
       " 397: 1.0,\n",
       " 398: 1.0,\n",
       " 399: 1.0,\n",
       " 400: 0.6833785192909281,\n",
       " 401: 0.6986780383795309,\n",
       " 402: 0.94025824964132,\n",
       " 403: 1.476036036036036,\n",
       " 404: 1.0,\n",
       " 405: 1.0,\n",
       " 406: 4.909063670411985,\n",
       " 407: 1.0,\n",
       " 408: 1.0,\n",
       " 409: 1.0,\n",
       " 410: 0.5875033617212012,\n",
       " 411: 0.8820457604306864,\n",
       " 412: 1.0,\n",
       " 413: 1.0,\n",
       " 414: 1.0,\n",
       " 415: 1.9078893740902474,\n",
       " 416: 1.080560593569662,\n",
       " 417: 1.0,\n",
       " 418: 3.0062385321100917,\n",
       " 419: 2.830928725701944,\n",
       " 420: 0.992969696969697,\n",
       " 421: 2.0904625199362044,\n",
       " 422: 1.344328205128205,\n",
       " 423: 3.640888888888889,\n",
       " 424: 1.4048445873526259,\n",
       " 425: 0.5249179014817781,\n",
       " 426: 15.984390243902439,\n",
       " 427: 1.0,\n",
       " 428: 0.6139203747072599,\n",
       " 429: 1.2938993089832183,\n",
       " 430: 0.7434600113442995,\n",
       " 431: 11.497543859649122,\n",
       " 432: 1.9218768328445748,\n",
       " 433: 5.1000778210116735,\n",
       " 434: 0.8212531328320802,\n",
       " 435: 1.2272659176029963,\n",
       " 436: 1.0,\n",
       " 437: 2.2405470085470087,\n",
       " 438: 0.3874430978421519,\n",
       " 439: 3.076807511737089,\n",
       " 440: 1.2938993089832183,\n",
       " 441: 1.8644665718349929,\n",
       " 442: 2.6162075848303394,\n",
       " 443: 0.6139203747072599,\n",
       " 444: 0.5639931153184166,\n",
       " 445: 1.0137045630317092,\n",
       " 446: 0.9723442136498517,\n",
       " 447: 2.9993592677345537,\n",
       " 448: 0.7607196749854904,\n",
       " 449: 9.03944827586207,\n",
       " 450: 1.0028462127008417,\n",
       " 451: 1.0,\n",
       " 452: 0.8802686366689053,\n",
       " 453: 0.5380623973727422,\n",
       " 454: 1.6062745098039215,\n",
       " 455: 0.655687843921961,\n",
       " 456: 0.9033218470020675,\n",
       " 457: 0.7131229597388465,\n",
       " 458: 9.165874125874126,\n",
       " 459: 9.102222222222222,\n",
       " 460: 1.0,\n",
       " 461: 1.0,\n",
       " 462: 0.6916728232189974,\n",
       " 463: 0.28217868675995694,\n",
       " 464: 0.7237548315847598,\n",
       " 465: 0.8892265943012212,\n",
       " 466: 0.5475020885547202,\n",
       " 467: 0.5060694980694981,\n",
       " 468: 0.7396839729119639,\n",
       " 469: 1.0,\n",
       " 470: 3.702598870056497,\n",
       " 471: 1.3054980079681275,\n",
       " 472: 0.7039312567132116,\n",
       " 473: 0.5696305953933073,\n",
       " 474: 0.8445360824742268,\n",
       " 475: 0.39207897098414596,\n",
       " 476: 0.1875672581568403,\n",
       " 477: 0.4097280400125039,\n",
       " 478: 1.0,\n",
       " 479: 1.0,\n",
       " 480: 1.0,\n",
       " 481: 1.0280156862745098,\n",
       " 482: 0.2905608512524939,\n",
       " 483: 0.6226698337292161,\n",
       " 484: 0.8274747474747475,\n",
       " 485: 0.6107735321528425,\n",
       " 486: 0.1679764193259003,\n",
       " 487: 0.8691777188328913,\n",
       " 488: 1.0,\n",
       " 489: 1.0,\n",
       " 490: 2.56,\n",
       " 491: 0.43588959095443963,\n",
       " 492: 0.7938946093276802,\n",
       " 493: 0.7096480779642664,\n",
       " 494: 2.742092050209205,\n",
       " 495: 2.1005128205128205,\n",
       " 496: 3.4675132275132277,\n",
       " 497: 1.0,\n",
       " 498: 1.0,\n",
       " 499: 1.0,\n",
       " 500: 0.7554582132564841,\n",
       " 501: 0.23948839758816007,\n",
       " 502: 1.3470914696813978,\n",
       " 503: 1.0,\n",
       " 504: 0.8051105651105651,\n",
       " 505: 0.6823112961998958,\n",
       " 506: 5.201269841269841,\n",
       " 507: 1.0,\n",
       " 508: 1.0,\n",
       " 509: 1.0,\n",
       " 510: 0.6250453028135432,\n",
       " 511: 1.7546452476572958,\n",
       " 512: 1.0,\n",
       " 513: 2.2367235494880546,\n",
       " 514: 1.9134598540145986,\n",
       " 515: 2.4317625231910944,\n",
       " 516: 1.0,\n",
       " 517: 1.7906010928961749,\n",
       " 518: 2.7306666666666666,\n",
       " 519: 1.0,\n",
       " 520: 0.49704967766401215,\n",
       " 521: 1.0,\n",
       " 522: 0.9484225759768452,\n",
       " 523: 0.7797263533610946,\n",
       " 524: 0.723355408388521,\n",
       " 525: 1.7930506155950752,\n",
       " 526: 2.173665008291874,\n",
       " 527: 0.9959878419452888,\n",
       " 528: 6.898526315789474,\n",
       " 529: 1.0,\n",
       " 530: 0.6203123521060104,\n",
       " 531: 1.0,\n",
       " 532: 0.7150681942171304,\n",
       " 533: 0.48689450222882613,\n",
       " 534: 0.7058266020463112,\n",
       " 535: 5.002748091603054,\n",
       " 536: 0.94025824964132,\n",
       " 537: 0.42932197838191943,\n",
       " 538: 1.4003418803418803,\n",
       " 539: 1.0,\n",
       " 540: 5.02191570881226,\n",
       " 541: 8.680264900662252,\n",
       " 542: 0.30847728877382913,\n",
       " 543: 0.5393909465020577,\n",
       " 544: 1.8512994350282486,\n",
       " 545: 1.2459315589353612,\n",
       " 546: 1.1872463768115942,\n",
       " 547: 0.6701022494887525,\n",
       " 548: 0.8971389459274469,\n",
       " 549: 1.0,\n",
       " 550: 1.0,\n",
       " 551: 0.8253904282115869,\n",
       " 552: 0.4266666666666667,\n",
       " 553: 0.5944308390022676,\n",
       " 554: 2.054420062695925,\n",
       " 555: 0.4087059557218584,\n",
       " 556: 0.7787997623291741,\n",
       " 557: 0.46678062678062676,\n",
       " 558: 2.6914168377823406,\n",
       " 559: 1.0,\n",
       " 560: 0.7948574893875076,\n",
       " 561: 0.6589844142785319,\n",
       " 562: 1.0717252657399836,\n",
       " 563: 0.8533333333333334,\n",
       " 564: 0.497426944971537,\n",
       " 565: 0.40119987756351394,\n",
       " 566: 0.23983897529734674,\n",
       " 567: 0.7005451630144308,\n",
       " 568: 1.3146639919759278,\n",
       " 569: 1.0,\n",
       " 570: 0.7598376811594203,\n",
       " 571: 0.575129442738043,\n",
       " 572: 1.09044925124792,\n",
       " 573: 1.3081037924151697,\n",
       " 574: 0.30291657037208225,\n",
       " 575: 0.16593492847195848,\n",
       " 576: 0.5867144136078782,\n",
       " 577: 0.45749389179755673,\n",
       " 578: 2.9925114155251142,\n",
       " 579: 1.0,\n",
       " 580: 1.0,\n",
       " 581: 0.3859599528857479,\n",
       " 582: 1.0,\n",
       " 583: 1.0,\n",
       " 584: 0.35092904953145915,\n",
       " 585: 0.21980882106322322,\n",
       " 586: 0.7647141190198367,\n",
       " 587: 2.5700392156862746,\n",
       " 588: 1.0,\n",
       " 589: 1.0,\n",
       " 590: 0.21389033942558747,\n",
       " 591: 0.8946894197952219,\n",
       " 592: 1.0,\n",
       " 593: 0.41835939993616345,\n",
       " 594: 0.2731804918716132,\n",
       " 595: 0.9967452471482889,\n",
       " 596: 6.3015384615384615,\n",
       " 597: 1.0,\n",
       " 598: 1.0,\n",
       " 599: 1.0,\n",
       " 600: 0.3487812666311868,\n",
       " 601: 0.6085051067780873,\n",
       " 602: 2.708099173553719,\n",
       " 603: 0.5551545955103769,\n",
       " 604: 0.48545185185185186,\n",
       " 605: 1.0,\n",
       " 606: 4.269446254071661,\n",
       " 607: 1.0,\n",
       " 608: 2.837056277056277,\n",
       " 609: 1.0,\n",
       " 610: 0.4251443399286409,\n",
       " 611: 2.3405714285714287,\n",
       " 612: 0.5625407725321888,\n",
       " 613: 1.9889529590288315,\n",
       " 614: 5.799646017699115,\n",
       " 615: 1.0,\n",
       " 616: 3.777291066282421,\n",
       " 617: 1.4371929824561402,\n",
       " 618: 1.0,\n",
       " 619: 1.0,\n",
       " 620: 9.637647058823529,\n",
       " 621: 0.6690760592138847,\n",
       " 622: 0.5666753134457415,\n",
       " 623: 1.636354556803995,\n",
       " 624: 1.8280613668061367,\n",
       " 625: 1.1829602888086643,\n",
       " 626: 1.0814521452145214,\n",
       " 627: 2.56,\n",
       " 628: 1.0,\n",
       " 629: 1.0,\n",
       " 630: 19.275294117647057,\n",
       " 631: 0.38313943291435254,\n",
       " 632: 0.7515596330275229,\n",
       " 633: 0.8011735941320294,\n",
       " 634: 1.7930506155950752,\n",
       " 635: 0.4254203180785459,\n",
       " 636: 0.4671133285816108,\n",
       " 637: 7.447272727272727,\n",
       " 638: 327.68,\n",
       " 639: 1.0,\n",
       " 640: 0.5786843267108168,\n",
       " 641: 0.477319737800437,\n",
       " 642: 1.208036866359447,\n",
       " 643: 1.1723792486583184,\n",
       " 644: 1.312032032032032,\n",
       " 645: 1.2688480154888673,\n",
       " 646: 0.8691777188328913,\n",
       " 647: 1.002079510703364,\n",
       " 648: 1.0,\n",
       " 649: 1.0,\n",
       " 650: 0.521368337311058,\n",
       " 651: 1.1467366579177602,\n",
       " 652: 1.4483093922651933,\n",
       " 653: 0.7558938869665514,\n",
       " 654: 0.3433001571503405,\n",
       " 655: 0.6680530071355759,\n",
       " 656: 0.3275981004748813,\n",
       " 657: 0.9855037593984962,\n",
       " 658: 1.5384037558685446,\n",
       " 659: 1.0,\n",
       " 660: 1.9051162790697675,\n",
       " 661: 1.4293565976008724,\n",
       " 662: 0.9803440538519073,\n",
       " 663: 0.4921967705595193,\n",
       " 664: 0.18502540937323547,\n",
       " 665: 0.8600524934383202,\n",
       " 666: 1.1126655348047538,\n",
       " 667: 0.45797344514325644,\n",
       " 668: 1.0,\n",
       " 669: 1.0,\n",
       " 670: 1.2483047619047618,\n",
       " 671: 1.221547064305685,\n",
       " 672: 0.541396117306898,\n",
       " 673: 0.34285116400732407,\n",
       " 674: 0.19947040024349413,\n",
       " 675: 1.3173065326633167,\n",
       " 676: 1.7000259403372244,\n",
       " 677: 1.0,\n",
       " 678: 1.0,\n",
       " 679: 1.0,\n",
       " 680: 0.512,\n",
       " 681: 0.8832345013477089,\n",
       " 682: 0.8115913312693498,\n",
       " 683: 0.24582145536384095,\n",
       " 684: 0.3195319356411507,\n",
       " 685: 1.1427375762859633,\n",
       " 686: 2.7652320675105484,\n",
       " 687: 1.0,\n",
       " 688: 1.0,\n",
       " 689: 1.0,\n",
       " 690: 0.8483624595469256,\n",
       " 691: 2.051205007824726,\n",
       " 692: 0.3330927573062262,\n",
       " 693: 0.3108181171448897,\n",
       " 694: 0.6238553069966682,\n",
       " 695: 1.0,\n",
       " 696: 4.714820143884892,\n",
       " 697: 1.0,\n",
       " 698: 1.0,\n",
       " 699: 1.0,\n",
       " 700: 1.0,\n",
       " 701: 0.2624064064064064,\n",
       " 702: 0.3086225570991288,\n",
       " 703: 0.3559804454101032,\n",
       " 704: 0.6636556962025316,\n",
       " 705: 1.0,\n",
       " 706: 2.56,\n",
       " 707: 2.8432104121475055,\n",
       " 708: 1.0,\n",
       " 709: 1.0,\n",
       " 710: 0.7417770232031692,\n",
       " 711: 0.3933733493397359,\n",
       " 712: 0.34348008385744233,\n",
       " 713: 1.7664690026954177,\n",
       " 714: 1.0814521452145214,\n",
       " 715: 1.042736674622116,\n",
       " 716: 0.668734693877551,\n",
       " 717: 2.945438202247191,\n",
       " 718: 1.0,\n",
       " 719: 1.0,\n",
       " 720: 0.5278775674587193,\n",
       " 721: 0.5514177534707615,\n",
       " 722: 1.7360529801324502,\n",
       " 723: 1.0,\n",
       " 724: 1.221547064305685,\n",
       " 725: 0.47386840202458425,\n",
       " 726: 1.985939393939394,\n",
       " 727: 2.9388340807174886,\n",
       " 728: 1.0,\n",
       " 729: 1.0,\n",
       " 730: 0.42213204508856683,\n",
       " 731: 0.9309090909090909,\n",
       " 732: 1.8280613668061367,\n",
       " 733: 1.8434880450070323,\n",
       " 734: 0.44887671232876714,\n",
       " 735: 1.208036866359447,\n",
       " 736: 1.0,\n",
       " 737: 1.0,\n",
       " 738: 1.0,\n",
       " 739: 1.0,\n",
       " 740: 0.7589577301679212,\n",
       " 741: 0.9436429085673146,\n",
       " 742: 1.4231487513572205,\n",
       " 743: 0.8820457604306864,\n",
       " 744: 0.7261606648199446,\n",
       " 745: 0.6265391969407266,\n",
       " 746: 1.4293565976008724,\n",
       " 747: 1.0,\n",
       " 748: 2.7710782241014797,\n",
       " 749: 1.0,\n",
       " 750: 0.9416091954022988,\n",
       " 751: 6.826666666666667,\n",
       " 752: 0.5491076665270214,\n",
       " 753: 0.4408745375042045,\n",
       " 754: 0.3425823314166231,\n",
       " 755: 0.5733683289588801,\n",
       " 756: 6.721641025641025,\n",
       " 757: 1.0,\n",
       " 758: 1.0,\n",
       " 759: 1.0,\n",
       " 760: 2.56,\n",
       " 761: 6.898526315789474,\n",
       " 762: 0.5209538950715421,\n",
       " 763: 0.2580157480314961,\n",
       " 764: 0.7783372921615201,\n",
       " 765: 1.1937340619307832,\n",
       " 766: 1.1894010889292197,\n",
       " 767: 10.16062015503876,\n",
       " 768: 1.0,\n",
       " 769: 1.0,\n",
       " 770: 2.56,\n",
       " 771: 6.271387559808613,\n",
       " 772: 0.3039703153988868,\n",
       " 773: 0.6211943127962085,\n",
       " 774: 5.1000778210116735,\n",
       " 775: 1.9919756838905776,\n",
       " 776: 1.0,\n",
       " 777: 1.0,\n",
       " 778: 1.0,\n",
       " 779: 3.95987915407855,\n",
       " 780: 0.512,\n",
       " 781: 0.3731056077426701,\n",
       " 782: 0.16100233386561846,\n",
       " 783: 0.3879017460787215,\n",
       " 784: 1.0,\n",
       " 785: 0.870332005312085,\n",
       " 786: 1.3293306288032454,\n",
       " 787: 1.0,\n",
       " 788: 1.0,\n",
       " 789: 1.0,\n",
       " 790: 5.1000778210116735,\n",
       " 791: 0.4138680138932744,\n",
       " 792: 0.3321642169285352,\n",
       " 793: 0.6916728232189974,\n",
       " 794: 4.551111111111111,\n",
       " 795: 1.0,\n",
       " 796: 1.0,\n",
       " 797: 1.0,\n",
       " 798: 1.0,\n",
       " 799: 1.0,\n",
       " 800: 0.3005549185966521,\n",
       " 801: 0.11696591111904336,\n",
       " 802: 0.39325532553255327,\n",
       " 803: 0.19415197748481705,\n",
       " 804: 0.42037203335471457,\n",
       " 805: 0.35092904953145915,\n",
       " 806: 2.8493913043478263,\n",
       " 807: 1.0,\n",
       " 808: 1.0,\n",
       " 809: 1.0,\n",
       " 810: 0.20267821246327508,\n",
       " 811: 0.24721237268955112,\n",
       " 812: 0.244309412861137,\n",
       " 813: 0.3451988411904135,\n",
       " 814: 0.3944387601564851,\n",
       " 815: 1.7360529801324502,\n",
       " 816: 1.0,\n",
       " 817: 1.0,\n",
       " 818: 1.0,\n",
       " 819: 1.0,\n",
       " 820: 0.44552005438477227,\n",
       " 821: 0.246190833959429,\n",
       " 822: 0.37299943084803644,\n",
       " 823: 0.7511289398280803,\n",
       " 824: 0.7714655679811654,\n",
       " 825: 1.0,\n",
       " 826: 7.447272727272727,\n",
       " 827: 1.0,\n",
       " 828: 1.0,\n",
       " 829: 1.0,\n",
       " 830: 0.9243441466854725,\n",
       " 831: 0.38539253160835046,\n",
       " 832: 0.5174575602052902,\n",
       " 833: 0.5664304235090752,\n",
       " 834: 1.2862806673209028,\n",
       " 835: 2.719336099585062,\n",
       " 836: 1.0,\n",
       " 837: 1.0,\n",
       " 838: 1.0536334405144694,\n",
       " 839: 1.0,\n",
       " 840: 0.4004644057439658,\n",
       " 841: 0.7710117647058824,\n",
       " 842: 0.6902159031068984,\n",
       " 843: 1.048576,\n",
       " 844: 0.8533333333333334,\n",
       " 845: 3.034074074074074,\n",
       " 846: 1.0,\n",
       " 847: 1.0,\n",
       " 848: 1.0,\n",
       " 849: 1.0,\n",
       " 850: 0.33625448948178555,\n",
       " 851: 0.3237144974067671,\n",
       " 852: 0.40554455445544557,\n",
       " 853: 1.1328608470181505,\n",
       " 854: 1.0,\n",
       " 855: 1.0,\n",
       " 856: 1.0,\n",
       " 857: 1.0,\n",
       " 858: 1.0,\n",
       " 859: 4.283398692810458,\n",
       " 860: 0.5618174024860695,\n",
       " 861: 0.8186883198001249,\n",
       " 862: 0.5440929846409298,\n",
       " 863: 1.0,\n",
       " 864: 9.92969696969697,\n",
       " 865: 6.6873469387755105,\n",
       " 866: 1.0,\n",
       " 867: 1.0,\n",
       " 868: 1.0,\n",
       " 869: 1.0,\n",
       " 870: 1.2091512915129152,\n",
       " 871: 0.8784986595174262,\n",
       " 872: 0.6495143706640237,\n",
       " 873: 2.56,\n",
       " 874: 2.56,\n",
       " 875: 1.0,\n",
       " 876: 1.0,\n",
       " 877: 3.971878787878788,\n",
       " 878: 1.0,\n",
       " 879: 1.0,\n",
       " 880: 0.3764273406088455,\n",
       " 881: 0.4907225758143018,\n",
       " 882: 2.56,\n",
       " 883: 7.084972972972973,\n",
       " 884: 6.068148148148148,\n",
       " 885: 1.0,\n",
       " 886: 1.0,\n",
       " 887: 1.0,\n",
       " 888: 1.0,\n",
       " 889: 1.0,\n",
       " 890: 0.7150681942171304,\n",
       " 891: 93.62285714285714,\n",
       " 892: 1.0,\n",
       " 893: 1.0,\n",
       " 894: 1.0,\n",
       " 895: 1.0,\n",
       " 896: 1.0,\n",
       " 897: 1.0,\n",
       " 898: 1.0,\n",
       " 899: 1.0,\n",
       " 900: 0.5108028059236165,\n",
       " 901: 0.10246404002501563,\n",
       " 902: 0.07398927462602314,\n",
       " 903: 0.20871337579617835,\n",
       " 904: 2.9127111111111113,\n",
       " 905: 0.6162294311236484,\n",
       " 906: 0.6200189214758751,\n",
       " 907: 3.4952533333333333,\n",
       " 908: 1.0,\n",
       " 909: 1.0,\n",
       " 910: 0.20508840557033328,\n",
       " 911: 0.15906796116504854,\n",
       " 912: 0.2465149520406244,\n",
       " 913: 0.9623494860499265,\n",
       " 914: 4.020613496932516,\n",
       " 915: 6.0124770642201835,\n",
       " 916: 1.3016087388282025,\n",
       " 917: 3.5045989304812832,\n",
       " 918: 3.6510306406685236,\n",
       " 919: 1.0,\n",
       " 920: 0.22374871969955618,\n",
       " 921: 0.2523041385948027,\n",
       " 922: 1.147740805604203,\n",
       " 923: 3.855058823529412,\n",
       " 924: 1.0,\n",
       " 925: 1.0,\n",
       " 926: 1.0,\n",
       " 927: 1.2926232741617356,\n",
       " 928: 1.0,\n",
       " 929: 1.0,\n",
       " 930: 0.18549674497594112,\n",
       " 931: 0.6096372093023256,\n",
       " 932: 1.0,\n",
       " 933: 1.0,\n",
       " 934: 1.0,\n",
       " 935: 7.489828571428571,\n",
       " 936: 5.674112554112554,\n",
       " 937: 5.9850228310502285,\n",
       " 938: 1.0,\n",
       " 939: 1.0,\n",
       " 940: 0.2921801159161837,\n",
       " 941: 1.6528625472887768,\n",
       " 942: 1.0,\n",
       " 943: 1.0,\n",
       " 944: 3.713087818696884,\n",
       " 945: 2.68040899795501,\n",
       " 946: 1.0,\n",
       " 947: 87.38133333333333,\n",
       " 948: 100.82461538461538,\n",
       " 949: 1.0,\n",
       " 950: 2.932259507829978,\n",
       " 951: 2.56,\n",
       " 952: 1.0,\n",
       " 953: 1.968048048048048,\n",
       " 954: 1.0,\n",
       " 955: 1.0,\n",
       " 956: 1.0,\n",
       " 957: 1.518794901506373,\n",
       " 958: 109.22666666666667,\n",
       " 959: 0.7987324801950031,\n",
       " 960: 0.609353788935379,\n",
       " 961: 1.0,\n",
       " 962: 1.0,\n",
       " 963: 1.0,\n",
       " 964: 1.0,\n",
       " 965: 1.0,\n",
       " 966: 1.0,\n",
       " 967: 2.5352417794970985,\n",
       " 968: 1.0,\n",
       " 969: 2.742092050209205,\n",
       " 970: 0.7253569452130603,\n",
       " 971: 1.0,\n",
       " 972: 1.0,\n",
       " 973: 1.0,\n",
       " 974: 1.0,\n",
       " 975: 1.608245398773006,\n",
       " 976: 1.0,\n",
       " 977: 1.995007610350076,\n",
       " 978: 1.6161775585696672,\n",
       " 979: 1.1136108751062022,\n",
       " 980: 2.404990825688073,\n",
       " 981: 1.0,\n",
       " 982: 1.0,\n",
       " 983: 1.0,\n",
       " 984: 1.0,\n",
       " 985: 1.0,\n",
       " 986: 1.0,\n",
       " 987: 1.0,\n",
       " 988: 1.0,\n",
       " 989: 1.1568578993821712,\n",
       " 990: 1.0,\n",
       " 991: 1.0,\n",
       " 992: 1.0,\n",
       " 993: 1.0,\n",
       " 994: 1.0,\n",
       " 995: 1.0,\n",
       " 996: 1.0,\n",
       " 997: 1.4387705817782657,\n",
       " 998: 1.0,\n",
       " 999: 0.04456260837044844,\n",
       " ...}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Copy the class weights\n",
    "if not os.path.exists(\"/content/class_weights.npy\"):\n",
    "  !gsutil -m cp -r gs://crypto_nlp_training/four_float_to_int/class_weights.npy /content/class_weights.npy\n",
    "\n",
    "# Load the class weights\n",
    "cwnp = np.load(\"/content/class_weights.npy\")\n",
    "\n",
    "CLASS_WEIGHTS_DICT = {}\n",
    "\n",
    "for i in range(cwnp.shape[0]):\n",
    "  CLASS_WEIGHTS_DICT[i] = cwnp[i]\n",
    "\n",
    "CLASS_WEIGHTS_DICT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J9cA0AKquwZ2"
   },
   "source": [
    "---\n",
    "# Prepare data source\n",
    "\n",
    "For training a neural network, first the data source has to be prepared. For this purpose, the method `FileListToDataStream` from the `DataStreamCreator` class is used. This method creates a stream of `X-Block` and `y-data` arrays out of a list of .csv file names, pointing to tick tables (called `EXAMPLE_FILE_PATHS` in this example). For details about `X-Blocks` and `y-data`, please refer to the documentation of the `XBlockGenerator` and the `YDataGenerator` under https://github.com/girsigit/CryptoCrystalBall/tree/main/DataStreamCreator.\n",
    "\n",
    "<br>\n",
    "\n",
    "Target values (y-data) from the data generator would not be necessary in this notebook, but since it cannot be switched off, the future direction and its derviation of the price have been chosen in `Y_TYPE_DICT` since they are not expensive to compute. A switch flag will be added in a future release."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pqze4dT8uz6V",
    "outputId": "985dae70-a5db-4972-bde2-b52e5b15c6b5",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dataType': 0,\n",
       " 'direction_ma_timespan': 200,\n",
       " 'derivation_ma_timespan': 100,\n",
       " 'direction_derivation_shift_span': 0}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set direction and derivation information as y target\n",
    "# Both y values (direction & derivation) are in the interval [-1.0,1.0]\n",
    "\n",
    "Y_TYPE_DICT = copy.deepcopy(DataStreamCreator.YDataGenerator.PARAM_DICT_TEMPLATE_Y_DATA_TYPE_DIRECTION_FLOAT)\n",
    "Y_TYPE_DICT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mlb37_K21h7j",
    "outputId": "473038a5-e93d-4ba8-e917-4da2ba5ba05f",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "77"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate how many word shall be replaced\n",
    "replace_index_number = int(np.round(X_BLOCK_LENGHT * MLM_MASK_FACTOR))\n",
    "replace_index_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1gVe75Q51mHH",
    "outputId": "3dba72d9-8963-4293-b88c-f11421c1d0e3",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 77)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[422,  93, 449, 256, 494,   2, 473, 322, 156, 175,  72, 249, 451,\n",
       "        232, 243, 452, 342,  42,  14, 369, 364,  20, 239, 188, 307, 371,\n",
       "         98, 270, 149,  71, 489, 310, 466, 234,  22,  65, 171, 229, 218,\n",
       "        281, 394, 472, 384, 150,  99, 133, 372, 233,  88, 329,   5, 393,\n",
       "        132, 137, 248, 167, 191,  50,  20,  96,  71, 174, 496,  63, 342,\n",
       "        293, 373, 228, 245, 126,  65, 425, 338, 175, 421, 406, 243],\n",
       "       [222,  62, 501, 331, 104, 338, 468,   9,   6, 311, 195, 412, 183,\n",
       "        457, 349, 315, 465, 318,  72, 462, 287, 444, 463,  35,  66, 509,\n",
       "        117, 265,  88, 354, 227, 115, 240, 448, 210, 161, 445, 108, 171,\n",
       "        411, 402, 211, 271, 497, 176, 278, 358, 497, 203, 362, 280, 229,\n",
       "        249, 343, 111,  67, 427, 447, 368, 504, 270, 266,  80, 136, 148,\n",
       "        174, 279, 385, 217,  84,  69,  77,  14, 189, 507, 460,  52],\n",
       "       [388, 398, 165, 108, 305,  53,  95, 417,  53, 427,  65, 158, 155,\n",
       "          9, 334,  41, 407, 474, 386, 232, 389, 339, 436,  58, 229, 340,\n",
       "        299, 315, 433, 424, 306, 377,  14, 360, 503, 503, 135, 372, 393,\n",
       "        199, 207, 180,  92, 106, 248, 196, 487, 179, 184,  48, 448,  29,\n",
       "        441, 202, 110, 148, 157,  15, 491, 455, 244,  58,  94, 325, 250,\n",
       "        350, 424, 383, 280,  37,  27, 225,  75, 266, 494, 481, 227],\n",
       "       [ 72, 463, 193, 200, 212, 237,   9, 112,  51, 255, 449, 271,  97,\n",
       "        137, 479, 294, 308,  55, 182, 504, 105,  93, 138, 275, 136,  54,\n",
       "         32, 294,  83, 142, 101, 188, 157,  90, 434,  65, 429, 291, 264,\n",
       "        330, 128, 178, 322, 461, 451, 143, 484, 363, 279, 125, 443,  22,\n",
       "        377,  58, 168, 478, 395,   2, 161, 389, 292, 451, 222, 237, 113,\n",
       "        307,  18, 385,   3, 479, 140, 280, 134, 441, 251, 506, 116],\n",
       "       [388, 121, 306, 416, 498, 273,  44,  93, 415, 282, 270, 444, 204,\n",
       "        161, 293, 498, 488,  78, 233, 252, 311, 228, 368, 128, 178, 215,\n",
       "        367, 129, 494, 335, 314,  31, 214, 504, 156, 219, 332, 450, 128,\n",
       "        242,  70,  34, 191, 328, 352, 459, 400, 509, 252, 121, 250, 331,\n",
       "        208, 112, 472, 167, 113, 399, 476,  60, 362, 100, 202, 307, 451,\n",
       "        246, 241, 128, 311, 402, 382, 156, 287, 325,  13, 108, 310]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create random indices, to replace 'words' with MASK_TOKEN_I\n",
    "mask_positions = np.round(np.random.rand(BATCH_SIZE, replace_index_number) * X_BLOCK_LENGHT).astype(int)\n",
    "print(mask_positions.shape)\n",
    "mask_positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 336
    },
    "id": "vVctAErd2wzo",
    "outputId": "435f0cae-bf0a-4446-9078-bafb66dd4fbf",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([32., 44., 40., 42., 46., 32., 36., 37., 35., 41.]),\n",
       " array([  2. ,  52.7, 103.4, 154.1, 204.8, 255.5, 306.2, 356.9, 407.6,\n",
       "        458.3, 509. ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(mask_positions.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "a7iuksPdCSrZ",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Method for normalizing the distribution of one digit\n",
    "def NormalizeDigitDistribution(dataIn, categoryLimitValues):\n",
    "  normalizedDistribution = np.empty(dataIn.shape)\n",
    "\n",
    "  for i, lim in enumerate(categoryLimitValues):\n",
    "    normalizedDistribution[(dataIn >= lim[0]) & (dataIn <= lim[1])] = i\n",
    "\n",
    "  return normalizedDistribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "d4kZzefRCRhB",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Method for converting a four-float vector into an integer 'word' in the range of 0-10000\n",
    "def ConvertFourFloatDataToWords(fourFloatIn, digitLimits):\n",
    "  # Normalize each digit\n",
    "  digitsNormalized = []\n",
    "\n",
    "  for digit in range(4):\n",
    "    digitsNormalized.append(\n",
    "        NormalizeDigitDistribution(fourFloatIn[:,:,digit], digitLimits[digit])\n",
    "        )\n",
    "    \n",
    "  # Combine the digits to one integer (creating the 'word')\n",
    "  intData = digitsNormalized[0] * 1000 + digitsNormalized[1] * 100 + digitsNormalized[2] * 10 + digitsNormalized[3]\n",
    "  intData = intData.astype(np.int32)  \n",
    "\n",
    "  del digitsNormalized\n",
    "\n",
    "  return intData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "S2e6q_2su26o",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# A python generator function has to be applied on the dataStream\n",
    "\n",
    "def pythonGeneratorMLMTraining():\n",
    "  # Initialize the FileListToDataStream generator\n",
    "  dataStreamTraining = DataStreamCreator.FileListToDataStream(fileList = TRAIN_FILES,\n",
    "                                                      batch_size = BATCH_SIZE,\n",
    "                                                      X_Block_lenght = X_BLOCK_LENGHT,\n",
    "                                                      y_type_dict=Y_TYPE_DICT,\n",
    "                                                      shuffle=True,\n",
    "                                                      parallel_generators = BATCH_SIZE,\n",
    "                                                      random_seed = RANDOM_SEED,\n",
    "                                                      **DATA_STREAM_PARAMETERS\n",
    "                                                      )\n",
    "  \n",
    "  # Calculate how many word shall be replaced\n",
    "  mask_number = int(np.round(X_BLOCK_LENGHT * MLM_MASK_FACTOR))\n",
    "  logging.info(f\"In each batch of X-Blocks, {mask_number*BATCH_SIZE} elements will be randomly masked. This is an average of {mask_number} per X-Block\")\n",
    "\n",
    "  # This while has to integrated into the FileListToDataStream method\n",
    "  while True:  \n",
    "    try:\n",
    "      ne = next(dataStreamTraining)\n",
    "      _X = ne['X']\n",
    "\n",
    "      # Convert the X-Block into a sentence\n",
    "      with tf.device('/CPU:0'):        \n",
    "        four_float_sentence = fourFloatClassifierModel.predict(_X, batch_size = BATCH_SIZE, verbose = 0)\n",
    "        int_sentence = ConvertFourFloatDataToWords(four_float_sentence, digitLimits)\n",
    "\n",
    "        # _X_sentence = intClassifierModel.predict(_X, batch_size = BATCH_SIZE, verbose = 0)\n",
    "\n",
    "      # Round to avoid too many categories\n",
    "      # Todo: Better classifier model!\n",
    "      # _X_sentence = np.round(_X_sentence / 10.0).astype(int)\n",
    "\n",
    "      # Create random indices, to replace 'words' with MASK_TOKEN_I\n",
    "      mask_positions = np.round(np.random.rand(BATCH_SIZE, mask_number) * X_BLOCK_LENGHT * BATCH_SIZE).astype(int)\n",
    "      mask_positions[mask_positions == X_BLOCK_LENGHT * BATCH_SIZE] -= 1  # Avoid the upper array limit\n",
    "\n",
    "      # Mask the chosen tokens\n",
    "      int_sentence_masked = np.array(int_sentence).flatten()\n",
    "      int_sentence_masked[mask_positions] = MASK_TOKEN_ID\n",
    "      int_sentence_masked = int_sentence_masked.reshape(int_sentence.shape)\n",
    "\n",
    "      # print(mask_positions[0,0])\n",
    "\n",
    "      # 'Remove' all tokens that shall not be predicted from the training y data (the full sentence), so that the network can focus on the missing tokens\n",
    "      # More precise: Setting them to -1 tells the loss function to ignore them\n",
    "      int_sentence[int_sentence_masked != MASK_TOKEN_ID] = -1\n",
    "\n",
    "      # Not required here, as the network shall predict back its original input\n",
    "      # _y = ne['y']\n",
    "      \n",
    "      # Return the masked senteces as X data, the full ones are the y-data --> The network shall predict the missing tokens\n",
    "      yield (int_sentence_masked, int_sentence)\n",
    "    except StopIteration as si:\n",
    "      logging.warning(\"StopIteration in pythonGenerator\")\n",
    "      logging.warning(si)\n",
    "      return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FoTRNHyEvnyg",
    "outputId": "d7fb1944-9236-47c2-c749-8a999e6fe3e3",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<FlatMapDataset element_spec=(TensorSpec(shape=(5, 512), dtype=tf.int32, name=None), TensorSpec(shape=(5, 512), dtype=tf.int32, name=None))>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a Tensorflow dataset out of the python generator, which can be fed to the network\n",
    "tfGenTraining = tf.data.Dataset.from_generator(pythonGeneratorMLMTraining, \n",
    "                                               output_types = (tf.int32, tf.int32),\n",
    "                                               output_shapes=(\n",
    "                                                   (BATCH_SIZE, X_BLOCK_LENGHT),\n",
    "                                                   (BATCH_SIZE, X_BLOCK_LENGHT)\n",
    "                                                   )\n",
    "                                               )\n",
    "tfGenTraining.prefetch(buffer_size=2)\n",
    "tfGenTraining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YST-Iwzsv4GO",
    "outputId": "5bcf6d64-6742-46d2-a6da-860fd98e47b2",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:File 'TFC-USDT.csv' loaded, 120 left\n",
      "INFO:root:File 'CEL-USDT.csv' loaded, 119 left\n",
      "INFO:root:File 'DGB-USDT.csv' loaded, 118 left\n",
      "INFO:root:File 'BTT-USDT.csv' loaded, 117 left\n",
      "INFO:root:File 'GAME-USDT.csv' loaded, 116 left\n",
      "INFO:root:In each batch of X-Blocks, 385 elements will be randomly masked. This is an average of 77 per X-Block\n"
     ]
    }
   ],
   "source": [
    "it = tfGenTraining.as_numpy_iterator()\n",
    "\n",
    "ne = next(it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fUxLLmbB3gu2",
    "outputId": "47b8b7f0-9e8e-4ca1-e7de-fe1619e0193a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4443,    3, 4443, ..., 4705, 2905,    3],\n",
       "       [4443, 4443, 4443, ..., 7283, 9196,    3],\n",
       "       [   3, 4443, 4443, ..., 5498, 6398, 5496],\n",
       "       [4443, 4443,    3, ..., 8621,    3, 8424],\n",
       "       [4443, 4443,    3, ...,   92,   92,   93]], dtype=int32)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ne[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wh8PxiukwI4r",
    "outputId": "08907604-1651-4f5e-9552-228b10bb71fb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  -1, 4443,   -1, ...,   -1,   -1, 5806],\n",
       "       [  -1,   -1,   -1, ...,   -1,   -1, 4086],\n",
       "       [4543,   -1,   -1, ...,   -1,   -1,   -1],\n",
       "       [  -1,   -1, 4443, ...,   -1, 9533,   -1],\n",
       "       [  -1,   -1, 4443, ...,   -1,   -1,   -1]], dtype=int32)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ne[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 354
    },
    "id": "n7Ge9vX8C2q3",
    "outputId": "0dfd442e-7bcc-43fc-951c-3be50f20a210"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([623., 242., 195., 204., 287., 166., 195., 203., 191., 254.]),\n",
       " array([3.0000e+00, 9.9690e+02, 1.9908e+03, 2.9847e+03, 3.9786e+03,\n",
       "        4.9725e+03, 5.9664e+03, 6.9603e+03, 7.9542e+03, 8.9481e+03,\n",
       "        9.9420e+03]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(ne[0].flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 372
    },
    "id": "5_UA09HxC48E",
    "outputId": "9e36f4da-0996-4cd8-d316-abee0fcf3e76"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([2251.,   36.,   33.,   30.,   49.,   28.,   22.,   34.,   31.,\n",
       "          46.]),\n",
       " array([-1.0000e+00,  9.9240e+02,  1.9858e+03,  2.9792e+03,  3.9726e+03,\n",
       "         4.9660e+03,  5.9594e+03,  6.9528e+03,  7.9462e+03,  8.9396e+03,\n",
       "         9.9330e+03]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjMAAAGdCAYAAADnrPLBAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/P9b71AAAACXBIWXMAAA9hAAAPYQGoP6dpAAAgnklEQVR4nO3de3BU5f3H8c+SkDWkySkhJstKwDhDFQ1aG2wIUgHBACVkrE5B0YhTilrlkgLlop2Rn6ME7RSYDpUi40gFFKcjWFuYlFA1lkkCGEzlpuIYbpIliGE3aNxweX5/OJzpEkASNpcH3q+ZnXHPfndzzoOStyd7Nh5jjBEAAIClOrX3DgAAAFwKYgYAAFiNmAEAAFYjZgAAgNWIGQAAYDViBgAAWI2YAQAAViNmAACA1WLbewday+nTp3Xo0CElJibK4/G09+4AAICLYIxRfX29/H6/OnW6uHMul23MHDp0SOnp6e29GwAAoAUOHDigHj16XNTsZRsziYmJkr5bjKSkpHbeGwAAcDFCoZDS09Pd7+MX47KNmTM/WkpKSiJmAACwTHPeIsIbgAEAgNWIGQAAYDViBgAAWI2YAQAAViNmAACA1YgZAABgNWIGAABYjZgBAABWI2YAAIDViBkAAGA1YgYAAFiNmAEAAFYjZgAAgNWIGQAAYLXY9t4BW107e11770Kz7Z0/qr13AQCAqOPMDAAAsBoxAwAArEbMAAAAqxEzAADAasQMAACwGjEDAACsRswAAACrETMAAMBqxAwAALAaMQMAAKxGzAAAAKsRMwAAwGrEDAAAsBoxAwAArEbMAAAAqxEzAADAasQMAACwGjEDAACsRswAAACrETMAAMBqxAwAALAaMQMAAKxGzAAAAKsRMwAAwGrEDAAAsBoxAwAArEbMAAAAqxEzAADAasQMAACwGjEDAACsRswAAACrETMAAMBqxAwAALAaMQMAAKzWrJgpKirSbbfdpsTERKWmpuruu+/WJ598EjFjjNHcuXPl9/sVHx+vwYMHa+fOnREz4XBYkydPVkpKihISEpSfn6+DBw9GzNTV1amgoECO48hxHBUUFOjYsWMtO0oAAHDZalbMlJaW6oknnlBFRYVKSkp08uRJ5ebm6uuvv3ZnXnjhBS1YsECLFy/W1q1b5fP5dNddd6m+vt6dKSws1Nq1a7V69Wpt2rRJx48fV15enk6dOuXOjBs3TlVVVSouLlZxcbGqqqpUUFAQhUMGAACXE48xxrT0yUeOHFFqaqpKS0t1xx13yBgjv9+vwsJCzZo1S9J3Z2HS0tL0/PPP69FHH1UwGNTVV1+tFStWaOzYsZKkQ4cOKT09XevXr9fw4cO1e/du3XjjjaqoqFB2drYkqaKiQjk5Ofr44491/fXXf+++hUIhOY6jYDCopKSklh7ieV07e13UX7O17Z0/qr13AQCAC2rJ9+9Les9MMBiUJCUnJ0uSqqurFQgElJub6854vV4NGjRIZWVlkqTKykqdOHEiYsbv9yszM9OdKS8vl+M4bshIUv/+/eU4jjsDAAAgSbEtfaIxRtOmTdPAgQOVmZkpSQoEApKktLS0iNm0tDTt27fPnYmLi1PXrl2bzJx5fiAQUGpqapOvmZqa6s6cLRwOKxwOu/dDoVALjwwAANikxWdmJk2apI8++kivv/56k8c8Hk/EfWNMk21nO3vmXPMXep2ioiL3zcKO4yg9Pf1iDgMAAFiuRTEzefJkvf3223r33XfVo0cPd7vP55OkJmdPamtr3bM1Pp9PjY2Nqquru+DM4cOHm3zdI0eONDnrc8acOXMUDAbd24EDB1pyaAAAwDLNihljjCZNmqQ1a9bonXfeUUZGRsTjGRkZ8vl8Kikpcbc1NjaqtLRUAwYMkCRlZWWpc+fOETM1NTXasWOHO5OTk6NgMKgtW7a4M5s3b1YwGHRnzub1epWUlBRxAwAAl79mvWfmiSee0Guvvaa///3vSkxMdM/AOI6j+Ph4eTweFRYWat68eerdu7d69+6tefPmqUuXLho3bpw7O2HCBE2fPl3dunVTcnKyZsyYob59+2rYsGGSpD59+mjEiBGaOHGili5dKkl65JFHlJeXd1FXMgEAgCtHs2JmyZIlkqTBgwdHbH/llVf08MMPS5JmzpyphoYGPf7446qrq1N2drY2bNigxMREd37hwoWKjY3VmDFj1NDQoKFDh2r58uWKiYlxZ1atWqUpU6a4Vz3l5+dr8eLFLTlGAABwGbukz5npyPicmab4nBkAQEfX5p8zAwAA0N6IGQAAYDViBgAAWI2YAQAAViNmAACA1YgZAABgNWIGAABYjZgBAABWI2YAAIDViBkAAGA1YgYAAFiNmAEAAFYjZgAAgNWIGQAAYDViBgAAWI2YAQAAViNmAACA1YgZAABgNWIGAABYjZgBAABWI2YAAIDViBkAAGA1YgYAAFiNmAEAAFYjZgAAgNWIGQAAYDViBgAAWI2YAQAAViNmAACA1YgZAABgNWIGAABYjZgBAABWI2YAAIDViBkAAGA1YgYAAFiNmAEAAFYjZgAAgNWIGQAAYDViBgAAWI2YAQAAViNmAACA1YgZAABgNWIGAABYjZgBAABWI2YAAIDViBkAAGA1YgYAAFiNmAEAAFYjZgAAgNWIGQAAYDViBgAAWI2YAQAAViNmAACA1YgZAABgNWIGAABYjZgBAABWI2YAAIDViBkAAGA1YgYAAFiNmAEAAFYjZgAAgNWIGQAAYDViBgAAWI2YAQAAViNmAACA1YgZAABgNWIGAABYjZgBAABWa3bMvP/++xo9erT8fr88Ho/eeuutiMcffvhheTyeiFv//v0jZsLhsCZPnqyUlBQlJCQoPz9fBw8ejJipq6tTQUGBHMeR4zgqKCjQsWPHmn2AAADg8tbsmPn66691yy23aPHixeedGTFihGpqatzb+vXrIx4vLCzU2rVrtXr1am3atEnHjx9XXl6eTp065c6MGzdOVVVVKi4uVnFxsaqqqlRQUNDc3QUAAJe52OY+YeTIkRo5cuQFZ7xer3w+3zkfCwaDevnll7VixQoNGzZMkrRy5Uqlp6dr48aNGj58uHbv3q3i4mJVVFQoOztbkrRs2TLl5OTok08+0fXXX9/c3QYAAJepVnnPzHvvvafU1FT96Ec/0sSJE1VbW+s+VllZqRMnTig3N9fd5vf7lZmZqbKyMklSeXm5HMdxQ0aS+vfvL8dx3JmzhcNhhUKhiBsAALj8RT1mRo4cqVWrVumdd97RH//4R23dulV33nmnwuGwJCkQCCguLk5du3aNeF5aWpoCgYA7k5qa2uS1U1NT3ZmzFRUVue+vcRxH6enpUT4yAADQETX7x0zfZ+zYse4/Z2Zmql+/furVq5fWrVune+6557zPM8bI4/G49//3n88387/mzJmjadOmufdDoRBBAwDAFaDVL83u3r27evXqpT179kiSfD6fGhsbVVdXFzFXW1urtLQ0d+bw4cNNXuvIkSPuzNm8Xq+SkpIibgAA4PLX6jFz9OhRHThwQN27d5ckZWVlqXPnziopKXFnampqtGPHDg0YMECSlJOTo2AwqC1btrgzmzdvVjAYdGcAAACkFvyY6fjx4/rss8/c+9XV1aqqqlJycrKSk5M1d+5c3Xvvverevbv27t2rJ598UikpKfrFL34hSXIcRxMmTND06dPVrVs3JScna8aMGerbt697dVOfPn00YsQITZw4UUuXLpUkPfLII8rLy+NKJgAAEKHZMfPBBx9oyJAh7v0z71MZP368lixZou3bt+vVV1/VsWPH1L17dw0ZMkRvvPGGEhMT3ecsXLhQsbGxGjNmjBoaGjR06FAtX75cMTEx7syqVas0ZcoU96qn/Pz8C362DQAAuDJ5jDGmvXeiNYRCITmOo2Aw2Crvn7l29rqov2Zr2zt/VHvvAgAAF9SS79/8biYAAGA1YgYAAFiNmAEAAFYjZgAAgNWIGQAAYDViBgAAWI2YAQAAViNmAACA1YgZAABgNWIGAABYjZgBAABWI2YAAIDViBkAAGA1YgYAAFiNmAEAAFYjZgAAgNWIGQAAYDViBgAAWI2YAQAAViNmAACA1YgZAABgNWIGAABYjZgBAABWI2YAAIDViBkAAGA1YgYAAFiNmAEAAFYjZgAAgNWIGQAAYDViBgAAWI2YAQAAViNmAACA1YgZAABgNWIGAABYjZgBAABWI2YAAIDViBkAAGA1YgYAAFiNmAEAAFYjZgAAgNWIGQAAYDViBgAAWI2YAQAAViNmAACA1YgZAABgNWIGAABYjZgBAABWI2YAAIDViBkAAGA1YgYAAFiNmAEAAFYjZgAAgNWIGQAAYDViBgAAWI2YAQAAViNmAACA1YgZAABgNWIGAABYjZgBAABWI2YAAIDViBkAAGA1YgYAAFiNmAEAAFYjZgAAgNWIGQAAYDViBgAAWI2YAQAAVmt2zLz//vsaPXq0/H6/PB6P3nrrrYjHjTGaO3eu/H6/4uPjNXjwYO3cuTNiJhwOa/LkyUpJSVFCQoLy8/N18ODBiJm6ujoVFBTIcRw5jqOCggIdO3as2QcIAAAub82Oma+//lq33HKLFi9efM7HX3jhBS1YsECLFy/W1q1b5fP5dNddd6m+vt6dKSws1Nq1a7V69Wpt2rRJx48fV15enk6dOuXOjBs3TlVVVSouLlZxcbGqqqpUUFDQgkMEAACXM48xxrT4yR6P1q5dq7vvvlvSd2dl/H6/CgsLNWvWLEnfnYVJS0vT888/r0cffVTBYFBXX321VqxYobFjx0qSDh06pPT0dK1fv17Dhw/X7t27deONN6qiokLZ2dmSpIqKCuXk5Ojjjz/W9ddf/737FgqF5DiOgsGgkpKSWnqI53Xt7HVRf83Wtnf+qPbeBQAALqgl37+j+p6Z6upqBQIB5ebmutu8Xq8GDRqksrIySVJlZaVOnDgRMeP3+5WZmenOlJeXy3EcN2QkqX///nIcx505WzgcVigUirgBAIDLX1RjJhAISJLS0tIitqelpbmPBQIBxcXFqWvXrhecSU1NbfL6qamp7szZioqK3PfXOI6j9PT0Sz4eAADQ8bXK1UwejyfivjGmybaznT1zrvkLvc6cOXMUDAbd24EDB1qw5wAAwDZRjRmfzydJTc6e1NbWumdrfD6fGhsbVVdXd8GZw4cPN3n9I0eONDnrc4bX61VSUlLEDQAAXP6iGjMZGRny+XwqKSlxtzU2Nqq0tFQDBgyQJGVlZalz584RMzU1NdqxY4c7k5OTo2AwqC1btrgzmzdvVjAYdGcAAAAkKba5Tzh+/Lg+++wz9351dbWqqqqUnJysnj17qrCwUPPmzVPv3r3Vu3dvzZs3T126dNG4ceMkSY7jaMKECZo+fbq6deum5ORkzZgxQ3379tWwYcMkSX369NGIESM0ceJELV26VJL0yCOPKC8v76KuZAIAAFeOZsfMBx98oCFDhrj3p02bJkkaP368li9frpkzZ6qhoUGPP/646urqlJ2drQ0bNigxMdF9zsKFCxUbG6sxY8aooaFBQ4cO1fLlyxUTE+POrFq1SlOmTHGvesrPzz/vZ9sAAIAr1yV9zkxHxufMNMXnzAAAOrp2/5wZAACAtkbMAAAAqxEzAADAasQMAACwGjEDAACsRswAAACrETMAAMBqxAwAALAaMQMAAKxGzAAAAKsRMwAAwGrEDAAAsBoxAwAArEbMAAAAqxEzAADAasQMAACwGjEDAACsRswAAACrETMAAMBqxAwAALAaMQMAAKxGzAAAAKsRMwAAwGrEDAAAsBoxAwAArEbMAAAAqxEzAADAasQMAACwGjEDAACsRswAAACrETMAAMBqxAwAALAaMQMAAKxGzAAAAKsRMwAAwGrEDAAAsBoxAwAArEbMAAAAqxEzAADAasQMAACwGjEDAACsRswAAACrETMAAMBqxAwAALAaMQMAAKxGzAAAAKsRMwAAwGrEDAAAsBoxAwAArEbMAAAAqxEzAADAasQMAACwGjEDAACsRswAAACrETMAAMBqxAwAALAaMQMAAKxGzAAAAKsRMwAAwGrEDAAAsBoxAwAArEbMAAAAqxEzAADAasQMAACwGjEDAACsRswAAACrETMAAMBqUY+ZuXPnyuPxRNx8Pp/7uDFGc+fOld/vV3x8vAYPHqydO3dGvEY4HNbkyZOVkpKihIQE5efn6+DBg9HeVQAAcBlolTMzN910k2pqatzb9u3b3cdeeOEFLViwQIsXL9bWrVvl8/l01113qb6+3p0pLCzU2rVrtXr1am3atEnHjx9XXl6eTp061Rq7CwAALBbbKi8aGxtxNuYMY4wWLVqkp556Svfcc48k6a9//avS0tL02muv6dFHH1UwGNTLL7+sFStWaNiwYZKklStXKj09XRs3btTw4cNbY5cBAIClWuXMzJ49e+T3+5WRkaH77rtPn3/+uSSpurpagUBAubm57qzX69WgQYNUVlYmSaqsrNSJEyciZvx+vzIzM92ZcwmHwwqFQhE3AABw+Yt6zGRnZ+vVV1/Vv/71Ly1btkyBQEADBgzQ0aNHFQgEJElpaWkRz0lLS3MfCwQCiouLU9euXc87cy5FRUVyHMe9paenR/nIAABARxT1mBk5cqTuvfde9e3bV8OGDdO6deskfffjpDM8Hk/Ec4wxTbad7ftm5syZo2Aw6N4OHDhwCUcBAABs0eqXZickJKhv377as2eP+z6as8+w1NbWumdrfD6fGhsbVVdXd96Zc/F6vUpKSoq4AQCAy1+rx0w4HNbu3bvVvXt3ZWRkyOfzqaSkxH28sbFRpaWlGjBggCQpKytLnTt3jpipqanRjh073BkAAIAzon4104wZMzR69Gj17NlTtbW1evbZZxUKhTR+/Hh5PB4VFhZq3rx56t27t3r37q158+apS5cuGjdunCTJcRxNmDBB06dPV7du3ZScnKwZM2a4P7YCAAD4X1GPmYMHD+r+++/Xl19+qauvvlr9+/dXRUWFevXqJUmaOXOmGhoa9Pjjj6uurk7Z2dnasGGDEhMT3ddYuHChYmNjNWbMGDU0NGjo0KFavny5YmJior27AADAch5jjGnvnWgNoVBIjuMoGAy2yvtnrp29Luqv2dr2zh/V3rsAAMAFteT7N7+bCQAAWI2YAQAAViNmAACA1YgZAABgNWIGAABYjZgBAABWI2YAAIDViBkAAGA1YgYAAFiNmAEAAFYjZgAAgNWIGQAAYDViBgAAWI2YAQAAViNmAACA1YgZAABgNWIGAABYjZgBAABWI2YAAIDViBkAAGA1YgYAAFiNmAEAAFYjZgAAgNWIGQAAYDViBgAAWI2YAQAAViNmAACA1YgZAABgNWIGAABYjZgBAABWI2YAAIDViBkAAGA1YgYAAFiNmAEAAFYjZgAAgNWIGQAAYDViBgAAWI2YAQAAViNmAACA1YgZAABgNWIGAABYjZgBAABWI2YAAIDViBkAAGA1YgYAAFiNmAEAAFYjZgAAgNWIGQAAYDViBgAAWI2YAQAAViNmAACA1YgZAABgNWIGAABYjZgBAABWI2YAAIDViBkAAGA1YgYAAFiNmAEAAFYjZgAAgNWIGQAAYDViBgAAWI2YAQAAViNmAACA1YgZAABgtdj23gEA7e/a2evaexeabe/8Ue29C0BU8d9hy3FmBgAAWI0zM1cQG6vfRh3l/1SAaODvDdigw8fMiy++qD/84Q+qqanRTTfdpEWLFulnP/tZe+8WcF785d82bFxnQhdoHR06Zt544w0VFhbqxRdf1O23366lS5dq5MiR2rVrl3r27NneuwcAzWJjgAE26NDvmVmwYIEmTJigX//61+rTp48WLVqk9PR0LVmypL13DQAAdBAd9sxMY2OjKisrNXv27Ijtubm5KisrazIfDocVDofd+8FgUJIUCoVaZf9Oh79pldcFAMAWrfE99sxrGmMu+jkdNma+/PJLnTp1SmlpaRHb09LSFAgEmswXFRXp//7v/5psT09Pb7V9BADgSuYsar3Xrq+vl+M4FzXbYWPmDI/HE3HfGNNkmyTNmTNH06ZNc++fPn1aX331lbp163bO+UsRCoWUnp6uAwcOKCkpKaqvjUisddtgndsOa912WOu2E821Nsaovr5efr//op/TYWMmJSVFMTExTc7C1NbWNjlbI0ler1derzdi2w9/+MPW3EUlJSXxH0gbYa3bBuvcdljrtsNat51orfXFnpE5o8O+ATguLk5ZWVkqKSmJ2F5SUqIBAwa0014BAICOpsOemZGkadOmqaCgQP369VNOTo5eeukl7d+/X4899lh77xoAAOggOnTMjB07VkePHtUzzzyjmpoaZWZmav369erVq1e77pfX69XTTz/d5MdaiD7Wum2wzm2HtW47rHXbae+19pjmXPsEAADQwXTY98wAAABcDGIGAABYjZgBAABWI2YAAIDViJlmevHFF5WRkaGrrrpKWVlZ+s9//tPeu9ShFRUV6bbbblNiYqJSU1N1991365NPPomYMcZo7ty58vv9io+P1+DBg7Vz586ImXA4rMmTJyslJUUJCQnKz8/XwYMHI2bq6upUUFAgx3HkOI4KCgp07Nix1j7EDqmoqEgej0eFhYXuNtY5er744gs9+OCD6tatm7p06aIf//jHqqysdB9nraPj5MmT+v3vf6+MjAzFx8fruuuu0zPPPKPTp0+7M6x1y7z//vsaPXq0/H6/PB6P3nrrrYjH23Jd9+/fr9GjRyshIUEpKSmaMmWKGhsbm3dABhdt9erVpnPnzmbZsmVm165dZurUqSYhIcHs27evvXetwxo+fLh55ZVXzI4dO0xVVZUZNWqU6dmzpzl+/Lg7M3/+fJOYmGjefPNNs337djN27FjTvXt3EwqF3JnHHnvMXHPNNaakpMRs27bNDBkyxNxyyy3m5MmT7syIESNMZmamKSsrM2VlZSYzM9Pk5eW16fF2BFu2bDHXXnutufnmm83UqVPd7axzdHz11VemV69e5uGHHzabN2821dXVZuPGjeazzz5zZ1jr6Hj22WdNt27dzD//+U9TXV1t/va3v5kf/OAHZtGiRe4Ma90y69evN0899ZR58803jSSzdu3aiMfbal1PnjxpMjMzzZAhQ8y2bdtMSUmJ8fv9ZtKkSc06HmKmGX7605+axx57LGLbDTfcYGbPnt1Oe2Sf2tpaI8mUlpYaY4w5ffq08fl8Zv78+e7Mt99+axzHMX/5y1+MMcYcO3bMdO7c2axevdqd+eKLL0ynTp1McXGxMcaYXbt2GUmmoqLCnSkvLzeSzMcff9wWh9Yh1NfXm969e5uSkhIzaNAgN2ZY5+iZNWuWGThw4HkfZ62jZ9SoUeZXv/pVxLZ77rnHPPjgg8YY1jpazo6ZtlzX9evXm06dOpkvvvjCnXn99deN1+s1wWDwoo+BHzNdpMbGRlVWVio3Nzdie25ursrKytppr+wTDAYlScnJyZKk6upqBQKBiHX1er0aNGiQu66VlZU6ceJExIzf71dmZqY7U15eLsdxlJ2d7c70799fjuNcUX8+TzzxhEaNGqVhw4ZFbGedo+ftt99Wv3799Mtf/lKpqam69dZbtWzZMvdx1jp6Bg4cqH//+9/69NNPJUn//e9/tWnTJv385z+XxFq3lrZc1/LycmVmZkb8Usnhw4crHA5H/Oj2+3ToTwDuSL788kudOnWqyS+5TEtLa/LLMHFuxhhNmzZNAwcOVGZmpiS5a3eudd23b587ExcXp65duzaZOfP8QCCg1NTUJl8zNTX1ivnzWb16tbZt26atW7c2eYx1jp7PP/9cS5Ys0bRp0/Tkk09qy5YtmjJlirxerx566CHWOopmzZqlYDCoG264QTExMTp16pSee+453X///ZL497q1tOW6BgKBJl+na9euiouLa9baEzPN5PF4Iu4bY5psw7lNmjRJH330kTZt2tTksZas69kz55q/Uv58Dhw4oKlTp2rDhg266qqrzjvHOl+606dPq1+/fpo3b54k6dZbb9XOnTu1ZMkSPfTQQ+4ca33p3njjDa1cuVKvvfaabrrpJlVVVamwsFB+v1/jx49351jr1tFW6xqNtefHTBcpJSVFMTExTUqxtra2SVWiqcmTJ+vtt9/Wu+++qx49erjbfT6fJF1wXX0+nxobG1VXV3fBmcOHDzf5ukeOHLki/nwqKytVW1urrKwsxcbGKjY2VqWlpfrTn/6k2NhYdw1Y50vXvXt33XjjjRHb+vTpo/3790vi3+lo+t3vfqfZs2frvvvuU9++fVVQUKDf/va3KioqksRat5a2XFefz9fk69TV1enEiRPNWnti5iLFxcUpKytLJSUlEdtLSko0YMCAdtqrjs8Yo0mTJmnNmjV65513lJGREfF4RkaGfD5fxLo2NjaqtLTUXdesrCx17tw5YqampkY7duxwZ3JychQMBrVlyxZ3ZvPmzQoGg1fEn8/QoUO1fft2VVVVubd+/frpgQceUFVVla677jrWOUpuv/32Jh8v8Omnn7q/AJd/p6Pnm2++UadOkd+mYmJi3EuzWevW0ZbrmpOTox07dqimpsad2bBhg7xer7Kysi5+py/6rcJwL81++eWXza5du0xhYaFJSEgwe/fube9d67B+85vfGMdxzHvvvWdqamrc2zfffOPOzJ8/3ziOY9asWWO2b99u7r///nNeAtijRw+zceNGs23bNnPnnXee8xLAm2++2ZSXl5vy8nLTt2/fy/rSyu/zv1czGcM6R8uWLVtMbGysee6558yePXvMqlWrTJcuXczKlSvdGdY6OsaPH2+uueYa99LsNWvWmJSUFDNz5kx3hrVumfr6evPhhx+aDz/80EgyCxYsMB9++KH7USNtta5nLs0eOnSo2bZtm9m4caPp0aMHl2a3tj//+c+mV69eJi4uzvzkJz9xLzHGuUk65+2VV15xZ06fPm2efvpp4/P5jNfrNXfccYfZvn17xOs0NDSYSZMmmeTkZBMfH2/y8vLM/v37I2aOHj1qHnjgAZOYmGgSExPNAw88YOrq6trgKDums2OGdY6ef/zjHyYzM9N4vV5zww03mJdeeinicdY6OkKhkJk6darp2bOnueqqq8x1111nnnrqKRMOh90Z1rpl3n333XP+3Tx+/HhjTNuu6759+8yoUaNMfHy8SU5ONpMmTTLffvtts47HY4wxF38eBwAAoGPhPTMAAMBqxAwAALAaMQMAAKxGzAAAAKsRMwAAwGrEDAAAsBoxAwAArEbMAAAAqxEzAADAasQMAACwGjEDAACsRswAAACr/T8Ycl9EpI0HpwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(ne[1].flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3Ow2UkYNIB2X",
    "outputId": "c9667f3f-ddfd-423c-ab3e-fafb1db5b396"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  -1, 4443,   -1, ...,   -1,   -1, 5806],\n",
       "       [  -1,   -1,   -1, ...,   -1,   -1, 4086],\n",
       "       [4543,   -1,   -1, ...,   -1,   -1,   -1],\n",
       "       [  -1,   -1, 4443, ...,   -1, 9533,   -1],\n",
       "       [  -1,   -1, 4443, ...,   -1,   -1,   -1]], dtype=int32)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wurst = np.array(ne[1])\n",
    "wurst[ne[0] != MASK_TOKEN_ID] = -1\n",
    "wurst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LGFj4aix8P9y",
    "outputId": "c5a2d142-40b7-4f8a-c075-8f351858b62a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(ne[0][0,:] == 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "moBea0tTbFbX"
   },
   "source": [
    "---\n",
    "# Create the NLP model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7V1gTRpwWvV_",
    "outputId": "0eacc029-3de8-4c13-a15d-0852238cfac7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RobertaConfig {\n",
       "  \"attention_probs_dropout_prob\": 0.1,\n",
       "  \"bos_token_id\": 0,\n",
       "  \"classifier_dropout\": null,\n",
       "  \"eos_token_id\": 2,\n",
       "  \"hidden_act\": \"gelu\",\n",
       "  \"hidden_dropout_prob\": 0.1,\n",
       "  \"hidden_size\": 768,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"intermediate_size\": 3072,\n",
       "  \"layer_norm_eps\": 1e-12,\n",
       "  \"max_position_embeddings\": 513,\n",
       "  \"model_type\": \"roberta\",\n",
       "  \"num_attention_heads\": 12,\n",
       "  \"num_hidden_layers\": 12,\n",
       "  \"pad_token_id\": 1,\n",
       "  \"position_embedding_type\": \"absolute\",\n",
       "  \"transformers_version\": \"4.22.0\",\n",
       "  \"type_vocab_size\": 2,\n",
       "  \"use_cache\": true,\n",
       "  \"vocab_size\": 10000\n",
       "}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg = RobertaConfig()\n",
    "\n",
    "cfg.vocab_size = VOCAB_SIZE\n",
    "cfg.max_position_embeddings = X_BLOCK_LENGHT + 1\n",
    "\n",
    "cfg.bos_token_id = BOS_TOKEN_ID\n",
    "cfg.pad_token_id = PAD_TOKEN_ID\n",
    "cfg.eos_token_id = EOS_TOKEN_ID\n",
    "\n",
    "cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LE3ZxhjDuZmA",
    "outputId": "819b43b3-72b8-4f41-f8f3-286efc50804d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"RobertaMLMTraining_1\"\n",
      "____________________________________________________________________________________________________________________________________________________________________________________________________________________________\n",
      " Layer (type)                                                                                      Output Shape                                                                            Param #                          \n",
      "============================================================================================================================================================================================================================\n",
      " input (InputLayer)                                                                                [(None, 512)]                                                                           0                                \n",
      "                                                                                                                                                                                                                            \n",
      " tf_roberta_model (TFRobertaModel)                                                                 TFBaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=(None, 512, 768),      93722112                         \n",
      "                                                                                                    pooler_output=(None, 768),                                                                                              \n",
      "                                                                                                    past_key_values=None, hidden_states=None, attentions=None, cross_attentions=None)                                       \n",
      "                                                                                                                                                                                                                            \n",
      " Categories (Dense)                                                                                (None, 512, 10000)                                                                      7690000                          \n",
      "                                                                                                                                                                                                                            \n",
      "============================================================================================================================================================================================================================\n",
      "Total params: 101,412,112\n",
      "Trainable params: 101,412,112\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________________________________________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#@title CreateModelRobertaMLMTraining\n",
    "def CreateModelRobertaMLMTraining():\n",
    "\n",
    "  # A sentence as input\n",
    "  inputSentence = Input(shape=(X_BLOCK_LENGHT), name='input', dtype='int32')\n",
    "  \n",
    "  # The NLP model\n",
    "  nlp = TFRobertaModel(cfg)(inputSentence)\n",
    "\n",
    "  # A dense layer to predict back the full sentence\n",
    "  predicted_sentence = Dense(VOCAB_SIZE, activation='softmax', name=\"Categories\")(nlp['last_hidden_state'])\n",
    "\n",
    "  outputs = [predicted_sentence]\n",
    "\n",
    "  # And combine it all in a model object\n",
    "  model = Model(inputs=inputSentence, outputs=outputs, name='RobertaMLMTraining_1')\n",
    "\n",
    "  return model\n",
    "\n",
    "model = CreateModelRobertaMLMTraining()\n",
    "model.summary(line_length=220)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ufsD_eAeSSXi"
   },
   "source": [
    "### Todo: Check if weighted classed are required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "PrUGwBcoYfxV"
   },
   "outputs": [],
   "source": [
    "# #@title Load the class weights\n",
    "# with file_io.FileIO('gs://ticks_with_indicators_with_volume/sentences/set2/weightArray.npy', mode='rb') as input_f:\n",
    "#   with file_io.FileIO('/content/weightArray.npy', mode='wb+') as output_f:\n",
    "#     output_f.write(input_f.read())\n",
    "\n",
    "# CLASS_WEIGHTS = np.empty((1,1,1024))\n",
    "# CLASS_WEIGHTS[0,0,:] = np.load('/content/weightArray.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "1QdZbG6kYg-1"
   },
   "outputs": [],
   "source": [
    "# plt.plot(CLASS_WEIGHTS[0,0,:])\n",
    "# plt.yscale(\"log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "Rpigcso1YiwV"
   },
   "outputs": [],
   "source": [
    "# CLASS_WEIGHTS_TF_CONST = tf.constant(tf.convert_to_tensor(CLASS_WEIGHTS,dtype=tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "cellView": "form",
    "id": "jg3ngnAVYlZI"
   },
   "outputs": [],
   "source": [
    "#@title CreateModelRobertaMLMTrainingWeighted - Todo change to new style\n",
    "def CreateModelRobertaMLMTrainingWeighted():\n",
    "\n",
    "  # Build your model input\n",
    "  inputSentence = Input(shape=(X_LOOKBACK_CNT), name='input', dtype='int32')\n",
    "  \n",
    "  nlp = TFRobertaModel(cfg)(inputSentence)\n",
    "\n",
    "  categories = Dense(1024, activation='softmax', name=\"Categories\")(nlp['last_hidden_state'])\n",
    "  categories_weighted = tf.multiply(categories, CLASS_WEIGHTS_TF_CONST)\n",
    "\n",
    "  outputs = [categories_weighted]\n",
    "\n",
    "  mnamesuffix = \"_1\"\n",
    "\n",
    "  # And combine it all in a model object\n",
    "  model = Model(inputs=inputSentence, outputs=outputs, name='ModelRobertaMLMTrainingWeighted'+mnamesuffix)\n",
    "\n",
    "  return model\n",
    "\n",
    "# model = CreateModelRobertaMLMTrainingWeighted()\n",
    "# model.summary(line_length=220)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "cellView": "form",
    "id": "RQbpCGz8fHAi"
   },
   "outputs": [],
   "source": [
    "#@title CreateModelRobertaMLMTrainingDropout - Todo change to new style\n",
    "def CreateModelRobertaMLMTrainingDropout():\n",
    "\n",
    "  # Build your model input\n",
    "  inputSentence = Input(shape=(X_LOOKBACK_CNT), name='input', dtype='int32')\n",
    "  \n",
    "  nlp = TFRobertaModel(cfg, name=\"Roberta\")(inputSentence)\n",
    "\n",
    "  categories = Dense(VOCAB_SIZE, activation='softmax', name=\"Categories\")(nlp['last_hidden_state'])\n",
    "  drp = Dropout(0.15, name=\"CategoriesDropout\")(categories)\n",
    "\n",
    "  # categories_weighted = tf.multiply(drp, CLASS_WEIGHTS_TF_CONST)\n",
    "\n",
    "  outputs = [drp]\n",
    "\n",
    "  mnamesuffix = \"_1\"\n",
    "\n",
    "  # And combine it all in a model object\n",
    "  model = Model(inputs=inputSentence, outputs=outputs, name='ModelRobertaMLMTrainingDropout'+mnamesuffix)\n",
    "\n",
    "  return model\n",
    "\n",
    "# model = CreateModelRobertaMLMTrainingDropout()\n",
    "# model.summary(line_length=220)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "cellView": "form",
    "id": "ZDpFvhHH7hEi"
   },
   "outputs": [],
   "source": [
    "#@title CreateModelRobertaLastWordPrediction - Todo change to new style\n",
    "def CreateModelRobertaLastWordPrediction():\n",
    "\n",
    "  # Build your model input\n",
    "  inputSentence = Input(shape=(X_LOOKBACK_CNT), name='input', dtype='int32')\n",
    "  \n",
    "  nlp = TFRobertaModel(cfg, name=\"Roberta\")(inputSentence)\n",
    "\n",
    "  flat = Flatten(name=\"FlattenNLP\")(nlp['last_hidden_state'])\n",
    "  lastWord = Dense(VOCAB_SIZE, activation='softmax', name=\"Categories\", dtype=tf.float32)(flat)\n",
    "\n",
    "  outputs = [lastWord]\n",
    "\n",
    "  mnamesuffix = \"_1\"\n",
    "\n",
    "  # And combine it all in a model object\n",
    "  model = Model(inputs=inputSentence, outputs=outputs, name='ModelRobertaLastWordPrediction'+mnamesuffix)\n",
    "\n",
    "  return model\n",
    "\n",
    "# model = CreateModelRobertaLastWordPrediction()\n",
    "# model.summary(line_length=220)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kXE8AjjoEWE4"
   },
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QfwL7EWInGWB"
   },
   "source": [
    "### Train strategy in the paper\n",
    "https://huggingface.co/roberta-base\n",
    "\n",
    "The model was trained on 1024 V100 GPUs for 500K steps with a batch size of 8K and a sequence length of 512. The optimizer used is Adam with a learning rate of 6e-4, 1=0.9\\beta_{1} = 0.91=0.9, 2=0.98\\beta_{2} = 0.982=0.98 and =1e6\\epsilon = 1e-6=1e6, a weight decay of 0.01, learning rate warmup for 24,000 steps and linear decay of the learning rate after."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "_jkOrQ01hZnE",
    "outputId": "afe655bf-d35c-4f71-ced0-d225a2ff6155"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'RobertaMLMTraining_1_GPU_512LB_10000VC_MaskedPrediction'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CHKPNT_NAME = f\"{model.name}_GPU_{X_BLOCK_LENGHT}LB_{VOCAB_SIZE}VC_MaskedPrediction\"\n",
    "CHKPNT_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "g0VmovApkwAB"
   },
   "outputs": [],
   "source": [
    "# Set an optimizer\n",
    "optimizer = Adam(\n",
    "    learning_rate=5e-04,\n",
    "    epsilon=1e-06,\n",
    "    beta_1=0.9,\n",
    "    beta_2=0.98,\n",
    "    decay=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "id": "yMoJi05f0JKp"
   },
   "outputs": [],
   "source": [
    "# # Create a masked loss to predict only the missing tokens\n",
    "# # https://stackoverflow.com/questions/56328140/how-do-i-implement-a-masked-softmax-cross-entropy-loss-function-in-keras\n",
    "\n",
    "# SCCE = tf.keras.losses.SparseCategoricalCrossentropy(reduction=tf.keras.losses.Reduction.NONE, from_logits=False)\n",
    "\n",
    "# def sparse_crossentropy_masked(y_true, y_pred):\n",
    "#   y_true_masked = tf.boolean_mask(y_true, tf.not_equal(y_true, -1))\n",
    "#   y_pred_masked = tf.boolean_mask(y_pred, tf.not_equal(y_true, -1))\n",
    "\n",
    "#   return tf.reduce_sum(SCCE(y_true_masked, y_pred_masked)) * (1. / BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "id": "mhCAE0Ujne49"
   },
   "outputs": [],
   "source": [
    "# # Create a masked loss to predict only the missing tokens\n",
    "# # https://stackoverflow.com/questions/56328140/how-do-i-implement-a-masked-softmax-cross-entropy-loss-function-in-keras\n",
    "\n",
    "# SCCE = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False)\n",
    "\n",
    "# def sparse_crossentropy_masked(y_true, y_pred):\n",
    "#   # y_true_masked = tf.boolean_mask(y_true, tf.not_equal(y_true, -1))\n",
    "#   # y_pred_masked = tf.boolean_mask(y_pred, tf.not_equal(y_true, -1))\n",
    "\n",
    "#   maskTensor = tf.not_equal(y_true, -1)\n",
    "#   a\n",
    "#   y_true_masked = y_true * tf.cast(maskTensor, tf.int32)\n",
    "#   y_pred_masked = y_pred * tf.cast(maskTensor, tf.float32)\n",
    "\n",
    "#   return SCCE(y_true_masked, y_pred_masked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "id": "AOLSygN7Ut7_"
   },
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "# model.compile(\n",
    "#     optimizer = optimizer,\n",
    "#     loss = [tf.keras.losses.MeanSquaredError()], \n",
    "#     metrics=[tf.keras.losses.MeanAbsoluteError(), tf.keras.losses.MeanAbsolutePercentageError()])\n",
    "\n",
    "model.compile(\n",
    "    optimizer = optimizer,\n",
    "    loss = tf.keras.losses.SparseCategoricalCrossentropy(ignore_class=-1),\n",
    "    metrics=None)\n",
    "\n",
    "# model.compile(\n",
    "#     optimizer = optimizer,\n",
    "#     loss = sparse_crossentropy_masked, \n",
    "#     metrics=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TFa0iWcaqli5",
    "outputId": "0ec595c6-7c5c-4723-8a2c-64d0d7a07f08"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"RobertaMLMTraining_1\"\n",
      "____________________________________________________________________________________________________________________________________________________________________________________________________________________________\n",
      " Layer (type)                                                                                      Output Shape                                                                            Param #                          \n",
      "============================================================================================================================================================================================================================\n",
      " input (InputLayer)                                                                                [(None, 512)]                                                                           0                                \n",
      "                                                                                                                                                                                                                            \n",
      " tf_roberta_model (TFRobertaModel)                                                                 TFBaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=(None, 512, 768),      93722112                         \n",
      "                                                                                                    pooler_output=(None, 768),                                                                                              \n",
      "                                                                                                    past_key_values=None, hidden_states=None, attentions=None, cross_attentions=None)                                       \n",
      "                                                                                                                                                                                                                            \n",
      " Categories (Dense)                                                                                (None, 512, 10000)                                                                      7690000                          \n",
      "                                                                                                                                                                                                                            \n",
      "============================================================================================================================================================================================================================\n",
      "Total params: 101,412,112\n",
      "Trainable params: 101,412,112\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________________________________________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary(line_length=220)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "id": "iGC1RvizroRS"
   },
   "outputs": [],
   "source": [
    "# # Callback for colab\n",
    "# # Todo: Adapt the callback to be suitable for both colab (store to bucket) and local (store to disk)\n",
    "# #@title CustomCallback\n",
    "# class CustomCallback(tf.keras.callbacks.Callback):\n",
    "#   def __init__(self, save_freq, val_freq, checkpoint_path, model_name, epoch_add=0):\n",
    "#     self.save_freq = save_freq\n",
    "#     self.val_freq = val_freq\n",
    "#     self.checkpoint_path = checkpoint_path\n",
    "#     self.model_name = model_name\n",
    "#     self.current_epoch = 0\n",
    "#     self.epoch_add = epoch_add\n",
    "\n",
    "#   def on_epoch_begin(self, epoch, logs=None):\n",
    "#     self.current_epoch = epoch + self.epoch_add\n",
    "#     # keys = list(logs.keys())\n",
    "#     # print(\"Start epoch {} of training; got log keys: {}\".format(epoch, keys))\n",
    "\n",
    "#   def on_epoch_end(self, epoch, logs=None):\n",
    "#     self.saveTheModel(-1, logs)\n",
    "\n",
    "#   def on_train_batch_end(self, batch, logs=None):\n",
    "#     self.saveTheModel(batch, logs)\n",
    "\n",
    "#   def saveTheModel(self, batch, logs=None):\n",
    "#     if (0 < batch and 0 == batch % self.save_freq) or (0 > batch):\n",
    "#       if 0 > batch:\n",
    "#         _save_folder = os.path.join(self.checkpoint_path,\n",
    "#                                     self.model_name,\n",
    "#                                     \"cp_daily_valid_{:02d}_end\".format(self.current_epoch)\n",
    "#                                     )\n",
    "#       else:\n",
    "#         _save_folder = os.path.join(self.checkpoint_path,\n",
    "#                                     self.model_name,\n",
    "#                                     \"cp_daily_valid_{:02d}_{:05d}\".format(self.current_epoch, batch)\n",
    "#                                     )\n",
    "\n",
    "#       _model_path_local = os.path.join(\"/content/\", \"model.h5\")\n",
    "#       _model_path_bucket = os.path.join(_save_folder, \"model.h5\")\n",
    "\n",
    "#       model.save(_model_path_local)\n",
    "     \n",
    "#       # Copy model.h5 over to Google Cloud Storage\n",
    "#       with file_io.FileIO(_model_path_local, mode='rb') as input_f:\n",
    "#           with file_io.FileIO(_model_path_bucket, mode='wb+') as output_f:\n",
    "#               output_f.write(input_f.read())\n",
    "#               print(\"\\nSaved model to: '\" + _model_path_bucket + \"'\")\n",
    "\n",
    "#       # Save optimizer config\n",
    "#       c = copy.deepcopy(self.model.optimizer.get_config())\n",
    "\n",
    "#       fp = os.path.join(_save_folder, \"c.pickle\")\n",
    "#       with file_io.FileIO(fp, mode='wb+') as handle:\n",
    "#         pickle.dump(c, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "#         print(\"Saved optimizer config to: '\" + fp + \"'\")\n",
    "\n",
    "#       # Save optimizer weights\n",
    "#       # w = copy.deepcopy(self.model.optimizer.get_weights())\n",
    "\n",
    "#       # fp = os.path.join(_save_folder, \"w.pickle\")\n",
    "#       # with file_io.FileIO(fp, mode='wb+') as handle:\n",
    "#       #   pickle.dump(w, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "#       #   print(\"Saved optimizer weights to: '\" + fp + \"'\")\n",
    "\n",
    "#     # if 0 < batch and 0 == batch % self.val_freq:\n",
    "#     #   print(\"-------------------------EVAL-------------------------\")\n",
    "#     #   model.evaluate(tfgenTest)\n",
    "#     #   print(\"\\n-------------------------EVAL-------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title CustomCallback\n",
    "class CustomCallback(tf.keras.callbacks.Callback):\n",
    "  def __init__(self, save_freq, val_freq, checkpoint_path, model_name, epoch_add=0):\n",
    "    self.save_freq = save_freq\n",
    "    self.val_freq = val_freq\n",
    "    self.checkpoint_path = checkpoint_path\n",
    "    self.model_name = model_name\n",
    "    self.current_epoch = 0\n",
    "    self.epoch_add = epoch_add\n",
    "\n",
    "  def on_epoch_begin(self, epoch, logs=None):\n",
    "    self.current_epoch = epoch + self.epoch_add\n",
    "    # keys = list(logs.keys())\n",
    "    # print(\"Start epoch {} of training; got log keys: {}\".format(epoch, keys))\n",
    "\n",
    "  def on_epoch_end(self, epoch, logs=None):\n",
    "    self.saveTheModel(-1, logs)\n",
    "\n",
    "  def on_train_batch_end(self, batch, logs=None):\n",
    "    self.saveTheModel(batch, logs)\n",
    "\n",
    "  def saveTheModel(self, batch, logs=None):\n",
    "    if (0 < batch and 0 == batch % self.save_freq) or (0 > batch):\n",
    "      logging.info(str(datetime.datetime.utcnow()))\n",
    "    \n",
    "      if 0 > batch:\n",
    "        _save_folder = os.path.join(self.checkpoint_path,\n",
    "                                    self.model_name,\n",
    "                                    \"cp_daily_valid_{:02d}_end\".format(self.current_epoch)\n",
    "                                    )\n",
    "      else:\n",
    "        _save_folder = os.path.join(self.checkpoint_path,\n",
    "                                    self.model_name,\n",
    "                                    \"cp_daily_valid_{:02d}_{:05d}\".format(self.current_epoch, batch)\n",
    "                                    )\n",
    "      \n",
    "      fp = os.path.join(_save_folder, \"model.h5\")\n",
    "      model.save(fp)\n",
    "      logging.info(f\"Saved model to '{fp}'\")\n",
    "      \n",
    "      # Save optimizer config\n",
    "      # c = copy.deepcopy(self.model.optimizer.get_config())\n",
    "\n",
    "      fp = os.path.join(_save_folder, \"c.pickle\")\n",
    "      with file_io.FileIO(fp, mode='wb+') as handle:\n",
    "        pickle.dump(self.model.optimizer.get_config(), handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "        \n",
    "      logging.info(f\"Saved optimizer config to '{fp}'\")\n",
    "\n",
    "      # Save optimizer weights\n",
    "      # w = copy.deepcopy(self.model.optimizer.get_weights())\n",
    "\n",
    "      fp = os.path.join(_save_folder, \"w.pickle\")\n",
    "      with open(fp, \"wb\") as handle:\n",
    "        # with file_io.FileIO(fp, mode='wb+') as handle:\n",
    "        pickle.dump(self.model.optimizer.get_weights(), handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "      \n",
    "      logging.info(f\"Saved optimizer weights to '{fp}'\")\n",
    "        \n",
    "      logging.info(f\"Did a gc collect: {gc.collect()}\")\n",
    "\n",
    "    # if 0 < batch and 0 == batch % self.val_freq:\n",
    "    #   print(\"-------------------------EVAL-------------------------\")\n",
    "    #   model.evaluate(tfgenTest)\n",
    "    #   print(\"\\n-------------------------EVAL-------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25200"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "id": "TczoGFYOStmg"
   },
   "outputs": [],
   "source": [
    "# CLASS_WEIGHTS_DICT = None\n",
    "# CLASS_WEIGHTS_DICT = {}\n",
    "\n",
    "# for i, cw in enumerate(CLASS_WEIGHTS[0,0,:]):\n",
    "#   CLASS_WEIGHTS_DICT[i] = cw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "id": "JyggHiDGNTEX"
   },
   "outputs": [],
   "source": [
    "epoch_add = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "id": "-pJ08IBN7cgB"
   },
   "outputs": [],
   "source": [
    "CALLBACK_EVERY_N_BATCHES = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "id": "CuGT0rFvzH1n"
   },
   "outputs": [],
   "source": [
    "cc = CustomCallback(checkpoint_path = CHECKPOINT_PATH,\n",
    "                    model_name = CHKPNT_NAME,\n",
    "                    save_freq = CALLBACK_EVERY_N_BATCHES,\n",
    "                    val_freq = CALLBACK_EVERY_N_BATCHES,\n",
    "                    epoch_add = epoch_add)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "id": "LuuH0xBKGE1g",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "id": "0noHN-UeSCQ-"
   },
   "outputs": [],
   "source": [
    "%reload_ext tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u7xAyqce3qYJ"
   },
   "source": [
    "The TensorBoard UI is displayed in a browser window. In this colab, perform the following steps to prepare to capture profile information.\n",
    "1.  Click on the dropdown menu box on the top right side and scroll down and click PROFILE. A new window appears that shows: **No profile data was found** at the top.\n",
    "1.  Click on the CAPTURE PROFILE button. A new dialog appears. The top input line shows: **Profile Service URL or TPU name**. Copy and paste the Profile Service URL (the service_addr value shown before launching TensorBoard) into the top input line. While still on the dialog box, start the training with the next step.\n",
    "1.  Click on the next colab cell to start training the model.\n",
    "1.  Watch the output from the training until several epochs have completed. This allows time for the profile data to start being collected. Return to the dialog box and click on the CAPTURE button. If the capture succeeds, the page will auto refresh and redirect you to the profiling results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "mpUXurxwSp_3",
    "outputId": "8d57d014-c4bc-49e1-a434-179a5be0529c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/content/bigdata/log/RobertaMLMTraining_1_GPU_512LB_10000VC_MaskedPrediction20230219-182050'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Todo: Create more elegant solution\n",
    "log_dir = \"gs://ticks_with_indicators_with_volume/logs/TPU/\" + CHKPNT_NAME + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "if not COLAB:\n",
    "    log_dir = os.path.join(\"/content/bigdata/log\",log_dir.split(\"/\")[-1])\n",
    "\n",
    "log_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "He5Jna87RsPN",
    "outputId": "efab0e32-2cca-4c12-bc49-8cd1fb7492b9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/content/bigdata/log/RobertaMLMTraining_1_GPU_512LB_10000VC_MaskedPrediction20230219-182050'"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "id": "_X-ab7uc3gTt"
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(\n",
    "    log_dir=log_dir,\n",
    "    histogram_freq=1,\n",
    "    update_freq=CALLBACK_EVERY_N_BATCHES    \n",
    "    )\n",
    "#profile_batch=(5,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "CLASS_WEIGHTS_DICT = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(\"/content/bigdata/chk/RobertaMLMTraining_1_GPU_512LB_10000VC_MaskedPrediction/cp_daily_valid_01_end/model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-21e66d994d456e3b\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-21e66d994d456e3b\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir $log_dir --host 0.0.0.0 --port 6006"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DcUTfAbHb2FW",
    "outputId": "a6b2d3a2-f00f-4733-fd4b-268b42e7f2a6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model/roberta/pooler/dense/kernel:0', 'tf_roberta_model/roberta/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model/roberta/pooler/dense/kernel:0', 'tf_roberta_model/roberta/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model/roberta/pooler/dense/kernel:0', 'tf_roberta_model/roberta/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model/roberta/pooler/dense/kernel:0', 'tf_roberta_model/roberta/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "INFO:root:File 'TFC-USDT.csv' loaded, 120 left\n",
      "INFO:root:File 'CEL-USDT.csv' loaded, 119 left\n",
      "INFO:root:File 'DGB-USDT.csv' loaded, 118 left\n",
      "INFO:root:File 'BTT-USDT.csv' loaded, 117 left\n",
      "INFO:root:File 'GAME-USDT.csv' loaded, 116 left\n",
      "INFO:root:In each batch of X-Blocks, 385 elements will be randomly masked. This is an average of 77 per X-Block\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   2000/Unknown - 1305s 647ms/step - loss: 7.7074"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:2023-02-19 18:42:44.459893\n",
      "INFO:root:Saved model to '/content/bigdata/chk/RobertaMLMTraining_1_GPU_512LB_10000VC_MaskedPrediction/cp_daily_valid_02_02000/model.h5'\n",
      "INFO:root:Saved optimizer config to '/content/bigdata/chk/RobertaMLMTraining_1_GPU_512LB_10000VC_MaskedPrediction/cp_daily_valid_02_02000/c.pickle'\n",
      "INFO:root:Saved optimizer weights to '/content/bigdata/chk/RobertaMLMTraining_1_GPU_512LB_10000VC_MaskedPrediction/cp_daily_valid_02_02000/w.pickle'\n",
      "INFO:root:Did a gc collect: 53866\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   2615/Unknown - 1719s 653ms/step - loss: 7.6986"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:File 'XYM-USDT.csv' loaded in retry loop, 115 left\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   2761/Unknown - 1815s 653ms/step - loss: 7.7144"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:File 'ETC-USDT.csv' loaded in retry loop, 114 left\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   3089/Unknown - 2029s 653ms/step - loss: 7.7387"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:File 'LBC-USDT.csv' loaded in retry loop, 113 left\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   4000/Unknown - 2620s 652ms/step - loss: 7.7837"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:2023-02-19 19:04:39.963267\n",
      "INFO:root:Saved model to '/content/bigdata/chk/RobertaMLMTraining_1_GPU_512LB_10000VC_MaskedPrediction/cp_daily_valid_02_04000/model.h5'\n",
      "INFO:root:Saved optimizer config to '/content/bigdata/chk/RobertaMLMTraining_1_GPU_512LB_10000VC_MaskedPrediction/cp_daily_valid_02_04000/c.pickle'\n",
      "INFO:root:Saved optimizer weights to '/content/bigdata/chk/RobertaMLMTraining_1_GPU_512LB_10000VC_MaskedPrediction/cp_daily_valid_02_04000/w.pickle'\n",
      "INFO:root:Did a gc collect: 65549\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   4343/Unknown - 2862s 657ms/step - loss: 7.7876"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:File 'LUNA-USDT.csv' loaded in retry loop, 112 left\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   6000/Unknown - 3937s 654ms/step - loss: 7.8429"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:2023-02-19 19:26:36.710185\n",
      "INFO:root:Saved model to '/content/bigdata/chk/RobertaMLMTraining_1_GPU_512LB_10000VC_MaskedPrediction/cp_daily_valid_02_06000/model.h5'\n",
      "INFO:root:Saved optimizer config to '/content/bigdata/chk/RobertaMLMTraining_1_GPU_512LB_10000VC_MaskedPrediction/cp_daily_valid_02_06000/c.pickle'\n",
      "INFO:root:Saved optimizer weights to '/content/bigdata/chk/RobertaMLMTraining_1_GPU_512LB_10000VC_MaskedPrediction/cp_daily_valid_02_06000/w.pickle'\n",
      "INFO:root:Did a gc collect: 29204\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   8000/Unknown - 5255s 656ms/step - loss: 7.9005"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:2023-02-19 19:48:35.019557\n",
      "INFO:root:Saved model to '/content/bigdata/chk/RobertaMLMTraining_1_GPU_512LB_10000VC_MaskedPrediction/cp_daily_valid_02_08000/model.h5'\n",
      "INFO:root:Saved optimizer config to '/content/bigdata/chk/RobertaMLMTraining_1_GPU_512LB_10000VC_MaskedPrediction/cp_daily_valid_02_08000/c.pickle'\n",
      "INFO:root:Saved optimizer weights to '/content/bigdata/chk/RobertaMLMTraining_1_GPU_512LB_10000VC_MaskedPrediction/cp_daily_valid_02_08000/w.pickle'\n",
      "INFO:root:Did a gc collect: 51919\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  10000/Unknown - 6568s 656ms/step - loss: 7.9355"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:2023-02-19 20:10:28.015731\n",
      "INFO:root:Saved model to '/content/bigdata/chk/RobertaMLMTraining_1_GPU_512LB_10000VC_MaskedPrediction/cp_daily_valid_02_10000/model.h5'\n",
      "INFO:root:Saved optimizer config to '/content/bigdata/chk/RobertaMLMTraining_1_GPU_512LB_10000VC_MaskedPrediction/cp_daily_valid_02_10000/c.pickle'\n",
      "INFO:root:Saved optimizer weights to '/content/bigdata/chk/RobertaMLMTraining_1_GPU_512LB_10000VC_MaskedPrediction/cp_daily_valid_02_10000/w.pickle'\n",
      "INFO:root:Did a gc collect: 51919\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  12000/Unknown - 7888s 656ms/step - loss: 7.9726"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:2023-02-19 20:32:27.360708\n",
      "INFO:root:Saved model to '/content/bigdata/chk/RobertaMLMTraining_1_GPU_512LB_10000VC_MaskedPrediction/cp_daily_valid_02_12000/model.h5'\n",
      "INFO:root:Saved optimizer config to '/content/bigdata/chk/RobertaMLMTraining_1_GPU_512LB_10000VC_MaskedPrediction/cp_daily_valid_02_12000/c.pickle'\n",
      "INFO:root:Saved optimizer weights to '/content/bigdata/chk/RobertaMLMTraining_1_GPU_512LB_10000VC_MaskedPrediction/cp_daily_valid_02_12000/w.pickle'\n",
      "INFO:root:Did a gc collect: 51919\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  12736/Unknown - 8386s 658ms/step - loss: 7.9862"
     ]
    }
   ],
   "source": [
    "model.fit(tfGenTraining,\n",
    "          epochs=200,\n",
    "          verbose = 1,\n",
    "          callbacks=[tensorboard_callback, cc],\n",
    "          class_weight=CLASS_WEIGHTS_DICT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2Nh12BlMEOBF",
    "outputId": "8bb69110-e6ee-48e6-e62b-1547db0c5ee4"
   },
   "outputs": [],
   "source": [
    "# copy_filenames = ['gs://crypto_nlp_training/chk/RobertaMLMTraining_1_GPU_512LB_10000VC_MaskedPrediction/cp_daily_valid_01_06000/model.h5'\n",
    "#                   ]\n",
    "\n",
    "# for p in copy_filenames:\n",
    "#   fn = p.split(\"/\")[-1]\n",
    "#   cpnt = p.split(\"/\")[-2]\n",
    "\n",
    "#   os.mkdir(os.path.join(\"/content\", cpnt))\n",
    "\n",
    "#   localPath = os.path.join(\"/content\", cpnt, fn)\n",
    "\n",
    "#   if (\"model.h5\" in p):\n",
    "#     localPathModel = localPath\n",
    "#   elif (\"w.pickle\" in p):\n",
    "#     localPathW = localPath\n",
    "\n",
    "#   with file_io.FileIO(p, mode='rb') as input_f:\n",
    "#     with file_io.FileIO(localPath, mode='wb+') as output_f:\n",
    "#       output_f.write(input_f.read())\n",
    "#       print(\"Pulled from bucket: '\" + fn + \"'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nYu7qfd3IsMu",
    "outputId": "d24bd442-2144-459f-eec5-0437fdd2cde3"
   },
   "outputs": [],
   "source": [
    "# print(f\"Loading {localPathModel}\")\n",
    "# model.load_weights(localPathModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HRuwJfh2l7nS"
   },
   "outputs": [],
   "source": [
    "# model.load_weights(\"/content/model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3HLXTKPAfZ04"
   },
   "outputs": [],
   "source": [
    "# modelOld = CreateModelRobertaMLMTrainingDropout()\n",
    "# modelOld.load_weights(\"/content/cp_daily_valid_49_end/model.h5\")\n",
    "# modelOld.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NWKr6ROif078"
   },
   "outputs": [],
   "source": [
    "# model.get_layer(\"Roberta\").set_weights(modelOld.get_layer(\"Roberta\").get_weights())\n",
    "# model.get_layer(\"Categories\").set_weights(modelOld.get_layer(\"Categories\").get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_mV2OpQAGDja"
   },
   "outputs": [],
   "source": [
    "# with open(\"/content/w.pickle\", 'rb') as pickle_file:\n",
    "#   w = pickle.load(pickle_file)\n",
    "# model.optimizer.set_weights(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kXHVjhsDHHF9"
   },
   "outputs": [],
   "source": [
    "# model.optimizer.learning_rate = 5e-2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HyBFN04Q-qcU"
   },
   "source": [
    "LR 5e-4  5000/Unknown - 5576s 1s/step - loss: 296.81093730\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zvFil-4dStzq"
   },
   "source": [
    "# Full sentence as y\n",
    "20000/Unknown - 21155s 1s/step - loss: 0.9579\n",
    "Saved model to: 'gs://crypto_nlp_training/chk/RobertaMLMTraining_1_GPU_512LB_10000VC_FullPrediction/cp_daily_valid_00_20000/model.h5'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5le0oPyfbE79"
   },
   "source": [
    "# Masked sentence as y, LR 5e-4, Random state 11\n",
    "14000/Unknown - 15387s 1s/step - loss: 5.3956\n",
    "Saved model to: 'gs://crypto_nlp_training/chk/RobertaMLMTraining_1_GPU_512LB_10000VC_MaskedPrediction/cp_daily_valid_00_14000/model.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P2BZv38mgNQs"
   },
   "outputs": [],
   "source": [
    "# A python generator function has to be applied on the dataStream\n",
    "\n",
    "def pythonGeneratorMLMTraining():\n",
    "  # Initialize the FileListToDataStream generator\n",
    "  dataStreamTraining = DataStreamCreator.FileListToDataStream(fileList = TRAIN_FILES,\n",
    "                                                      batch_size = BATCH_SIZE,\n",
    "                                                      X_Block_lenght = X_BLOCK_LENGHT,\n",
    "                                                      y_type_dict=Y_TYPE_DICT,\n",
    "                                                      shuffle=True,\n",
    "                                                      parallel_generators = 8,\n",
    "                                                      random_seed = RANDOM_SEED,\n",
    "                                                      **DATA_STREAM_PARAMETERS\n",
    "                                                      )\n",
    "  \n",
    "  # Calculate how many word shall be replaced\n",
    "  mask_number = int(np.round(X_BLOCK_LENGHT * MLM_MASK_FACTOR))\n",
    "  logging.info(f\"In each batch of X-Blocks, {mask_number*BATCH_SIZE} elements will be randomly masked. This is an average of {mask_number} per X-Block\")\n",
    "\n",
    "  # This while has to integrated into the FileListToDataStream method\n",
    "  while True:  \n",
    "    try:\n",
    "      ne = next(dataStreamTraining)\n",
    "      _X = ne['X']\n",
    "\n",
    "      # Convert the X-Block into a sentence\n",
    "      with tf.device('/CPU:0'):        \n",
    "        four_float_sentence = fourFloatClassifierModel.predict(_X, batch_size = BATCH_SIZE, verbose = 0)\n",
    "        int_sentence = ConvertFourFloatDataToWords(four_float_sentence, digitLimits)\n",
    "\n",
    "        # _X_sentence = intClassifierModel.predict(_X, batch_size = BATCH_SIZE, verbose = 0)\n",
    "\n",
    "      # Round to avoid too many categories\n",
    "      # Todo: Better classifier model!\n",
    "      # _X_sentence = np.round(_X_sentence / 10.0).astype(int)\n",
    "\n",
    "      # Create random indices, to replace 'words' with MASK_TOKEN_I\n",
    "      mask_positions = np.round(np.random.rand(BATCH_SIZE, mask_number) * X_BLOCK_LENGHT * BATCH_SIZE).astype(int)\n",
    "      mask_positions[mask_positions == X_BLOCK_LENGHT * BATCH_SIZE] -= 1  # Avoid the upper array limit\n",
    "\n",
    "      # Mask the chosen tokens\n",
    "      int_sentence_masked = np.array(int_sentence).flatten()\n",
    "      int_sentence_masked[mask_positions] = MASK_TOKEN_ID\n",
    "      int_sentence_masked = int_sentence_masked.reshape(int_sentence.shape)\n",
    "\n",
    "      # print(mask_positions[0,0])\n",
    "\n",
    "      # 'Remove' all tokens that shall not be predicted from the training y data (the full sentence), so that the network can focus on the missing tokens\n",
    "      # More precise: Setting them to -1 tells the loss function to ignore them\n",
    "      int_sentence[int_sentence_masked != MASK_TOKEN_ID] = -1\n",
    "\n",
    "      # Not required here, as the network shall predict back its original input\n",
    "      # _y = ne['y']\n",
    "      \n",
    "      # Return the masked senteces as X data, the full ones are the y-data --> The network shall predict the missing tokens\n",
    "      yield (int_sentence_masked, int_sentence)\n",
    "    except StopIteration as si:\n",
    "      logging.warning(\"StopIteration in pythonGenerator\")\n",
    "      logging.warning(si)\n",
    "      return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RLmWNTDIUpt6"
   },
   "outputs": [],
   "source": [
    "# A python generator function has to be applied on the dataStream\n",
    "\n",
    "def pythonGeneratorMLMEval():\n",
    "  # Initialize the FileListToDataStream generator\n",
    "  dataStreamTraining = DataStreamCreator.FileListToDataStream(fileList = TRAIN_FILES,\n",
    "                                                      batch_size = BATCH_SIZE,\n",
    "                                                      X_Block_lenght = X_BLOCK_LENGHT,\n",
    "                                                      y_type_dict=Y_TYPE_DICT,\n",
    "                                                      shuffle=True,\n",
    "                                                      parallel_generators = BATCH_SIZE,\n",
    "                                                      random_seed = RANDOM_SEED,\n",
    "                                                      **DATA_STREAM_PARAMETERS\n",
    "                                                      )\n",
    "  \n",
    "  # Calculate how many word shall be replaced\n",
    "  mask_number = int(np.round(X_BLOCK_LENGHT * MLM_MASK_FACTOR))\n",
    "  logging.info(f\"In each batch of X-Blocks, {mask_number*BATCH_SIZE} elements will be randomly masked. This is an average of {mask_number} per X-Block\")\n",
    "\n",
    "  # This while has to integrated into the FileListToDataStream method\n",
    "  while True:  \n",
    "    try:\n",
    "      ne = next(dataStreamTraining)\n",
    "      _X = ne['X']\n",
    "\n",
    "      # Convert the X-Block into a sentence\n",
    "      with tf.device('/CPU:0'):        \n",
    "        four_float_sentence = fourFloatClassifierModel.predict(_X, batch_size = BATCH_SIZE, verbose = 0)\n",
    "        int_sentence = ConvertFourFloatDataToWords(four_float_sentence, digitLimits)\n",
    "\n",
    "        # _X_sentence = intClassifierModel.predict(_X, batch_size = BATCH_SIZE, verbose = 0)\n",
    "\n",
    "      # Round to avoid too many categories\n",
    "      # Todo: Better classifier model!\n",
    "      # _X_sentence = np.round(_X_sentence / 10.0).astype(int)\n",
    "\n",
    "      # Create random indices, to replace 'words' with MASK_TOKEN_I\n",
    "      mask_positions = np.round(np.random.rand(BATCH_SIZE, mask_number) * X_BLOCK_LENGHT * BATCH_SIZE).astype(int)\n",
    "      mask_positions[mask_positions == X_BLOCK_LENGHT * BATCH_SIZE] -= 1  # Avoid the upper array limit\n",
    "\n",
    "      # Mask the chosen tokens\n",
    "      int_sentence_masked = np.array(int_sentence).flatten()\n",
    "      int_sentence_masked[mask_positions] = MASK_TOKEN_ID\n",
    "      int_sentence_masked = int_sentence_masked.reshape(int_sentence.shape)\n",
    "\n",
    "      # print(mask_positions[0,0])\n",
    "\n",
    "      # 'Remove' all tokens that shall not be predicted from the training y data (the full sentence), so that the network can focus on the missing tokens\n",
    "      # More precise: Setting them to -1 tells the loss function to ignore them\n",
    "      # int_sentence[int_sentence_masked != MASK_TOKEN_ID] = -1\n",
    "\n",
    "      # Not required here, as the network shall predict back its original input\n",
    "      # _y = ne['y']\n",
    "      \n",
    "      # Return the masked senteces as X data, the full ones are the y-data --> The network shall predict the missing tokens\n",
    "      yield (int_sentence_masked, int_sentence)\n",
    "    except StopIteration as si:\n",
    "      logging.warning(\"StopIteration in pythonGenerator\")\n",
    "      logging.warning(si)\n",
    "      return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iUSw95cqUuE_"
   },
   "outputs": [],
   "source": [
    "# Create a Tensorflow dataset out of the python generator, which can be fed to the network\n",
    "tfGenEval = tf.data.Dataset.from_generator(pythonGeneratorMLMEval, \n",
    "                                               output_types = (tf.int32, tf.int32),\n",
    "                                               output_shapes=(\n",
    "                                                   (BATCH_SIZE, X_BLOCK_LENGHT),\n",
    "                                                   (BATCH_SIZE, X_BLOCK_LENGHT)\n",
    "                                                   )\n",
    "                                               )\n",
    "tfGenEval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qI3WKmspUe2Z"
   },
   "outputs": [],
   "source": [
    "it = tfGenEval.as_numpy_iterator()\n",
    "ne = next(it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ktuZ3D04UzeE"
   },
   "outputs": [],
   "source": [
    "p = model.predict(ne[0])\n",
    "p.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-ZhRrApuU8M1"
   },
   "outputs": [],
   "source": [
    "gtVal = ne[1][0,:]\n",
    "gtVal.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aRfxK1DeVJWp"
   },
   "outputs": [],
   "source": [
    "porig= copy.deepcopy(p)\n",
    "# p = copy.deepcopy(porig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vgzPCL7KVXC1"
   },
   "outputs": [],
   "source": [
    "plt.plot(p[0,0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k6oO5JBsWz_j"
   },
   "outputs": [],
   "source": [
    "intPrediction = np.empty(p.shape[:-1])\n",
    "\n",
    "for b in range(p.shape[0]):\n",
    "  for ts in range(p.shape[1]):\n",
    "    classMax = np.max(p[b,ts,:])\n",
    "    maxIndex = np.where(p[b,ts,:] == classMax)\n",
    "\n",
    "    #print(f\"classMax: {classMax}, maxIndex: {maxIndex}\")\n",
    "    \n",
    "    intPrediction[b,ts] = maxIndex[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RPVXsb8mYGGL"
   },
   "outputs": [],
   "source": [
    "intPrediction.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V-utCJSuYStU"
   },
   "outputs": [],
   "source": [
    "gtVal[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3pXGXuOcYVo2"
   },
   "outputs": [],
   "source": [
    "intPrediction[0,:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "voZjwOaDDph1"
   },
   "outputs": [],
   "source": [
    "_ = plt.hist(gtVal.flatten(), bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a84-E1mj4RUY"
   },
   "outputs": [],
   "source": [
    "_ = plt.hist(intPrediction.flatten(), bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q_DfyjS2gsPi"
   },
   "outputs": [],
   "source": [
    "plt.plot(intPrediction[0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hsSenZntVcu8"
   },
   "outputs": [],
   "source": [
    "pMaxed = p * (p >= np.sort(p, axis=2)[:,[-1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "StZjtHTCV77e"
   },
   "outputs": [],
   "source": [
    "pMaxes = np.max(p, axis=2)\n",
    "pMaxes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pZzVhSx8WplK"
   },
   "outputs": [],
   "source": [
    "# p == pMaxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4sF0q8BlWQte"
   },
   "outputs": [],
   "source": [
    "# p[:] = np.where(p == pMaxes, pMaxes, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1lUV2_40WYcJ"
   },
   "outputs": [],
   "source": [
    "plt.plot(p[0,0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FtG_7-pWWC4s"
   },
   "outputs": [],
   "source": [
    "np.max(p[0,0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RPxpJLVpWF6c"
   },
   "outputs": [],
   "source": [
    "pMaxes[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cOM14p-9VxBY"
   },
   "outputs": [],
   "source": [
    "plt.plot(pMaxed[0,0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KSKQas1GQaM-",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# _save_folder = os.path.join(checkpoint_path,\n",
    "#                                 CHKPNT_NAME,\n",
    "#                                 \"robert_tpu_scratch_{:01d}_{:05d}\".format(112, 0)\n",
    "#                                 )\n",
    "\n",
    "# _model_path_local = os.path.join(\"/content/\", \"model.h5\")\n",
    "# _model_path_bucket = os.path.join(_save_folder, \"model.h5\")\n",
    "\n",
    "# model.save(_model_path_local)\n",
    "\n",
    "# # Copy model.h5 over to Google Cloud Storage\n",
    "# with file_io.FileIO(_model_path_local, mode='rb') as input_f:\n",
    "#     with file_io.FileIO(_model_path_bucket, mode='wb+') as output_f:\n",
    "#         output_f.write(input_f.read())\n",
    "#         print(\"\\nSaved model to: '\" + _model_path_bucket + \"'\")\n",
    "\n",
    "# # Save optimizer config\n",
    "# c = copy.deepcopy(model.optimizer.get_config())\n",
    "\n",
    "# fp = os.path.join(_save_folder, \"c.pickle\")\n",
    "# with file_io.FileIO(fp, mode='wb+') as handle:\n",
    "#   pickle.dump(c, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "#   print(\"Saved optimizer config to: '\" + fp + \"'\")\n",
    "\n",
    "# # Save optimizer weights\n",
    "# w = copy.deepcopy(model.optimizer.get_weights())\n",
    "\n",
    "# fp = os.path.join(_save_folder, \"w.pickle\")\n",
    "# with file_io.FileIO(fp, mode='wb+') as handle:\n",
    "#   pickle.dump(w, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "#   print(\"Saved optimizer weights to: '\" + fp + \"'\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
