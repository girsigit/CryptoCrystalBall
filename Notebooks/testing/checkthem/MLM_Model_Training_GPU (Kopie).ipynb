{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RIbOPenP-I_d"
   },
   "source": [
    "# Mount drive and bucket\n",
    "Todo: Remove in public version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "GHybPwDjX1gZ"
   },
   "outputs": [],
   "source": [
    "# Check if the notebook is run in Google Colab\n",
    "import sys\n",
    "\n",
    "COLAB = 'google.colab' in sys.modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(60000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 60 seconds\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import logging\n",
    "\n",
    "nblog = open(\"/content/bigdata/nb.log\", \"a+\")\n",
    "sys.stdout.echo = nblog\n",
    "sys.stderr.echo = nblog\n",
    "\n",
    "#get_ipython().log.handlers[0].stream = nblog\n",
    "#get_ipython().log.setLevel(logging.INFO)\n",
    "\n",
    "%autosave 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sK6Uuoy5qsua",
    "outputId": "d29d48f5-a2e5-40f9-927d-002d32fd48f9"
   },
   "outputs": [],
   "source": [
    "# if COLAB:\n",
    "#   from google.colab import drive\n",
    "#   drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "MTJ7bYMtHmvS"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run the command!\n"
     ]
    }
   ],
   "source": [
    "if COLAB:\n",
    "  from google.colab import auth\n",
    "  auth.authenticate_user()\n",
    "else:\n",
    "    print(\"Run the command!\")\n",
    "  #Todo #bring the command inside the notebook\n",
    "  #run this terminal inside docker: gcloud auth login b.girsule@gmail.com --no-launch-browser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "DOScyXpJws23"
   },
   "outputs": [],
   "source": [
    "# Todo: Check if possible in local docker\n",
    "# from google.cloud import storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "t9dbL-PU-okV",
    "outputId": "14e73bf6-881d-4bc0-96f4-8a1b79cae570"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-14 14:30:42.094180: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-14 14:30:42.218316: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-02-14 14:30:42.836359: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-14 14:30:42.836434: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-14 14:30:42.836447: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF Version is 2.10.0, ok!\n"
     ]
    }
   ],
   "source": [
    "# Check if the tf version is 2.10.0, this is required to use the 'ignore_class' in the  SparseCategoricalCrossentropy\n",
    "import tensorflow as tf\n",
    "\n",
    "if '2.10.0' != tf.__version__:\n",
    "  !pip uninstall tensorflow -y\n",
    "  !pip install tensorflow-gpu==2.10.0\n",
    "  please_restart_the_runtime\n",
    "else:\n",
    "  print(\"TF Version is 2.10.0, ok!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "FYePtDVpqtkN"
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "# import tensorflow_gcs_config\n",
    "from tensorflow.python.lib.io import file_io\n",
    "\n",
    "from keras.layers import Input, Dense #, ReLU, Add, Flatten, Concatenate, LayerNormalization, UpSampling2D, Activation, LSTM, Multiply, Dropout, Reshape, Permute, BatchNormalization, MaxPooling1D, AveragePooling1D, MaxPooling3D, AveragePooling2D, LayerNormalization, MaxPooling2D\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "pxa3Ug_JplIq"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "EcBnUrFKqyCK"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import datetime\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "R_3vswfeRqmj"
   },
   "outputs": [],
   "source": [
    "# Set the google cloud bucket data\n",
    "project_id = 'tweetprediction'\n",
    "bucket_name = 'crypto_nlp_training'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "X3s3eDubSFaJ",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set the checkpoint path for saving train progress\n",
    "if COLAB:\n",
    "    CHECKPOINT_PATH = f\"gs://{bucket_name}/chk/\"\n",
    "else:\n",
    "    CHECKPOINT_PATH = f\"/content/bigdata/chk/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8rvlsLwbpmWJ",
    "outputId": "12f0ff94-d55c-449f-f101-c4581499db7d"
   },
   "outputs": [],
   "source": [
    "# Check if the notebook is run in google colab, if so, clone the repo\n",
    "if COLAB:\n",
    "    print(\"Running in Colab\")\n",
    "\n",
    "    # Clone the whole repo to get all data and code if not already done\n",
    "    if not os.path.exists(\"/content/CryptoCrystalBall\"):\n",
    "      !git clone https://github.com/girsigit/CryptoCrystalBall\n",
    "\n",
    "      # cd into the notebooks directory --> Necessary to match all paths for importing\n",
    "    #%cd /content/CryptoCrystalBall/JupyterDocker/notebooks\n",
    "    %cd /content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "q9OmJ6vFthwG"
   },
   "outputs": [],
   "source": [
    "# Try importing the Ta-Lib library, if this fails, try to install it and\n",
    "# import it again afterwards\n",
    "try:\n",
    "    import talib\n",
    "except:\n",
    "    !wget http://prdownloads.sourceforge.net/ta-lib/ta-lib-0.4.0-src.tar.gz\n",
    "    !tar -xzvf ta-lib-0.4.0-src.tar.gz\n",
    "    %cd ta-lib\n",
    "    !./configure --prefix=/usr\n",
    "    !make\n",
    "    !make install\n",
    "    !pip install Ta-Lib\n",
    "    %cd ..\n",
    "\n",
    "    import talib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "2orTUN099zyA",
    "tags": []
   },
   "outputs": [],
   "source": [
    "try:\n",
    "  from transformers import TFRobertaModel, RobertaConfig\n",
    "except:\n",
    "  # Important!: Version 4.23 does not work on TPU\n",
    "  !pip install transformers==4.22\n",
    "\n",
    "  from transformers import TFRobertaModel, RobertaConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip uninstall -y tensorboard-plugin-profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qfAsp4TWHivL",
    "outputId": "a25fdba4-ad57-40a3-f725-7d4ed114d38b",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Required to do profiling\n",
    "# !pip install tensorboard-plugin-profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "axPYAbN9upgY",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nbt7oQxzL2Zy"
   },
   "source": [
    "---\n",
    "# Add custom import path for DataStreamCreator and IndicatorCalculator\n",
    "\n",
    "These libs are not in the standard python directory, so their paths have to be added to the import paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ICDL0OwbL2Zz",
    "outputId": "41c7541e-3a1e-4035-f2f3-182fed452a8e",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['', 'content']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Get the current directory\n",
    "# current_dir = os.getcwd()\n",
    "# current_dir_splitted = current_dir.split(os.sep)\n",
    "\n",
    "# Todo: is inside /content/CB in local docker\n",
    "current_dir_splitted = [\"\", \"content\"]\n",
    "current_dir_splitted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JJ8l6O2gL2Z1",
    "outputId": "de6d884a-f4be-47e2-c808-eeac3448580c",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dsc_dir: /content/CryptoCrystalBall/DataStreamCreator\n",
      "ind_dir: /content/CryptoCrystalBall/IndicatorCalculator\n"
     ]
    }
   ],
   "source": [
    "# Create the import directories for the DataStreamCreator and the IndicatorCalculator\n",
    "dsc_dir = '/content/CryptoCrystalBall/DataStreamCreator'\n",
    "print(f\"dsc_dir: {dsc_dir}\")\n",
    "\n",
    "ind_dir = '/content/CryptoCrystalBall/IndicatorCalculator'\n",
    "print(f\"ind_dir: {ind_dir}\")\n",
    "\n",
    "# Add them to the import paths\n",
    "sys.path.insert(0, dsc_dir)\n",
    "sys.path.insert(0, ind_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "iqyTbcZDttLT",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import the actual classes\n",
    "from IndicatorCalculator import IndicatorCalculator\n",
    "import DataStreamCreator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zPsG4dqRL2Z5"
   },
   "source": [
    "---\n",
    "# Define all the parameters and variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5J8ODl45L2Z6",
    "outputId": "690c2801-687e-47fe-cefc-616e029a62a5",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA_PATH: /content/DemoData\n"
     ]
    }
   ],
   "source": [
    "# Define the tick data path\n",
    "DATA_PATH = os.path.join(os.sep, *current_dir_splitted, 'DemoData')\n",
    "print(f\"DATA_PATH: {DATA_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7TUeLGiOL2Z7",
    "outputId": "00651843-f462-4c20-e6cc-7cb0d7cd6d23",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMG_SAVE_PATH: /content/Documentation/Images\n"
     ]
    }
   ],
   "source": [
    "# Define the chart image save path\n",
    "IMG_SAVE_PATH = os.path.join(os.sep, *current_dir_splitted, 'Documentation', 'Images')\n",
    "print(f\"IMG_SAVE_PATH: {IMG_SAVE_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "o23rkki9ttLZ",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define a global random seed\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "# Set the seed in np\n",
    "np.random.seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "g9gBeRtnxKMD",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# X_BLOCK_LENGHT defines how far into the past a 'slice of a chart' shall be\n",
    "# See: https://github.com/girsigit/CryptoCrystalBall/tree/main/DataStreamCreator#xblockgenerator\n",
    "X_BLOCK_LENGHT = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "sh5dsBKr5Ko-",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# How many examples shall be processed at the same time, limited by GPU memory\n",
    "BATCH_SIZE = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "J331jHk-u345",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# A fixed number of features is used\n",
    "FEATURES = 160"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "1JVT1Z2U0lW8",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Finanical indicator timespans\n",
    "# See: https://github.com/girsigit/CryptoCrystalBall/tree/main/IndicatorCalculator\n",
    "SHORTSPAN = 6\n",
    "MIDSPAN = 48\n",
    "LONGSPAN = 120"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "AnNz-Oke3J3p",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Additional settings for the data stream\n",
    "# For this notebook, the calculation of pattern indicators is turned off\n",
    "DATA_STREAM_PARAMETERS = {\n",
    "    \"calcPatternIndicators\": False, # No patterns are used\n",
    "    \"calcVolumeInidators\": False, # No volume indicators, these are wide spread and may disturb the classifer\n",
    "    \"dropna\": True # Drop all tick/indicator table rows containing nan values instead of just replacing them by 0 (which would lead to wrong predictions)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "GKkv21lAxYEP",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# NLP token configuration\n",
    "BOS_TOKEN_ID = 0\n",
    "PAD_TOKEN_ID = 1\n",
    "EOS_TOKEN_ID = 2\n",
    "MASK_TOKEN_ID = 3\n",
    "\n",
    "MLM_MASK_FACTOR = 0.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "V5P8Nbn7F5CS",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Vocab size configuration\n",
    "# The feature vector to integer classifier model has a 5 digit output, therefore the vocab size would be 100000\n",
    "# As this is too much, the categories are rounded --> Todo: Create better classifier model\n",
    "\n",
    "VOCAB_SIZE = 10000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7xXpDFe9ROVQ"
   },
   "source": [
    "# Load the train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "b2EO18ZmppNe",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Check if the dataset already has been copy, if not, copy it\n",
    "if not os.path.exists(\"/content/dataset\") or not os.path.exists(\"/content/dataset/Train\"):\n",
    "  !mkdir /content/dataset\n",
    "  !mkdir /content/dataset/Train\n",
    "  !gsutil -m cp -r gs://cryptocrystalball_public/CryptoDataset/Hourly/significant_currencies.txt /content/dataset/significant_currencies.txt\n",
    "  !gsutil -m cp -r gs://cryptocrystalball_public/CryptoDataset/Hourly/Train/* /content/dataset/Train/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2sRVckzNtbZL",
    "outputId": "5cfd2c06-7823-40b3-eea8-2dbc3f51df57",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 121 significant files names.\n"
     ]
    }
   ],
   "source": [
    "#@markdown ### Use only significant currencies\n",
    "#@markdown Load a manually defined list of significant currencies (`significant_currencies.txt`).\n",
    "#@markdown This list contains no currencies which little or no volume or price movement, to\n",
    "#@markdown avoid training on data sample which would never be used to trade on in a real \n",
    "#@markdown application.\n",
    "\n",
    "#@markdown If enabled, only currency pairs with the base currency USDT are laoded,\n",
    "#@markdown this is important to prevent interference between different cryptocurrencies.\n",
    "#@markdown For example, in `BTC-ETH.csv`, there is influence of both the BTC and the ETH price, but we want to predict trade signals based on a 'real' currency (USDT is kind of the same as USD).\n",
    "\n",
    "significant_only = True #@param {type:\"boolean\"}\n",
    "\n",
    "if significant_only:\n",
    "  with open(\"/content/dataset/significant_currencies.txt\") as f:\n",
    "    SIGNIFICANT_CURRS = f.read().splitlines()\n",
    "\n",
    "  print(f\"Loaded {len(SIGNIFICANT_CURRS)} significant files names.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dlNAUwUTtdBE",
    "outputId": "3c614762-758a-444f-dc86-e86527a6c0ca",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The train dataset contains 121 files.\n",
      "['/content/dataset/Train/1INCH-USDT.csv', '/content/dataset/Train/4ART-USDT.csv', '/content/dataset/Train/AAVE-USDT.csv']\n"
     ]
    }
   ],
   "source": [
    "# Get train file names - Only pick the ones ending with -USDT to prevent\n",
    "# influence between different currencies\n",
    "TRAIN_PATH = \"/content/dataset/Train\"\n",
    "\n",
    "# Get all file names\n",
    "TRAIN_FILES = [os.path.join(TRAIN_PATH,f) for f in listdir(TRAIN_PATH) if isfile(join(TRAIN_PATH, f)) and \".csv\" in f ]\n",
    "\n",
    "# Filter for significant currencies only\n",
    "if significant_only:\n",
    "  TRAIN_FILES = [f for f in TRAIN_FILES if f.split(\"/\")[-1].replace(\".csv\",\"\") in SIGNIFICANT_CURRS]\n",
    "\n",
    "# Filter for USDT-based ones only\n",
    "TRAIN_FILES = [f for f in TRAIN_FILES if \"-USDT\" in f]\n",
    "\n",
    "# Sort them (as a stable basis for randomizing afterwards)\n",
    "TRAIN_FILES = sorted(TRAIN_FILES)\n",
    "\n",
    "print(f\"The train dataset contains {len(TRAIN_FILES)} files.\")\n",
    "print(TRAIN_FILES[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jhiJj_nfsmU0"
   },
   "source": [
    "# Load the classifier model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i8fWOHkSsMpz",
    "outputId": "1f57628e-dd3c-4395-a875-5d33279b4616",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Copy the feature vector to four float classifier model\n",
    "# Also copy the digit limits\n",
    "if not os.path.exists(\"/content/bottleneckToFourFloatModel.h5\"):\n",
    "  !gsutil -m cp -r gs://crypto_nlp_training/four_float_to_int/bottleneckToFourFloatModel.h5 /content/bottleneckToFourFloatModel.h5\n",
    "  !gsutil -m cp -r gs://crypto_nlp_training/four_float_to_int/digitLimits.npy /content/digitLimits.npy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3daDKjTltDTH",
    "outputId": "aee227b2-d87a-4651-bf6f-14d73592e862",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-14 14:30:44.544927: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-14 14:30:44.583003: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-14 14:30:44.583189: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-14 14:30:44.584046: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-14 14:30:44.584747: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-14 14:30:44.584916: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-14 14:30:44.585060: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-14 14:30:45.044524: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-14 14:30:45.044726: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-14 14:30:45.044873: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-14 14:30:45.044995: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 7386 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1070, pci bus id: 0000:01:00.0, compute capability: 6.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "Model: \"NNClassifierBottleneckToFourFloat\"\n",
      "____________________________________________________________________________________________________________________________________________________________________________________________________________________________\n",
      " Layer (type)                                                                                      Output Shape                                                                            Param #                          \n",
      "============================================================================================================================================================================================================================\n",
      " inputTicksAndIndicators (InputLayer)                                                              [(None, 512, 160)]                                                                      0                                \n",
      "                                                                                                                                                                                                                            \n",
      " tf.expand_dims_1 (TFOpLambda)                                                                     (None, 512, 160, 1)                                                                     0                                \n",
      "                                                                                                                                                                                                                            \n",
      " permute_1 (Permute)                                                                               (None, 512, 1, 160)                                                                     0                                \n",
      "                                                                                                                                                                                                                            \n",
      " DepthwiseConv2DInput (DepthwiseConv2D)                                                            (None, 512, 1, 160)                                                                     160                              \n",
      "                                                                                                                                                                                                                            \n",
      " tf.compat.v1.squeeze_1 (TFOpLambda)                                                               (None, 512, 160)                                                                        0                                \n",
      "                                                                                                                                                                                                                            \n",
      " Tanh_Input (Activation)                                                                           (None, 512, 160)                                                                        0                                \n",
      "                                                                                                                                                                                                                            \n",
      " tf.clip_by_value_1 (TFOpLambda)                                                                   (None, 512, 160)                                                                        0                                \n",
      "                                                                                                                                                                                                                            \n",
      " Bottleneck_1 (Dense)                                                                              (None, 512, 80)                                                                         12880                            \n",
      "                                                                                                                                                                                                                            \n",
      " Bottleneck_2 (Dense)                                                                              (None, 512, 40)                                                                         3240                             \n",
      "                                                                                                                                                                                                                            \n",
      " Bottleneck_3 (Dense)                                                                              (None, 512, 4)                                                                          164                              \n",
      "                                                                                                                                                                                                                            \n",
      "============================================================================================================================================================================================================================\n",
      "Total params: 16,444\n",
      "Trainable params: 16,444\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________________________________________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Load the model\n",
    "with tf.device('/CPU:0'):\n",
    "    fourFloatClassifierModel = keras.models.load_model(\"/content/bottleneckToFourFloatModel.h5\")\n",
    "    fourFloatClassifierModel.summary(line_length=220)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "2nLWLP3AB3gG",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load the digit limits\n",
    "digitLimits = np.load(\"/content/digitLimits.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0BeeQ7hvhXJF"
   },
   "source": [
    "# Load the class weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "05AAfFUyhZdg"
   },
   "outputs": [],
   "source": [
    "# # Copy the class weights\n",
    "# if not os.path.exists(\"/content/Class_weights_4Digit.h5\"):\n",
    "#   !gsutil -m cp -r gs://cryptocrystalball_public/XBlockToSentence/Classifier_Dense/4Digits/Class_weights_4Digit.npy /content/Class_weights_4Digit.h5\n",
    "\n",
    "# cwnp = np.load(\"/content/Class_weights_4Digit.h5\")\n",
    "\n",
    "# CLASS_WEIGHTS_DICT = {}\n",
    "\n",
    "# for i in range(cwnp.shape[0]):\n",
    "#   CLASS_WEIGHTS_DICT[i] = 1.0 / cwnp[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J9cA0AKquwZ2"
   },
   "source": [
    "---\n",
    "# Prepare data source\n",
    "\n",
    "For training a neural network, first the data source has to be prepared. For this purpose, the method `FileListToDataStream` from the `DataStreamCreator` class is used. This method creates a stream of `X-Block` and `y-data` arrays out of a list of .csv file names, pointing to tick tables (called `EXAMPLE_FILE_PATHS` in this example). For details about `X-Blocks` and `y-data`, please refer to the documentation of the `XBlockGenerator` and the `YDataGenerator` under https://github.com/girsigit/CryptoCrystalBall/tree/main/DataStreamCreator.\n",
    "\n",
    "<br>\n",
    "\n",
    "Target values (y-data) from the data generator would not be necessary in this notebook, but since it cannot be switched off, the future direction and its derviation of the price have been chosen in `Y_TYPE_DICT` since they are not expensive to compute. A switch flag will be added in a future release."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pqze4dT8uz6V",
    "outputId": "985dae70-a5db-4972-bde2-b52e5b15c6b5",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dataType': 0,\n",
       " 'direction_ma_timespan': 200,\n",
       " 'derivation_ma_timespan': 100,\n",
       " 'direction_derivation_shift_span': 0}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set direction and derivation information as y target\n",
    "# Both y values (direction & derivation) are in the interval [-1.0,1.0]\n",
    "\n",
    "Y_TYPE_DICT = copy.deepcopy(DataStreamCreator.YDataGenerator.PARAM_DICT_TEMPLATE_Y_DATA_TYPE_DIRECTION_FLOAT)\n",
    "Y_TYPE_DICT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mlb37_K21h7j",
    "outputId": "473038a5-e93d-4ba8-e917-4da2ba5ba05f",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "77"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate how many word shall be replaced\n",
    "replace_index_number = int(np.round(X_BLOCK_LENGHT * MLM_MASK_FACTOR))\n",
    "replace_index_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1gVe75Q51mHH",
    "outputId": "3dba72d9-8963-4293-b88c-f11421c1d0e3",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 77)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[192, 487, 375, 307,  80,  80,  30, 443, 308, 363,  11, 497, 426,\n",
       "        109,  93,  94, 156, 269, 221, 149, 313,  71, 150, 188, 234, 402,\n",
       "        102, 263, 303,  24, 311,  87,  33, 486, 494, 414, 156,  50, 350,\n",
       "        225,  62, 254,  18, 466, 132, 339, 160, 266, 280,  95, 496, 397,\n",
       "        481, 458, 306, 472,  45, 100,  23, 167, 199, 139, 424, 183, 144,\n",
       "        278,  72, 411,  38, 505, 395, 102,   3, 418, 362, 373, 395],\n",
       "       [ 38, 184,  59, 442, 319, 169,  33, 159, 166, 374, 326, 454, 242,\n",
       "         61, 365, 390, 287, 395, 253, 268, 219,  13,  55,  16, 326, 161,\n",
       "        260, 465, 128, 210, 387, 117,  39, 148,  83, 476, 414, 324, 446,\n",
       "        411,  96, 457, 276, 413, 459, 163,  56, 117, 219, 419, 441,   4,\n",
       "        262, 214, 114,  61, 173, 483, 165, 266, 360, 186, 498, 493, 129,\n",
       "        255, 154, 146,  19, 312, 257,  26, 143, 465, 123,  74, 251],\n",
       "       [505, 124, 344, 390, 122, 373, 188, 324, 324, 274,  46, 428, 164,\n",
       "         95,  21, 303, 347,   8, 262, 116, 330,  89, 354, 198, 480,  70,\n",
       "        175,  58, 473, 449, 132, 338, 418, 284, 271, 124,  48, 459, 461,\n",
       "        324, 174, 179, 372, 459, 454, 399, 329,  43,  83, 460, 310,   5,\n",
       "         52, 340,   3,  82, 281, 354, 334, 115, 365, 121, 167, 382, 333,\n",
       "        435, 337, 291,  48, 188, 136, 125, 498, 201, 457, 323, 407],\n",
       "       [257, 295, 252, 100, 370, 144,  12, 330,  91, 482, 488, 468, 190,\n",
       "          8, 475, 219, 495, 493, 437, 151, 197, 436, 162,  87, 285, 479,\n",
       "        356, 292,  50, 315, 507,  72, 265, 449, 379, 357, 360, 184, 150,\n",
       "        414, 415, 444, 468, 262, 257, 409, 333, 359, 407, 456, 173, 192,\n",
       "         48, 296,  18, 238, 278, 147, 303,  16,  19, 421, 184,  65, 267,\n",
       "        394, 111, 319,  44,  26, 272, 277, 326, 372, 500, 264, 165],\n",
       "       [407, 139, 225,  40,  13, 493, 428, 356, 209,  89,  80, 128, 281,\n",
       "        366, 338, 143, 489, 378, 284, 313, 215, 127, 182, 388,   7,  59,\n",
       "         24,  21, 438, 360, 243,  50, 252, 242,  89, 222, 204, 315, 325,\n",
       "         23, 192, 320, 258, 439, 337,  83,  36, 329,  14, 300, 481, 295,\n",
       "        199, 329, 235, 279, 482, 198, 492, 464, 100,  36,  52,   9,  48,\n",
       "        350,  36, 163, 433,  12, 417, 144,  61, 357, 322, 449, 376]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create random indices, to replace 'words' with MASK_TOKEN_I\n",
    "mask_positions = np.round(np.random.rand(BATCH_SIZE, replace_index_number) * X_BLOCK_LENGHT).astype(int)\n",
    "print(mask_positions.shape)\n",
    "mask_positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 336
    },
    "id": "vVctAErd2wzo",
    "outputId": "435f0cae-bf0a-4446-9078-bafb66dd4fbf",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([51., 38., 35., 40., 22., 41., 43., 35., 37., 43.]),\n",
       " array([  3. ,  53.4, 103.8, 154.2, 204.6, 255. , 305.4, 355.8, 406.2,\n",
       "        456.6, 507. ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(mask_positions.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "a7iuksPdCSrZ",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Method for normalizing the distribution of one digit\n",
    "def NormalizeDigitDistribution(dataIn, categoryLimitValues):\n",
    "  normalizedDistribution = np.empty(dataIn.shape)\n",
    "\n",
    "  for i, lim in enumerate(categoryLimitValues):\n",
    "    normalizedDistribution[(dataIn >= lim[0]) & (dataIn <= lim[1])] = i\n",
    "\n",
    "  return normalizedDistribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "d4kZzefRCRhB",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Method for converting a four-float vector into an integer 'word' in the range of 0-10000\n",
    "def ConvertFourFloatDataToWords(fourFloatIn, digitLimits):\n",
    "  # Normalize each digit\n",
    "  digitsNormalized = []\n",
    "\n",
    "  for digit in range(4):\n",
    "    digitsNormalized.append(\n",
    "        NormalizeDigitDistribution(fourFloatIn[:,:,digit], digitLimits[digit])\n",
    "        )\n",
    "    \n",
    "  # Combine the digits to one integer (creating the 'word')\n",
    "  intData = digitsNormalized[0] * 1000 + digitsNormalized[1] * 100 + digitsNormalized[2] * 10 + digitsNormalized[3]\n",
    "  intData = intData.astype(np.int32)  \n",
    "\n",
    "  del digitsNormalized\n",
    "\n",
    "  return intData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "S2e6q_2su26o",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# A python generator function has to be applied on the dataStream\n",
    "\n",
    "def pythonGeneratorMLMTraining():\n",
    "  # Initialize the FileListToDataStream generator\n",
    "  dataStreamTraining = DataStreamCreator.FileListToDataStream(fileList = TRAIN_FILES,\n",
    "                                                      batch_size = BATCH_SIZE,\n",
    "                                                      X_Block_lenght = X_BLOCK_LENGHT,\n",
    "                                                      y_type_dict=Y_TYPE_DICT,\n",
    "                                                      shuffle=True,\n",
    "                                                      parallel_generators = BATCH_SIZE,\n",
    "                                                      random_seed = RANDOM_SEED,\n",
    "                                                      **DATA_STREAM_PARAMETERS\n",
    "                                                      )\n",
    "  \n",
    "  # Calculate how many word shall be replaced\n",
    "  mask_number = int(np.round(X_BLOCK_LENGHT * MLM_MASK_FACTOR))\n",
    "  logging.info(f\"In each batch of X-Blocks, {mask_number*BATCH_SIZE} elements will be randomly masked. This is an average of {mask_number} per X-Block\")\n",
    "\n",
    "  # This while has to integrated into the FileListToDataStream method\n",
    "  while True:  \n",
    "    try:\n",
    "      ne = next(dataStreamTraining)\n",
    "      _X = ne['X']\n",
    "\n",
    "      # Convert the X-Block into a sentence\n",
    "      with tf.device('/CPU:0'):        \n",
    "        four_float_sentence = fourFloatClassifierModel.predict(_X, batch_size = BATCH_SIZE, verbose = 0)\n",
    "        int_sentence = ConvertFourFloatDataToWords(four_float_sentence, digitLimits)\n",
    "\n",
    "        # _X_sentence = intClassifierModel.predict(_X, batch_size = BATCH_SIZE, verbose = 0)\n",
    "\n",
    "      # Round to avoid too many categories\n",
    "      # Todo: Better classifier model!\n",
    "      # _X_sentence = np.round(_X_sentence / 10.0).astype(int)\n",
    "\n",
    "      # Create random indices, to replace 'words' with MASK_TOKEN_I\n",
    "      mask_positions = np.round(np.random.rand(BATCH_SIZE, mask_number) * X_BLOCK_LENGHT * BATCH_SIZE).astype(int)\n",
    "      mask_positions[mask_positions == X_BLOCK_LENGHT * BATCH_SIZE] -= 1  # Avoid the upper array limit\n",
    "\n",
    "      # Mask the chosen tokens\n",
    "      int_sentence_masked = np.array(int_sentence).flatten()\n",
    "      int_sentence_masked[mask_positions] = MASK_TOKEN_ID\n",
    "      int_sentence_masked = int_sentence_masked.reshape(int_sentence.shape)\n",
    "\n",
    "      # print(mask_positions[0,0])\n",
    "\n",
    "      # 'Remove' all tokens that shall not be predicted from the training y data (the full sentence), so that the network can focus on the missing tokens\n",
    "      # More precise: Setting them to -1 tells the loss function to ignore them\n",
    "      int_sentence[int_sentence_masked != MASK_TOKEN_ID] = -1\n",
    "\n",
    "      # Not required here, as the network shall predict back its original input\n",
    "      # _y = ne['y']\n",
    "      \n",
    "      # Return the masked senteces as X data, the full ones are the y-data --> The network shall predict the missing tokens\n",
    "      yield (int_sentence_masked, int_sentence)\n",
    "    except StopIteration as si:\n",
    "      logging.warning(\"StopIteration in pythonGenerator\")\n",
    "      logging.warning(si)\n",
    "      return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FoTRNHyEvnyg",
    "outputId": "d7fb1944-9236-47c2-c749-8a999e6fe3e3",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<FlatMapDataset element_spec=(TensorSpec(shape=(5, 512), dtype=tf.int32, name=None), TensorSpec(shape=(5, 512), dtype=tf.int32, name=None))>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a Tensorflow dataset out of the python generator, which can be fed to the network\n",
    "tfGenTraining = tf.data.Dataset.from_generator(pythonGeneratorMLMTraining, \n",
    "                                               output_types = (tf.int32, tf.int32),\n",
    "                                               output_shapes=(\n",
    "                                                   (BATCH_SIZE, X_BLOCK_LENGHT),\n",
    "                                                   (BATCH_SIZE, X_BLOCK_LENGHT)\n",
    "                                                   )\n",
    "                                               )\n",
    "tfGenTraining.prefetch(buffer_size=2)\n",
    "tfGenTraining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YST-Iwzsv4GO",
    "outputId": "5bcf6d64-6742-46d2-a6da-860fd98e47b2",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:File 'UBQ-USDT.csv' loaded, 120 left\n",
      "INFO:root:File 'HDAO-USDT.csv' loaded, 119 left\n",
      "INFO:root:File 'SMARTCREDIT-USDT.csv' loaded, 118 left\n",
      "INFO:root:File 'BSV-USDT.csv' loaded, 117 left\n",
      "INFO:root:File 'VET-USDT.csv' loaded, 116 left\n",
      "INFO:root:In each batch of X-Blocks, 385 elements will be randomly masked. This is an average of 77 per X-Block\n"
     ]
    }
   ],
   "source": [
    "it = tfGenTraining.as_numpy_iterator()\n",
    "\n",
    "ne = next(it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fUxLLmbB3gu2",
    "outputId": "47b8b7f0-9e8e-4ca1-e7de-fe1619e0193a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4443, 4544, 4443, ..., 5461, 9364, 8177],\n",
       "       [4443, 4443, 4443, ..., 1055, 1055,  220],\n",
       "       [4443, 4443, 4443, ..., 1712, 4812, 6813],\n",
       "       [4544, 4443, 4443, ..., 9656,    3, 8567],\n",
       "       [4443, 4443, 4443, ..., 6805, 8904,    3]], dtype=int32)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ne[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wh8PxiukwI4r",
    "outputId": "08907604-1651-4f5e-9552-228b10bb71fb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  -1,   -1,   -1, ...,   -1,   -1,   -1],\n",
       "       [  -1,   -1,   -1, ...,   -1,   -1,   -1],\n",
       "       [  -1,   -1,   -1, ...,   -1,   -1,   -1],\n",
       "       [  -1,   -1,   -1, ...,   -1, 8656,   -1],\n",
       "       [  -1,   -1,   -1, ...,   -1,   -1, 6806]], dtype=int32)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ne[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 354
    },
    "id": "n7Ge9vX8C2q3",
    "outputId": "0dfd442e-7bcc-43fc-951c-3be50f20a210"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([597., 242., 202., 218., 297., 219., 180., 201., 206., 198.]),\n",
       " array([3.0000e+00, 9.9970e+02, 1.9964e+03, 2.9931e+03, 3.9898e+03,\n",
       "        4.9865e+03, 5.9832e+03, 6.9799e+03, 7.9766e+03, 8.9733e+03,\n",
       "        9.9700e+03]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(ne[0].flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 372
    },
    "id": "5_UA09HxC48E",
    "outputId": "9e36f4da-0996-4cd8-d316-abee0fcf3e76"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([2238.,   36.,   42.,   28.,   39.,   30.,   36.,   49.,   41.,\n",
       "          21.]),\n",
       " array([-1.0000e+00,  9.9250e+02,  1.9860e+03,  2.9795e+03,  3.9730e+03,\n",
       "         4.9665e+03,  5.9600e+03,  6.9535e+03,  7.9470e+03,  8.9405e+03,\n",
       "         9.9340e+03]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(ne[1].flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3Ow2UkYNIB2X",
    "outputId": "c9667f3f-ddfd-423c-ab3e-fafb1db5b396"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  -1,   -1,   -1, ...,   -1,   -1,   -1],\n",
       "       [  -1,   -1,   -1, ...,   -1,   -1,   -1],\n",
       "       [  -1,   -1,   -1, ...,   -1,   -1,   -1],\n",
       "       [  -1,   -1,   -1, ...,   -1, 8656,   -1],\n",
       "       [  -1,   -1,   -1, ...,   -1,   -1, 6806]], dtype=int32)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wurst = np.array(ne[1])\n",
    "wurst[ne[0] != MASK_TOKEN_ID] = -1\n",
    "wurst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LGFj4aix8P9y",
    "outputId": "c5a2d142-40b7-4f8a-c075-8f351858b62a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "82"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(ne[0][0,:] == 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "moBea0tTbFbX"
   },
   "source": [
    "---\n",
    "# Create the NLP model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7V1gTRpwWvV_",
    "outputId": "0eacc029-3de8-4c13-a15d-0852238cfac7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RobertaConfig {\n",
       "  \"attention_probs_dropout_prob\": 0.1,\n",
       "  \"bos_token_id\": 0,\n",
       "  \"classifier_dropout\": null,\n",
       "  \"eos_token_id\": 2,\n",
       "  \"hidden_act\": \"gelu\",\n",
       "  \"hidden_dropout_prob\": 0.1,\n",
       "  \"hidden_size\": 768,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"intermediate_size\": 3072,\n",
       "  \"layer_norm_eps\": 1e-12,\n",
       "  \"max_position_embeddings\": 513,\n",
       "  \"model_type\": \"roberta\",\n",
       "  \"num_attention_heads\": 12,\n",
       "  \"num_hidden_layers\": 12,\n",
       "  \"pad_token_id\": 1,\n",
       "  \"position_embedding_type\": \"absolute\",\n",
       "  \"transformers_version\": \"4.22.0\",\n",
       "  \"type_vocab_size\": 2,\n",
       "  \"use_cache\": true,\n",
       "  \"vocab_size\": 10000\n",
       "}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg = RobertaConfig()\n",
    "\n",
    "cfg.vocab_size = VOCAB_SIZE\n",
    "cfg.max_position_embeddings = X_BLOCK_LENGHT + 1\n",
    "\n",
    "cfg.bos_token_id = BOS_TOKEN_ID\n",
    "cfg.pad_token_id = PAD_TOKEN_ID\n",
    "cfg.eos_token_id = EOS_TOKEN_ID\n",
    "\n",
    "cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LE3ZxhjDuZmA",
    "outputId": "819b43b3-72b8-4f41-f8f3-286efc50804d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"RobertaMLMTraining_1\"\n",
      "____________________________________________________________________________________________________________________________________________________________________________________________________________________________\n",
      " Layer (type)                                                                                      Output Shape                                                                            Param #                          \n",
      "============================================================================================================================================================================================================================\n",
      " input (InputLayer)                                                                                [(None, 512)]                                                                           0                                \n",
      "                                                                                                                                                                                                                            \n",
      " tf_roberta_model (TFRobertaModel)                                                                 TFBaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=(None, 512, 768),      93722112                         \n",
      "                                                                                                    pooler_output=(None, 768),                                                                                              \n",
      "                                                                                                    past_key_values=None, hidden_states=None, attentions=None, cross_attentions=None)                                       \n",
      "                                                                                                                                                                                                                            \n",
      " Categories (Dense)                                                                                (None, 512, 10000)                                                                      7690000                          \n",
      "                                                                                                                                                                                                                            \n",
      "============================================================================================================================================================================================================================\n",
      "Total params: 101,412,112\n",
      "Trainable params: 101,412,112\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________________________________________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#@title CreateModelRobertaMLMTraining\n",
    "def CreateModelRobertaMLMTraining():\n",
    "\n",
    "  # A sentence as input\n",
    "  inputSentence = Input(shape=(X_BLOCK_LENGHT), name='input', dtype='int32')\n",
    "  \n",
    "  # The NLP model\n",
    "  nlp = TFRobertaModel(cfg)(inputSentence)\n",
    "\n",
    "  # A dense layer to predict back the full sentence\n",
    "  predicted_sentence = Dense(VOCAB_SIZE, activation='softmax', name=\"Categories\")(nlp['last_hidden_state'])\n",
    "\n",
    "  outputs = [predicted_sentence]\n",
    "\n",
    "  # And combine it all in a model object\n",
    "  model = Model(inputs=inputSentence, outputs=outputs, name='RobertaMLMTraining_1')\n",
    "\n",
    "  return model\n",
    "\n",
    "model = CreateModelRobertaMLMTraining()\n",
    "model.summary(line_length=220)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ufsD_eAeSSXi"
   },
   "source": [
    "### Todo: Check if weighted classed are required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "PrUGwBcoYfxV"
   },
   "outputs": [],
   "source": [
    "# #@title Load the class weights\n",
    "# with file_io.FileIO('gs://ticks_with_indicators_with_volume/sentences/set2/weightArray.npy', mode='rb') as input_f:\n",
    "#   with file_io.FileIO('/content/weightArray.npy', mode='wb+') as output_f:\n",
    "#     output_f.write(input_f.read())\n",
    "\n",
    "# CLASS_WEIGHTS = np.empty((1,1,1024))\n",
    "# CLASS_WEIGHTS[0,0,:] = np.load('/content/weightArray.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "1QdZbG6kYg-1"
   },
   "outputs": [],
   "source": [
    "# plt.plot(CLASS_WEIGHTS[0,0,:])\n",
    "# plt.yscale(\"log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "Rpigcso1YiwV"
   },
   "outputs": [],
   "source": [
    "# CLASS_WEIGHTS_TF_CONST = tf.constant(tf.convert_to_tensor(CLASS_WEIGHTS,dtype=tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "cellView": "form",
    "id": "jg3ngnAVYlZI"
   },
   "outputs": [],
   "source": [
    "#@title CreateModelRobertaMLMTrainingWeighted - Todo change to new style\n",
    "def CreateModelRobertaMLMTrainingWeighted():\n",
    "\n",
    "  # Build your model input\n",
    "  inputSentence = Input(shape=(X_LOOKBACK_CNT), name='input', dtype='int32')\n",
    "  \n",
    "  nlp = TFRobertaModel(cfg)(inputSentence)\n",
    "\n",
    "  categories = Dense(1024, activation='softmax', name=\"Categories\")(nlp['last_hidden_state'])\n",
    "  categories_weighted = tf.multiply(categories, CLASS_WEIGHTS_TF_CONST)\n",
    "\n",
    "  outputs = [categories_weighted]\n",
    "\n",
    "  mnamesuffix = \"_1\"\n",
    "\n",
    "  # And combine it all in a model object\n",
    "  model = Model(inputs=inputSentence, outputs=outputs, name='ModelRobertaMLMTrainingWeighted'+mnamesuffix)\n",
    "\n",
    "  return model\n",
    "\n",
    "# model = CreateModelRobertaMLMTrainingWeighted()\n",
    "# model.summary(line_length=220)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "cellView": "form",
    "id": "RQbpCGz8fHAi"
   },
   "outputs": [],
   "source": [
    "#@title CreateModelRobertaMLMTrainingDropout - Todo change to new style\n",
    "def CreateModelRobertaMLMTrainingDropout():\n",
    "\n",
    "  # Build your model input\n",
    "  inputSentence = Input(shape=(X_LOOKBACK_CNT), name='input', dtype='int32')\n",
    "  \n",
    "  nlp = TFRobertaModel(cfg, name=\"Roberta\")(inputSentence)\n",
    "\n",
    "  categories = Dense(VOCAB_SIZE, activation='softmax', name=\"Categories\")(nlp['last_hidden_state'])\n",
    "  drp = Dropout(0.15, name=\"CategoriesDropout\")(categories)\n",
    "\n",
    "  # categories_weighted = tf.multiply(drp, CLASS_WEIGHTS_TF_CONST)\n",
    "\n",
    "  outputs = [drp]\n",
    "\n",
    "  mnamesuffix = \"_1\"\n",
    "\n",
    "  # And combine it all in a model object\n",
    "  model = Model(inputs=inputSentence, outputs=outputs, name='ModelRobertaMLMTrainingDropout'+mnamesuffix)\n",
    "\n",
    "  return model\n",
    "\n",
    "# model = CreateModelRobertaMLMTrainingDropout()\n",
    "# model.summary(line_length=220)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "cellView": "form",
    "id": "ZDpFvhHH7hEi"
   },
   "outputs": [],
   "source": [
    "#@title CreateModelRobertaLastWordPrediction - Todo change to new style\n",
    "def CreateModelRobertaLastWordPrediction():\n",
    "\n",
    "  # Build your model input\n",
    "  inputSentence = Input(shape=(X_LOOKBACK_CNT), name='input', dtype='int32')\n",
    "  \n",
    "  nlp = TFRobertaModel(cfg, name=\"Roberta\")(inputSentence)\n",
    "\n",
    "  flat = Flatten(name=\"FlattenNLP\")(nlp['last_hidden_state'])\n",
    "  lastWord = Dense(VOCAB_SIZE, activation='softmax', name=\"Categories\", dtype=tf.float32)(flat)\n",
    "\n",
    "  outputs = [lastWord]\n",
    "\n",
    "  mnamesuffix = \"_1\"\n",
    "\n",
    "  # And combine it all in a model object\n",
    "  model = Model(inputs=inputSentence, outputs=outputs, name='ModelRobertaLastWordPrediction'+mnamesuffix)\n",
    "\n",
    "  return model\n",
    "\n",
    "# model = CreateModelRobertaLastWordPrediction()\n",
    "# model.summary(line_length=220)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kXE8AjjoEWE4"
   },
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QfwL7EWInGWB"
   },
   "source": [
    "### Train strategy in the paper\n",
    "https://huggingface.co/roberta-base\n",
    "\n",
    "The model was trained on 1024 V100 GPUs for 500K steps with a batch size of 8K and a sequence length of 512. The optimizer used is Adam with a learning rate of 6e-4, β1=0.9\\beta_{1} = 0.9β1​=0.9, β2=0.98\\beta_{2} = 0.98β2​=0.98 and ϵ=1e−6\\epsilon = 1e-6ϵ=1e−6, a weight decay of 0.01, learning rate warmup for 24,000 steps and linear decay of the learning rate after."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "_jkOrQ01hZnE",
    "outputId": "afe655bf-d35c-4f71-ced0-d225a2ff6155"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'RobertaMLMTraining_1_GPU_512LB_10000VC_MaskedPrediction'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CHKPNT_NAME = f\"{model.name}_GPU_{X_BLOCK_LENGHT}LB_{VOCAB_SIZE}VC_MaskedPrediction\"\n",
    "CHKPNT_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "g0VmovApkwAB"
   },
   "outputs": [],
   "source": [
    "# Set an optimizer\n",
    "optimizer = Adam(\n",
    "    learning_rate=5e-04,\n",
    "    epsilon=1e-06,\n",
    "    beta_1=0.9,\n",
    "    beta_2=0.98,\n",
    "    decay=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "id": "yMoJi05f0JKp"
   },
   "outputs": [],
   "source": [
    "# # Create a masked loss to predict only the missing tokens\n",
    "# # https://stackoverflow.com/questions/56328140/how-do-i-implement-a-masked-softmax-cross-entropy-loss-function-in-keras\n",
    "\n",
    "# SCCE = tf.keras.losses.SparseCategoricalCrossentropy(reduction=tf.keras.losses.Reduction.NONE, from_logits=False)\n",
    "\n",
    "# def sparse_crossentropy_masked(y_true, y_pred):\n",
    "#   y_true_masked = tf.boolean_mask(y_true, tf.not_equal(y_true, -1))\n",
    "#   y_pred_masked = tf.boolean_mask(y_pred, tf.not_equal(y_true, -1))\n",
    "\n",
    "#   return tf.reduce_sum(SCCE(y_true_masked, y_pred_masked)) * (1. / BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "id": "mhCAE0Ujne49"
   },
   "outputs": [],
   "source": [
    "# # Create a masked loss to predict only the missing tokens\n",
    "# # https://stackoverflow.com/questions/56328140/how-do-i-implement-a-masked-softmax-cross-entropy-loss-function-in-keras\n",
    "\n",
    "# SCCE = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False)\n",
    "\n",
    "# def sparse_crossentropy_masked(y_true, y_pred):\n",
    "#   # y_true_masked = tf.boolean_mask(y_true, tf.not_equal(y_true, -1))\n",
    "#   # y_pred_masked = tf.boolean_mask(y_pred, tf.not_equal(y_true, -1))\n",
    "\n",
    "#   maskTensor = tf.not_equal(y_true, -1)\n",
    "#   a\n",
    "#   y_true_masked = y_true * tf.cast(maskTensor, tf.int32)\n",
    "#   y_pred_masked = y_pred * tf.cast(maskTensor, tf.float32)\n",
    "\n",
    "#   return SCCE(y_true_masked, y_pred_masked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "id": "AOLSygN7Ut7_"
   },
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "# model.compile(\n",
    "#     optimizer = optimizer,\n",
    "#     loss = [tf.keras.losses.MeanSquaredError()], \n",
    "#     metrics=[tf.keras.losses.MeanAbsoluteError(), tf.keras.losses.MeanAbsolutePercentageError()])\n",
    "\n",
    "model.compile(\n",
    "    optimizer = optimizer,\n",
    "    loss = tf.keras.losses.SparseCategoricalCrossentropy(ignore_class=-1),\n",
    "    metrics=None)\n",
    "\n",
    "# model.compile(\n",
    "#     optimizer = optimizer,\n",
    "#     loss = sparse_crossentropy_masked, \n",
    "#     metrics=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TFa0iWcaqli5",
    "outputId": "0ec595c6-7c5c-4723-8a2c-64d0d7a07f08"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"RobertaMLMTraining_1\"\n",
      "____________________________________________________________________________________________________________________________________________________________________________________________________________________________\n",
      " Layer (type)                                                                                      Output Shape                                                                            Param #                          \n",
      "============================================================================================================================================================================================================================\n",
      " input (InputLayer)                                                                                [(None, 512)]                                                                           0                                \n",
      "                                                                                                                                                                                                                            \n",
      " tf_roberta_model (TFRobertaModel)                                                                 TFBaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=(None, 512, 768),      93722112                         \n",
      "                                                                                                    pooler_output=(None, 768),                                                                                              \n",
      "                                                                                                    past_key_values=None, hidden_states=None, attentions=None, cross_attentions=None)                                       \n",
      "                                                                                                                                                                                                                            \n",
      " Categories (Dense)                                                                                (None, 512, 10000)                                                                      7690000                          \n",
      "                                                                                                                                                                                                                            \n",
      "============================================================================================================================================================================================================================\n",
      "Total params: 101,412,112\n",
      "Trainable params: 101,412,112\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________________________________________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary(line_length=220)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "id": "iGC1RvizroRS"
   },
   "outputs": [],
   "source": [
    "# # Callback for colab\n",
    "# # Todo: Adapt the callback to be suitable for both colab (store to bucket) and local (store to disk)\n",
    "# #@title CustomCallback\n",
    "# class CustomCallback(tf.keras.callbacks.Callback):\n",
    "#   def __init__(self, save_freq, val_freq, checkpoint_path, model_name, epoch_add=0):\n",
    "#     self.save_freq = save_freq\n",
    "#     self.val_freq = val_freq\n",
    "#     self.checkpoint_path = checkpoint_path\n",
    "#     self.model_name = model_name\n",
    "#     self.current_epoch = 0\n",
    "#     self.epoch_add = epoch_add\n",
    "\n",
    "#   def on_epoch_begin(self, epoch, logs=None):\n",
    "#     self.current_epoch = epoch + self.epoch_add\n",
    "#     # keys = list(logs.keys())\n",
    "#     # print(\"Start epoch {} of training; got log keys: {}\".format(epoch, keys))\n",
    "\n",
    "#   def on_epoch_end(self, epoch, logs=None):\n",
    "#     self.saveTheModel(-1, logs)\n",
    "\n",
    "#   def on_train_batch_end(self, batch, logs=None):\n",
    "#     self.saveTheModel(batch, logs)\n",
    "\n",
    "#   def saveTheModel(self, batch, logs=None):\n",
    "#     if (0 < batch and 0 == batch % self.save_freq) or (0 > batch):\n",
    "#       if 0 > batch:\n",
    "#         _save_folder = os.path.join(self.checkpoint_path,\n",
    "#                                     self.model_name,\n",
    "#                                     \"cp_daily_valid_{:02d}_end\".format(self.current_epoch)\n",
    "#                                     )\n",
    "#       else:\n",
    "#         _save_folder = os.path.join(self.checkpoint_path,\n",
    "#                                     self.model_name,\n",
    "#                                     \"cp_daily_valid_{:02d}_{:05d}\".format(self.current_epoch, batch)\n",
    "#                                     )\n",
    "\n",
    "#       _model_path_local = os.path.join(\"/content/\", \"model.h5\")\n",
    "#       _model_path_bucket = os.path.join(_save_folder, \"model.h5\")\n",
    "\n",
    "#       model.save(_model_path_local)\n",
    "     \n",
    "#       # Copy model.h5 over to Google Cloud Storage\n",
    "#       with file_io.FileIO(_model_path_local, mode='rb') as input_f:\n",
    "#           with file_io.FileIO(_model_path_bucket, mode='wb+') as output_f:\n",
    "#               output_f.write(input_f.read())\n",
    "#               print(\"\\nSaved model to: '\" + _model_path_bucket + \"'\")\n",
    "\n",
    "#       # Save optimizer config\n",
    "#       c = copy.deepcopy(self.model.optimizer.get_config())\n",
    "\n",
    "#       fp = os.path.join(_save_folder, \"c.pickle\")\n",
    "#       with file_io.FileIO(fp, mode='wb+') as handle:\n",
    "#         pickle.dump(c, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "#         print(\"Saved optimizer config to: '\" + fp + \"'\")\n",
    "\n",
    "#       # Save optimizer weights\n",
    "#       # w = copy.deepcopy(self.model.optimizer.get_weights())\n",
    "\n",
    "#       # fp = os.path.join(_save_folder, \"w.pickle\")\n",
    "#       # with file_io.FileIO(fp, mode='wb+') as handle:\n",
    "#       #   pickle.dump(w, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "#       #   print(\"Saved optimizer weights to: '\" + fp + \"'\")\n",
    "\n",
    "#     # if 0 < batch and 0 == batch % self.val_freq:\n",
    "#     #   print(\"-------------------------EVAL-------------------------\")\n",
    "#     #   model.evaluate(tfgenTest)\n",
    "#     #   print(\"\\n-------------------------EVAL-------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title CustomCallback\n",
    "class CustomCallback(tf.keras.callbacks.Callback):\n",
    "  def __init__(self, save_freq, val_freq, checkpoint_path, model_name, epoch_add=0):\n",
    "    self.save_freq = save_freq\n",
    "    self.val_freq = val_freq\n",
    "    self.checkpoint_path = checkpoint_path\n",
    "    self.model_name = model_name\n",
    "    self.current_epoch = 0\n",
    "    self.epoch_add = epoch_add\n",
    "\n",
    "  def on_epoch_begin(self, epoch, logs=None):\n",
    "    self.current_epoch = epoch + self.epoch_add\n",
    "    # keys = list(logs.keys())\n",
    "    # print(\"Start epoch {} of training; got log keys: {}\".format(epoch, keys))\n",
    "\n",
    "  def on_epoch_end(self, epoch, logs=None):\n",
    "    self.saveTheModel(-1, logs)\n",
    "\n",
    "  def on_train_batch_end(self, batch, logs=None):\n",
    "    self.saveTheModel(batch, logs)\n",
    "\n",
    "  def saveTheModel(self, batch, logs=None):\n",
    "    if (0 < batch and 0 == batch % self.save_freq) or (0 > batch):\n",
    "      if 0 > batch:\n",
    "        _save_folder = os.path.join(self.checkpoint_path,\n",
    "                                    self.model_name,\n",
    "                                    \"cp_daily_valid_{:02d}_end\".format(self.current_epoch)\n",
    "                                    )\n",
    "      else:\n",
    "        _save_folder = os.path.join(self.checkpoint_path,\n",
    "                                    self.model_name,\n",
    "                                    \"cp_daily_valid_{:02d}_{:05d}\".format(self.current_epoch, batch)\n",
    "                                    )\n",
    "      \n",
    "      fp = os.path.join(_save_folder, \"model.h5\")\n",
    "      model.save(fp)\n",
    "      logging.info(f\"Saved model to '{fp}'\")\n",
    "      \n",
    "      # Save optimizer config\n",
    "      c = copy.deepcopy(self.model.optimizer.get_config())\n",
    "\n",
    "      fp = os.path.join(_save_folder, \"c.pickle\")\n",
    "      with file_io.FileIO(fp, mode='wb+') as handle:\n",
    "        pickle.dump(c, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "        \n",
    "      logging.info(f\"Saved optimizer config to '{fp}'\")\n",
    "\n",
    "      # Save optimizer weights\n",
    "      w = copy.deepcopy(self.model.optimizer.get_weights())\n",
    "\n",
    "      fp = os.path.join(_save_folder, \"w.pickle\")\n",
    "      with open(fp, \"wb\") as handle:\n",
    "        # with file_io.FileIO(fp, mode='wb+') as handle:\n",
    "        pickle.dump(w, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "      \n",
    "      logging.info(f\"Saved optimizer weights to '{fp}'\")\n",
    "\n",
    "    # if 0 < batch and 0 == batch % self.val_freq:\n",
    "    #   print(\"-------------------------EVAL-------------------------\")\n",
    "    #   model.evaluate(tfgenTest)\n",
    "    #   print(\"\\n-------------------------EVAL-------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "id": "TczoGFYOStmg"
   },
   "outputs": [],
   "source": [
    "CLASS_WEIGHTS_DICT = None\n",
    "# CLASS_WEIGHTS_DICT = {}\n",
    "\n",
    "# for i, cw in enumerate(CLASS_WEIGHTS[0,0,:]):\n",
    "#   CLASS_WEIGHTS_DICT[i] = cw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "id": "JyggHiDGNTEX"
   },
   "outputs": [],
   "source": [
    "epoch_add = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "id": "-pJ08IBN7cgB"
   },
   "outputs": [],
   "source": [
    "CALLBACK_EVERY_N_BATCHES = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "id": "CuGT0rFvzH1n"
   },
   "outputs": [],
   "source": [
    "cc = CustomCallback(checkpoint_path = CHECKPOINT_PATH,\n",
    "                    model_name = CHKPNT_NAME,\n",
    "                    save_freq = CALLBACK_EVERY_N_BATCHES,\n",
    "                    val_freq = CALLBACK_EVERY_N_BATCHES,\n",
    "                    epoch_add = epoch_add)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "id": "LuuH0xBKGE1g",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "id": "0noHN-UeSCQ-"
   },
   "outputs": [],
   "source": [
    "%reload_ext tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u7xAyqce3qYJ"
   },
   "source": [
    "The TensorBoard UI is displayed in a browser window. In this colab, perform the following steps to prepare to capture profile information.\n",
    "1.  Click on the dropdown menu box on the top right side and scroll down and click PROFILE. A new window appears that shows: **No profile data was found** at the top.\n",
    "1.  Click on the CAPTURE PROFILE button. A new dialog appears. The top input line shows: **Profile Service URL or TPU name**. Copy and paste the Profile Service URL (the service_addr value shown before launching TensorBoard) into the top input line. While still on the dialog box, start the training with the next step.\n",
    "1.  Click on the next colab cell to start training the model.\n",
    "1.  Watch the output from the training until several epochs have completed. This allows time for the profile data to start being collected. Return to the dialog box and click on the CAPTURE button. If the capture succeeds, the page will auto refresh and redirect you to the profiling results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "mpUXurxwSp_3",
    "outputId": "8d57d014-c4bc-49e1-a434-179a5be0529c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/content/bigdata/log/RobertaMLMTraining_1_GPU_512LB_10000VC_MaskedPrediction20230214-143052'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Todo: Create more elegant solution\n",
    "log_dir = \"gs://ticks_with_indicators_with_volume/logs/TPU/\" + CHKPNT_NAME + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "if not COLAB:\n",
    "    log_dir = os.path.join(\"/content/bigdata/log\",log_dir.split(\"/\")[-1])\n",
    "\n",
    "log_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "He5Jna87RsPN",
    "outputId": "efab0e32-2cca-4c12-bc49-8cd1fb7492b9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/content/bigdata/log/RobertaMLMTraining_1_GPU_512LB_10000VC_MaskedPrediction20230214-143052'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "id": "_X-ab7uc3gTt"
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(\n",
    "    log_dir=log_dir,\n",
    "    histogram_freq=1,\n",
    "    update_freq=CALLBACK_EVERY_N_BATCHES    \n",
    "    )\n",
    "#profile_batch=(5,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "CLASS_WEIGHTS_DICT = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-37ffaea8a703a5e5\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-37ffaea8a703a5e5\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir $log_dir --host 0.0.0.0 --port 6006"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DcUTfAbHb2FW",
    "outputId": "a6b2d3a2-f00f-4733-fd4b-268b42e7f2a6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model/roberta/pooler/dense/kernel:0', 'tf_roberta_model/roberta/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model/roberta/pooler/dense/kernel:0', 'tf_roberta_model/roberta/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model/roberta/pooler/dense/kernel:0', 'tf_roberta_model/roberta/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model/roberta/pooler/dense/kernel:0', 'tf_roberta_model/roberta/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "INFO:root:File 'UBQ-USDT.csv' loaded, 120 left\n",
      "INFO:root:File 'HDAO-USDT.csv' loaded, 119 left\n",
      "INFO:root:File 'SMARTCREDIT-USDT.csv' loaded, 118 left\n",
      "INFO:root:File 'BSV-USDT.csv' loaded, 117 left\n",
      "INFO:root:File 'VET-USDT.csv' loaded, 116 left\n",
      "INFO:root:In each batch of X-Blocks, 385 elements will be randomly masked. This is an average of 77 per X-Block\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   2000/Unknown - 1308s 649ms/step - loss: 7.6869"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Saved model to '/content/bigdata/chk/RobertaMLMTraining_1_GPU_512LB_10000VC_MaskedPrediction/cp_daily_valid_00_02000/model.h5'\n",
      "INFO:root:Saved optimizer config to '/content/bigdata/chk/RobertaMLMTraining_1_GPU_512LB_10000VC_MaskedPrediction/cp_daily_valid_00_02000/c.pickle'\n",
      "INFO:root:Saved optimizer weights to '/content/bigdata/chk/RobertaMLMTraining_1_GPU_512LB_10000VC_MaskedPrediction/cp_daily_valid_00_02000/w.pickle'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   2711/Unknown - 1782s 654ms/step - loss: 7.6822"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:File 'MCH-USDT.csv' loaded in retry loop, 115 left\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   3025/Unknown - 1986s 653ms/step - loss: 7.6855"
     ]
    }
   ],
   "source": [
    "model.fit(tfGenTraining,\n",
    "          epochs=200,\n",
    "          verbose = 1,\n",
    "          callbacks=[tensorboard_callback, cc],\n",
    "          class_weight=CLASS_WEIGHTS_DICT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2Nh12BlMEOBF",
    "outputId": "8bb69110-e6ee-48e6-e62b-1547db0c5ee4"
   },
   "outputs": [],
   "source": [
    "# copy_filenames = ['gs://crypto_nlp_training/chk/RobertaMLMTraining_1_GPU_512LB_10000VC_MaskedPrediction/cp_daily_valid_01_06000/model.h5'\n",
    "#                   ]\n",
    "\n",
    "# for p in copy_filenames:\n",
    "#   fn = p.split(\"/\")[-1]\n",
    "#   cpnt = p.split(\"/\")[-2]\n",
    "\n",
    "#   os.mkdir(os.path.join(\"/content\", cpnt))\n",
    "\n",
    "#   localPath = os.path.join(\"/content\", cpnt, fn)\n",
    "\n",
    "#   if (\"model.h5\" in p):\n",
    "#     localPathModel = localPath\n",
    "#   elif (\"w.pickle\" in p):\n",
    "#     localPathW = localPath\n",
    "\n",
    "#   with file_io.FileIO(p, mode='rb') as input_f:\n",
    "#     with file_io.FileIO(localPath, mode='wb+') as output_f:\n",
    "#       output_f.write(input_f.read())\n",
    "#       print(\"Pulled from bucket: '\" + fn + \"'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nYu7qfd3IsMu",
    "outputId": "d24bd442-2144-459f-eec5-0437fdd2cde3"
   },
   "outputs": [],
   "source": [
    "# print(f\"Loading {localPathModel}\")\n",
    "# model.load_weights(localPathModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HRuwJfh2l7nS"
   },
   "outputs": [],
   "source": [
    "# model.load_weights(\"/content/model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3HLXTKPAfZ04"
   },
   "outputs": [],
   "source": [
    "# modelOld = CreateModelRobertaMLMTrainingDropout()\n",
    "# modelOld.load_weights(\"/content/cp_daily_valid_49_end/model.h5\")\n",
    "# modelOld.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NWKr6ROif078"
   },
   "outputs": [],
   "source": [
    "# model.get_layer(\"Roberta\").set_weights(modelOld.get_layer(\"Roberta\").get_weights())\n",
    "# model.get_layer(\"Categories\").set_weights(modelOld.get_layer(\"Categories\").get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_mV2OpQAGDja"
   },
   "outputs": [],
   "source": [
    "# with open(\"/content/w.pickle\", 'rb') as pickle_file:\n",
    "#   w = pickle.load(pickle_file)\n",
    "# model.optimizer.set_weights(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kXHVjhsDHHF9"
   },
   "outputs": [],
   "source": [
    "# model.optimizer.learning_rate = 5e-2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HyBFN04Q-qcU"
   },
   "source": [
    "LR 5e-4  5000/Unknown - 5576s 1s/step - loss: 296.81093730\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zvFil-4dStzq"
   },
   "source": [
    "# Full sentence as y\n",
    "20000/Unknown - 21155s 1s/step - loss: 0.9579\n",
    "Saved model to: 'gs://crypto_nlp_training/chk/RobertaMLMTraining_1_GPU_512LB_10000VC_FullPrediction/cp_daily_valid_00_20000/model.h5'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5le0oPyfbE79"
   },
   "source": [
    "# Masked sentence as y, LR 5e-4, Random state 11\n",
    "14000/Unknown - 15387s 1s/step - loss: 5.3956\n",
    "Saved model to: 'gs://crypto_nlp_training/chk/RobertaMLMTraining_1_GPU_512LB_10000VC_MaskedPrediction/cp_daily_valid_00_14000/model.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P2BZv38mgNQs"
   },
   "outputs": [],
   "source": [
    "# A python generator function has to be applied on the dataStream\n",
    "\n",
    "def pythonGeneratorMLMTraining():\n",
    "  # Initialize the FileListToDataStream generator\n",
    "  dataStreamTraining = DataStreamCreator.FileListToDataStream(fileList = TRAIN_FILES,\n",
    "                                                      batch_size = BATCH_SIZE,\n",
    "                                                      X_Block_lenght = X_BLOCK_LENGHT,\n",
    "                                                      y_type_dict=Y_TYPE_DICT,\n",
    "                                                      shuffle=True,\n",
    "                                                      parallel_generators = 8,\n",
    "                                                      random_seed = RANDOM_SEED,\n",
    "                                                      **DATA_STREAM_PARAMETERS\n",
    "                                                      )\n",
    "  \n",
    "  # Calculate how many word shall be replaced\n",
    "  mask_number = int(np.round(X_BLOCK_LENGHT * MLM_MASK_FACTOR))\n",
    "  logging.info(f\"In each batch of X-Blocks, {mask_number*BATCH_SIZE} elements will be randomly masked. This is an average of {mask_number} per X-Block\")\n",
    "\n",
    "  # This while has to integrated into the FileListToDataStream method\n",
    "  while True:  \n",
    "    try:\n",
    "      ne = next(dataStreamTraining)\n",
    "      _X = ne['X']\n",
    "\n",
    "      # Convert the X-Block into a sentence\n",
    "      with tf.device('/CPU:0'):        \n",
    "        four_float_sentence = fourFloatClassifierModel.predict(_X, batch_size = BATCH_SIZE, verbose = 0)\n",
    "        int_sentence = ConvertFourFloatDataToWords(four_float_sentence, digitLimits)\n",
    "\n",
    "        # _X_sentence = intClassifierModel.predict(_X, batch_size = BATCH_SIZE, verbose = 0)\n",
    "\n",
    "      # Round to avoid too many categories\n",
    "      # Todo: Better classifier model!\n",
    "      # _X_sentence = np.round(_X_sentence / 10.0).astype(int)\n",
    "\n",
    "      # Create random indices, to replace 'words' with MASK_TOKEN_I\n",
    "      mask_positions = np.round(np.random.rand(BATCH_SIZE, mask_number) * X_BLOCK_LENGHT * BATCH_SIZE).astype(int)\n",
    "      mask_positions[mask_positions == X_BLOCK_LENGHT * BATCH_SIZE] -= 1  # Avoid the upper array limit\n",
    "\n",
    "      # Mask the chosen tokens\n",
    "      int_sentence_masked = np.array(int_sentence).flatten()\n",
    "      int_sentence_masked[mask_positions] = MASK_TOKEN_ID\n",
    "      int_sentence_masked = int_sentence_masked.reshape(int_sentence.shape)\n",
    "\n",
    "      # print(mask_positions[0,0])\n",
    "\n",
    "      # 'Remove' all tokens that shall not be predicted from the training y data (the full sentence), so that the network can focus on the missing tokens\n",
    "      # More precise: Setting them to -1 tells the loss function to ignore them\n",
    "      int_sentence[int_sentence_masked != MASK_TOKEN_ID] = -1\n",
    "\n",
    "      # Not required here, as the network shall predict back its original input\n",
    "      # _y = ne['y']\n",
    "      \n",
    "      # Return the masked senteces as X data, the full ones are the y-data --> The network shall predict the missing tokens\n",
    "      yield (int_sentence_masked, int_sentence)\n",
    "    except StopIteration as si:\n",
    "      logging.warning(\"StopIteration in pythonGenerator\")\n",
    "      logging.warning(si)\n",
    "      return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RLmWNTDIUpt6"
   },
   "outputs": [],
   "source": [
    "# A python generator function has to be applied on the dataStream\n",
    "\n",
    "def pythonGeneratorMLMEval():\n",
    "  # Initialize the FileListToDataStream generator\n",
    "  dataStreamTraining = DataStreamCreator.FileListToDataStream(fileList = TRAIN_FILES,\n",
    "                                                      batch_size = BATCH_SIZE,\n",
    "                                                      X_Block_lenght = X_BLOCK_LENGHT,\n",
    "                                                      y_type_dict=Y_TYPE_DICT,\n",
    "                                                      shuffle=True,\n",
    "                                                      parallel_generators = 4,\n",
    "                                                      random_seed = RANDOM_SEED,\n",
    "                                                      **DATA_STREAM_PARAMETERS\n",
    "                                                      )\n",
    "  \n",
    "  # Calculate how many word shall be replaced\n",
    "  mask_number = int(np.round(X_BLOCK_LENGHT * MLM_MASK_FACTOR))\n",
    "  logging.info(f\"In each batch of X-Blocks, {mask_number*BATCH_SIZE} elements will be randomly masked. This is an average of {mask_number} per X-Block\")\n",
    "\n",
    "  # This while has to integrated into the FileListToDataStream method\n",
    "  while True:  \n",
    "    try:\n",
    "      ne = next(dataStreamTraining)\n",
    "      _X = ne['X']\n",
    "\n",
    "      # Convert the X-Block into a sentence\n",
    "      with tf.device('/CPU:0'):        \n",
    "        four_float_sentence = fourFloatClassifierModel.predict(_X, batch_size = BATCH_SIZE, verbose = 0)\n",
    "        int_sentence = ConvertFourFloatDataToWords(four_float_sentence, digitLimits)\n",
    "\n",
    "        # _X_sentence = intClassifierModel.predict(_X, batch_size = BATCH_SIZE, verbose = 0)\n",
    "\n",
    "      # Round to avoid too many categories\n",
    "      # Todo: Better classifier model!\n",
    "      # _X_sentence = np.round(_X_sentence / 10.0).astype(int)\n",
    "\n",
    "      # Create random indices, to replace 'words' with MASK_TOKEN_I\n",
    "      mask_positions = np.round(np.random.rand(BATCH_SIZE, mask_number) * X_BLOCK_LENGHT * BATCH_SIZE).astype(int)\n",
    "      mask_positions[mask_positions == X_BLOCK_LENGHT * BATCH_SIZE] -= 1  # Avoid the upper array limit\n",
    "\n",
    "      # Mask the chosen tokens\n",
    "      int_sentence_masked = np.array(int_sentence).flatten()\n",
    "      int_sentence_masked[mask_positions] = MASK_TOKEN_ID\n",
    "      int_sentence_masked = int_sentence_masked.reshape(int_sentence.shape)\n",
    "\n",
    "      # print(mask_positions[0,0])\n",
    "\n",
    "      # 'Remove' all tokens that shall not be predicted from the training y data (the full sentence), so that the network can focus on the missing tokens\n",
    "      # More precise: Setting them to -1 tells the loss function to ignore them\n",
    "      # int_sentence[int_sentence_masked != MASK_TOKEN_ID] = -1\n",
    "\n",
    "      # Not required here, as the network shall predict back its original input\n",
    "      # _y = ne['y']\n",
    "      \n",
    "      # Return the masked senteces as X data, the full ones are the y-data --> The network shall predict the missing tokens\n",
    "      yield (int_sentence_masked, int_sentence)\n",
    "    except StopIteration as si:\n",
    "      logging.warning(\"StopIteration in pythonGenerator\")\n",
    "      logging.warning(si)\n",
    "      return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iUSw95cqUuE_"
   },
   "outputs": [],
   "source": [
    "# Create a Tensorflow dataset out of the python generator, which can be fed to the network\n",
    "tfGenEval = tf.data.Dataset.from_generator(pythonGeneratorMLMEval, \n",
    "                                               output_types = (tf.int32, tf.int32),\n",
    "                                               output_shapes=(\n",
    "                                                   (BATCH_SIZE, X_BLOCK_LENGHT),\n",
    "                                                   (BATCH_SIZE, X_BLOCK_LENGHT)\n",
    "                                                   )\n",
    "                                               )\n",
    "tfGenEval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qI3WKmspUe2Z"
   },
   "outputs": [],
   "source": [
    "it = tfGenEval.as_numpy_iterator()\n",
    "ne = next(it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ktuZ3D04UzeE"
   },
   "outputs": [],
   "source": [
    "p = model.predict(ne[0])\n",
    "p.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-ZhRrApuU8M1"
   },
   "outputs": [],
   "source": [
    "gtVal = ne[1][0,:]\n",
    "gtVal.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aRfxK1DeVJWp"
   },
   "outputs": [],
   "source": [
    "porig= copy.deepcopy(p)\n",
    "# p = copy.deepcopy(porig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vgzPCL7KVXC1"
   },
   "outputs": [],
   "source": [
    "plt.plot(p[0,0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k6oO5JBsWz_j"
   },
   "outputs": [],
   "source": [
    "intPrediction = np.empty(p.shape[:-1])\n",
    "\n",
    "for b in range(p.shape[0]):\n",
    "  for ts in range(p.shape[1]):\n",
    "    classMax = np.max(p[b,ts,:])\n",
    "    maxIndex = np.where(p[b,ts,:] == classMax)\n",
    "\n",
    "    #print(f\"classMax: {classMax}, maxIndex: {maxIndex}\")\n",
    "    \n",
    "    intPrediction[b,ts] = maxIndex[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RPVXsb8mYGGL"
   },
   "outputs": [],
   "source": [
    "intPrediction.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V-utCJSuYStU"
   },
   "outputs": [],
   "source": [
    "gtVal[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3pXGXuOcYVo2"
   },
   "outputs": [],
   "source": [
    "intPrediction[0,:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "voZjwOaDDph1"
   },
   "outputs": [],
   "source": [
    "plt.hist(gtVal.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a84-E1mj4RUY"
   },
   "outputs": [],
   "source": [
    "plt.hist(intPrediction.flatten(), bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q_DfyjS2gsPi"
   },
   "outputs": [],
   "source": [
    "plt.plot(intPrediction[0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hsSenZntVcu8"
   },
   "outputs": [],
   "source": [
    "pMaxed = p * (p >= np.sort(p, axis=2)[:,[-1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "StZjtHTCV77e"
   },
   "outputs": [],
   "source": [
    "pMaxes = np.max(p, axis=2)\n",
    "pMaxes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pZzVhSx8WplK"
   },
   "outputs": [],
   "source": [
    "# p == pMaxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4sF0q8BlWQte"
   },
   "outputs": [],
   "source": [
    "# p[:] = np.where(p == pMaxes, pMaxes, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1lUV2_40WYcJ"
   },
   "outputs": [],
   "source": [
    "plt.plot(p[0,0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FtG_7-pWWC4s"
   },
   "outputs": [],
   "source": [
    "np.max(p[0,0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RPxpJLVpWF6c"
   },
   "outputs": [],
   "source": [
    "pMaxes[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cOM14p-9VxBY"
   },
   "outputs": [],
   "source": [
    "plt.plot(pMaxed[0,0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KSKQas1GQaM-",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# _save_folder = os.path.join(checkpoint_path,\n",
    "#                                 CHKPNT_NAME,\n",
    "#                                 \"robert_tpu_scratch_{:01d}_{:05d}\".format(112, 0)\n",
    "#                                 )\n",
    "\n",
    "# _model_path_local = os.path.join(\"/content/\", \"model.h5\")\n",
    "# _model_path_bucket = os.path.join(_save_folder, \"model.h5\")\n",
    "\n",
    "# model.save(_model_path_local)\n",
    "\n",
    "# # Copy model.h5 over to Google Cloud Storage\n",
    "# with file_io.FileIO(_model_path_local, mode='rb') as input_f:\n",
    "#     with file_io.FileIO(_model_path_bucket, mode='wb+') as output_f:\n",
    "#         output_f.write(input_f.read())\n",
    "#         print(\"\\nSaved model to: '\" + _model_path_bucket + \"'\")\n",
    "\n",
    "# # Save optimizer config\n",
    "# c = copy.deepcopy(model.optimizer.get_config())\n",
    "\n",
    "# fp = os.path.join(_save_folder, \"c.pickle\")\n",
    "# with file_io.FileIO(fp, mode='wb+') as handle:\n",
    "#   pickle.dump(c, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "#   print(\"Saved optimizer config to: '\" + fp + \"'\")\n",
    "\n",
    "# # Save optimizer weights\n",
    "# w = copy.deepcopy(model.optimizer.get_weights())\n",
    "\n",
    "# fp = os.path.join(_save_folder, \"w.pickle\")\n",
    "# with file_io.FileIO(fp, mode='wb+') as handle:\n",
    "#   pickle.dump(w, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "#   print(\"Saved optimizer weights to: '\" + fp + \"'\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
